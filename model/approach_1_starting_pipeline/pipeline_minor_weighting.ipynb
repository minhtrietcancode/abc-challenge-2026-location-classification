{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e151f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare all of 4 folds data\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_filter_fold(i):\n",
    "    train_dir = f'../../cleaned_dataset/split_data/fold{i}/train.csv'  \n",
    "    test_dir = f'../../cleaned_dataset/split_data/fold{i}/test.csv'   \n",
    "    # load the data \n",
    "    train_df = pd.read_csv(train_dir)\n",
    "    test_df = pd.read_csv(test_dir)\n",
    "\n",
    "    # Get all of the unique labels for train / test sets \n",
    "    train_labels = list(train_df['room'].unique())\n",
    "    test_labels = list(test_df['room'].unique())\n",
    "\n",
    "    # Labels that appear in BOTH train and test\n",
    "    common_labels = list(set(train_labels) & set(test_labels))\n",
    "\n",
    "    # Filter to just keep the records with labels in common labels list\n",
    "    train_df = train_df[train_df['room'].isin(common_labels)].reset_index(drop=True)\n",
    "    test_df  = test_df[test_df['room'].isin(common_labels)].reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# Load fold 1\n",
    "train_df_1, test_df_1 = load_and_filter_fold(1)\n",
    "\n",
    "# Load fold 2\n",
    "train_df_2, test_df_2 = load_and_filter_fold(2)\n",
    "\n",
    "# Load fold 3\n",
    "train_df_3, test_df_3 = load_and_filter_fold(3)\n",
    "\n",
    "# Load fold 4\n",
    "train_df_4, test_df_4 = load_and_filter_fold(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a7bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add 25 beacon_1, beacon_2, ... , beacon_25\n",
    "def add_beacon_features(df, num_beacons=25):\n",
    "    df = df.copy()\n",
    "\n",
    "    for i in range(1, num_beacons + 1):\n",
    "        df[f'beacon_{i}'] = df['RSSI'].where(df['mac address'] == i, 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def aggregate_by_timestamp(df):\n",
    "    \"\"\"\n",
    "    Aggregate beacon data by timestamp (1-second windows)\n",
    "    \n",
    "    For each beacon column:\n",
    "    - If ALL values are 0: set mean, std, min, max, count = 0\n",
    "    - If ANY non-zero values exist: calculate statistics ONLY on non-zero values\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns: timestamp, room, beacon_1, beacon_2, ..., beacon_25\n",
    "    \n",
    "    Returns:\n",
    "        windowed_df: DataFrame with columns:\n",
    "            - timestamp\n",
    "            - room\n",
    "            - beacon_1_mean, beacon_1_std, beacon_1_min, beacon_1_max, beacon_1_count\n",
    "            - beacon_2_mean, beacon_2_std, beacon_2_min, beacon_2_max, beacon_2_count\n",
    "            - ...\n",
    "            - beacon_25_mean, beacon_25_std, beacon_25_min, beacon_25_max, beacon_25_count\n",
    "    \"\"\"    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Group by timestamp\n",
    "    grouped = df.groupby('timestamp')\n",
    "    \n",
    "    result_rows = []\n",
    "    \n",
    "    for timestamp, group in grouped:\n",
    "        # Initialize row with timestamp and room\n",
    "        row_data = {\n",
    "            'timestamp': timestamp,\n",
    "            'room': group['room'].iloc[0]  # Take first room value (should be consistent)\n",
    "        }\n",
    "        \n",
    "        # Process each beacon column (beacon_1 to beacon_25)\n",
    "        for beacon_id in range(1, 26):\n",
    "            beacon_col = f'beacon_{beacon_id}'\n",
    "            \n",
    "            # Get all values for this beacon in this window\n",
    "            beacon_values = group[beacon_col].values\n",
    "            \n",
    "            # Filter to get only non-zero values\n",
    "            non_zero_values = beacon_values[beacon_values != 0]\n",
    "            \n",
    "            # Check if we have any non-zero values\n",
    "            if len(non_zero_values) > 0:\n",
    "                # Calculate statistics on non-zero values ONLY\n",
    "                row_data[f'{beacon_col}_mean'] = non_zero_values.mean()\n",
    "                row_data[f'{beacon_col}_std'] = non_zero_values.std() if len(non_zero_values) > 1 else 0.0\n",
    "                row_data[f'{beacon_col}_min'] = non_zero_values.min()\n",
    "                row_data[f'{beacon_col}_max'] = non_zero_values.max()\n",
    "                row_data[f'{beacon_col}_count'] = len(non_zero_values)\n",
    "            else:\n",
    "                # All values are zero - set everything to 0\n",
    "                row_data[f'{beacon_col}_mean'] = 0.0\n",
    "                row_data[f'{beacon_col}_std'] = 0.0\n",
    "                row_data[f'{beacon_col}_min'] = 0.0\n",
    "                row_data[f'{beacon_col}_max'] = 0.0\n",
    "                row_data[f'{beacon_col}_count'] = 0\n",
    "        \n",
    "        result_rows.append(row_data)\n",
    "    \n",
    "    # Create DataFrame from result rows\n",
    "    windowed_df = pd.DataFrame(result_rows)\n",
    "    \n",
    "    # Filter out completely empty windows (all beacons are 0)\n",
    "    beacon_mean_cols = [f'beacon_{i}_mean' for i in range(1, 26)]\n",
    "    valid_windows = windowed_df[beacon_mean_cols].sum(axis=1) != 0\n",
    "    \n",
    "    removed_count = (~valid_windows).sum()\n",
    "    windowed_df = windowed_df[valid_windows].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Total windows after aggregation: {len(windowed_df)}\")\n",
    "    print(f\"Removed {removed_count} empty windows (all beacons = 0)\")\n",
    "    print(f\"Features: 25 beacons × 5 statistics = 125 features\")\n",
    "    \n",
    "    return windowed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a4b13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import essential libraries for model \n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ce1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_fold(i, train_df, test_df):\n",
    "    # firstly get the train and test df\n",
    "    print(f\"Loading the data frame from fold {i}\")\n",
    "    \n",
    "    # secondly create 25 beacon vector features \n",
    "    print(\"Adding 25 beacon vector features for both set\")\n",
    "    train_df = add_beacon_features(train_df)\n",
    "    test_df = add_beacon_features(test_df)\n",
    "\n",
    "    # apply windowing to both of the set \n",
    "    print(\"Applying windowing for both sets\")\n",
    "    windowed_train_df = aggregate_by_timestamp(train_df)\n",
    "    windowed_test_df = aggregate_by_timestamp(test_df)\n",
    "\n",
    "    # prepare training data\n",
    "    feature_cols = [col for col in windowed_train_df.columns \n",
    "                    if col not in ['room', 'timestamp']]\n",
    "\n",
    "    X_train = windowed_train_df[feature_cols]\n",
    "    y_train = windowed_train_df['room']\n",
    "\n",
    "    # Encode labels for XGBoost (XGBoost requires numeric labels)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "    # =====================================================================\n",
    "    # IDENTIFY 3 MOST MINORITY CLASSES AND APPLY 3X WEIGHTS\n",
    "    # =====================================================================\n",
    "    \n",
    "    # Get class distribution\n",
    "    class_counts = y_train.value_counts()\n",
    "    \n",
    "    # Identify 3 most minority classes (smallest counts)\n",
    "    minority_classes = class_counts.nsmallest(3).index.tolist()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CLASS DISTRIBUTION IN FOLD {i}:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(class_counts.to_string())\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"3 MOST MINORITY CLASSES:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for idx, minority_class in enumerate(minority_classes, 1):\n",
    "        count = class_counts[minority_class]\n",
    "        percentage = (count / len(y_train)) * 100\n",
    "        print(f\"{idx}. {minority_class:20s}: {count:5d} samples ({percentage:5.2f}%)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Calculate base balanced weights\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_encoded)\n",
    "    \n",
    "    # Apply 3x multiplier to the 3 most minority classes\n",
    "    for minority_class in minority_classes:\n",
    "        minority_mask = y_train == minority_class\n",
    "        sample_weights[minority_mask] *= 3.0\n",
    "    \n",
    "    print(f\"✓ Applied 3x weight multiplier to minority classes\")\n",
    "    print(f\"  Minority classes: {minority_classes}\\n\")\n",
    "\n",
    "    # Train XGBoost with parameters optimized for macro F1\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        gamma=0,\n",
    "        reg_alpha=0,\n",
    "        reg_lambda=1,\n",
    "        objective='multi:softmax',\n",
    "        num_class=len(y_train.unique()),\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method='hist'\n",
    "    )\n",
    "\n",
    "    print(\"Training XGBoost...\")\n",
    "    xgb_model.fit(\n",
    "        X_train, \n",
    "        y_train_encoded,\n",
    "        sample_weight=sample_weights\n",
    "    )\n",
    "    print(\"Training completed!\")\n",
    "    \n",
    "    # Prepare test data\n",
    "    X_test = windowed_test_df[feature_cols]\n",
    "    y_test = windowed_test_df['room']\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    \n",
    "    # Make predictions\n",
    "    print(\"Making predictions...\")\n",
    "    y_pred_encoded = xgb_model.predict(X_test)\n",
    "    y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "    \n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Calculate per-class F1 scores\n",
    "    per_class_f1 = f1_score(y_test, y_pred, average=None, labels=label_encoder.classes_)\n",
    "    per_class_f1_dict = {label: f1 for label, f1 in zip(label_encoder.classes_, per_class_f1)}\n",
    "    \n",
    "    print(f\"Fold {i} - Macro F1 Score: {macro_f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'fold': i,\n",
    "        'macro_f1': macro_f1,\n",
    "        'per_class_f1': per_class_f1_dict,\n",
    "        'classes': label_encoder.classes_,\n",
    "        'minority_classes': minority_classes,\n",
    "        'class_counts': class_counts.to_dict()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d0c93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROCESSING FOLD 1\n",
      "================================================================================\n",
      "\n",
      "Loading the data frame from fold 1\n",
      "Adding 25 beacon vector features for both set\n",
      "Applying windowing for both sets\n",
      "Total windows after aggregation: 19280\n",
      "Removed 0 empty windows (all beacons = 0)\n",
      "Features: 25 beacons × 5 statistics = 125 features\n",
      "Total windows after aggregation: 2481\n",
      "Removed 0 empty windows (all beacons = 0)\n",
      "Features: 25 beacons × 5 statistics = 125 features\n",
      "\n",
      "============================================================\n",
      "CLASS DISTRIBUTION IN FOLD 1:\n",
      "============================================================\n",
      "room\n",
      "nurse station    8487\n",
      "kitchen          4588\n",
      "cafeteria        4568\n",
      "cleaning          583\n",
      "523               342\n",
      "520               260\n",
      "513               195\n",
      "506               162\n",
      "515                39\n",
      "518                18\n",
      "508                17\n",
      "517                17\n",
      "505                 4\n",
      "\n",
      "============================================================\n",
      "3 MOST MINORITY CLASSES:\n",
      "============================================================\n",
      "1. 505                 :     4 samples ( 0.02%)\n",
      "2. 508                 :    17 samples ( 0.09%)\n",
      "3. 517                 :    17 samples ( 0.09%)\n",
      "============================================================\n",
      "\n",
      "✓ Applied 3x weight multiplier to minority classes\n",
      "  Minority classes: ['505', '508', '517']\n",
      "\n",
      "Training XGBoost...\n",
      "Training completed!\n",
      "Making predictions...\n",
      "Fold 1 - Macro F1 Score: 0.2803\n",
      "\n",
      "================================================================================\n",
      "PROCESSING FOLD 2\n",
      "================================================================================\n",
      "\n",
      "Loading the data frame from fold 2\n",
      "Adding 25 beacon vector features for both set\n",
      "Applying windowing for both sets\n",
      "Total windows after aggregation: 17506\n",
      "Removed 0 empty windows (all beacons = 0)\n",
      "Features: 25 beacons × 5 statistics = 125 features\n",
      "Total windows after aggregation: 5932\n",
      "Removed 0 empty windows (all beacons = 0)\n",
      "Features: 25 beacons × 5 statistics = 125 features\n",
      "\n",
      "============================================================\n",
      "CLASS DISTRIBUTION IN FOLD 2:\n",
      "============================================================\n",
      "room\n",
      "nurse station    8098\n",
      "cafeteria        3614\n",
      "kitchen          3470\n",
      "hallway           620\n",
      "523               369\n",
      "cleaning          213\n",
      "515               192\n",
      "522               181\n",
      "506               160\n",
      "512               159\n",
      "520               121\n",
      "511                96\n",
      "513                80\n",
      "501                50\n",
      "505                29\n",
      "517                23\n",
      "518                22\n",
      "502                 9\n",
      "\n",
      "============================================================\n",
      "3 MOST MINORITY CLASSES:\n",
      "============================================================\n",
      "1. 502                 :     9 samples ( 0.05%)\n",
      "2. 518                 :    22 samples ( 0.13%)\n",
      "3. 517                 :    23 samples ( 0.13%)\n",
      "============================================================\n",
      "\n",
      "✓ Applied 3x weight multiplier to minority classes\n",
      "  Minority classes: ['502', '518', '517']\n",
      "\n",
      "Training XGBoost...\n",
      "Training completed!\n",
      "Making predictions...\n",
      "Fold 2 - Macro F1 Score: 0.2504\n",
      "\n",
      "================================================================================\n",
      "PROCESSING FOLD 3\n",
      "================================================================================\n",
      "\n",
      "Loading the data frame from fold 3\n",
      "Adding 25 beacon vector features for both set\n",
      "Applying windowing for both sets\n",
      "Total windows after aggregation: 15136\n",
      "Removed 0 empty windows (all beacons = 0)\n",
      "Features: 25 beacons × 5 statistics = 125 features\n",
      "Total windows after aggregation: 7739\n",
      "Removed 0 empty windows (all beacons = 0)\n",
      "Features: 25 beacons × 5 statistics = 125 features\n",
      "\n",
      "============================================================\n",
      "CLASS DISTRIBUTION IN FOLD 3:\n",
      "============================================================\n",
      "room\n",
      "nurse station    5606\n",
      "cafeteria        3380\n",
      "kitchen          3309\n",
      "hallway           926\n",
      "cleaning          634\n",
      "523               398\n",
      "520               276\n",
      "513               245\n",
      "512               133\n",
      "511                93\n",
      "502                69\n",
      "518                30\n",
      "522                17\n",
      "516                10\n",
      "517                10\n",
      "\n",
      "============================================================\n",
      "3 MOST MINORITY CLASSES:\n",
      "============================================================\n",
      "1. 516                 :    10 samples ( 0.07%)\n",
      "2. 517                 :    10 samples ( 0.07%)\n",
      "3. 522                 :    17 samples ( 0.11%)\n",
      "============================================================\n",
      "\n",
      "✓ Applied 3x weight multiplier to minority classes\n",
      "  Minority classes: ['516', '517', '522']\n",
      "\n",
      "Training XGBoost...\n",
      "Training completed!\n",
      "Making predictions...\n",
      "Fold 3 - Macro F1 Score: 0.2652\n",
      "\n",
      "================================================================================\n",
      "PROCESSING FOLD 4\n",
      "================================================================================\n",
      "\n",
      "Loading the data frame from fold 4\n",
      "Adding 25 beacon vector features for both set\n",
      "Applying windowing for both sets\n",
      "Total windows after aggregation: 15000\n",
      "Removed 0 empty windows (all beacons = 0)\n",
      "Features: 25 beacons × 5 statistics = 125 features\n",
      "Total windows after aggregation: 7353\n",
      "Removed 0 empty windows (all beacons = 0)\n",
      "Features: 25 beacons × 5 statistics = 125 features\n",
      "\n",
      "============================================================\n",
      "CLASS DISTRIBUTION IN FOLD 4:\n",
      "============================================================\n",
      "room\n",
      "nurse station    5898\n",
      "kitchen          4152\n",
      "cafeteria        3024\n",
      "cleaning          634\n",
      "hallway           346\n",
      "523               328\n",
      "520               276\n",
      "506               192\n",
      "511                95\n",
      "508                27\n",
      "501                15\n",
      "516                13\n",
      "\n",
      "============================================================\n",
      "3 MOST MINORITY CLASSES:\n",
      "============================================================\n",
      "1. 516                 :    13 samples ( 0.09%)\n",
      "2. 501                 :    15 samples ( 0.10%)\n",
      "3. 508                 :    27 samples ( 0.18%)\n",
      "============================================================\n",
      "\n",
      "✓ Applied 3x weight multiplier to minority classes\n",
      "  Minority classes: ['516', '501', '508']\n",
      "\n",
      "Training XGBoost...\n",
      "Training completed!\n",
      "Making predictions...\n",
      "Fold 4 - Macro F1 Score: 0.3394\n",
      "\n",
      "================================================================================\n",
      "ALL FOLDS COMPLETED!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate all folds\n",
    "results = {}\n",
    "\n",
    "folds = {\n",
    "    1: (train_df_1, test_df_1),\n",
    "    2: (train_df_2, test_df_2),\n",
    "    3: (train_df_3, test_df_3),\n",
    "    4: (train_df_4, test_df_4)\n",
    "}\n",
    "\n",
    "for fold_num, (train_df, test_df) in folds.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PROCESSING FOLD {fold_num}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    result = train_evaluate_fold(fold_num, train_df, test_df)\n",
    "    results[fold_num] = result\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL FOLDS COMPLETED!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ead34213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Results saved to pipeline_minor_weighting.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save results to text file\n",
    "with open('pipeline_minor_weighting.txt', 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"CROSS-VALIDATION RESULTS - WITH 3X MINORITY CLASS WEIGHTING\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    # Overall macro F1 scores\n",
    "    f.write(\"MACRO F1 SCORES PER FOLD:\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    for fold_num in [1, 2, 3, 4]:\n",
    "        f.write(f\"Fold {fold_num}: {results[fold_num]['macro_f1']:.4f}\\n\")\n",
    "    \n",
    "    # Calculate mean and std\n",
    "    macro_f1_scores = [results[i]['macro_f1'] for i in [1, 2, 3, 4]]\n",
    "    mean_f1 = np.mean(macro_f1_scores)\n",
    "    std_f1 = np.std(macro_f1_scores)\n",
    "    \n",
    "    f.write(f\"\\nMean Macro F1: {mean_f1:.4f} ± {std_f1:.4f}\\n\")\n",
    "    f.write(f\"Min: {np.min(macro_f1_scores):.4f}, Max: {np.max(macro_f1_scores):.4f}\\n\")\n",
    "    \n",
    "    # Minority classes information\n",
    "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    f.write(\"MINORITY CLASSES (RECEIVED 3X WEIGHT MULTIPLIER)\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    for fold_num in [1, 2, 3, 4]:\n",
    "        f.write(f\"\\nFold {fold_num}:\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        minority_classes = results[fold_num]['minority_classes']\n",
    "        class_counts = results[fold_num]['class_counts']\n",
    "        for minority_class in minority_classes:\n",
    "            count = class_counts[minority_class]\n",
    "            f.write(f\"{minority_class:20s}: {count:5d} samples\\n\")\n",
    "    \n",
    "    # Per-class F1 scores for each fold\n",
    "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    f.write(\"PER-CLASS F1 SCORES\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    for fold_num in [1, 2, 3, 4]:\n",
    "        f.write(f\"\\nFold {fold_num}:\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        per_class = results[fold_num]['per_class_f1']\n",
    "        minority_classes = results[fold_num]['minority_classes']\n",
    "        for class_name in sorted(per_class.keys()):\n",
    "            marker = \" [MINORITY - 3X WEIGHT]\" if class_name in minority_classes else \"\"\n",
    "            f.write(f\"{class_name:20s}: {per_class[class_name]:.4f}{marker}\\n\")\n",
    "\n",
    "print(\"✅ Results saved to pipeline_minor_weighting.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65808e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Fold 1: Macro F1 = 0.2803\n",
      "  Minority classes (3x weight): ['505', '508', '517']\n",
      "\n",
      "Fold 2: Macro F1 = 0.2504\n",
      "  Minority classes (3x weight): ['502', '518', '517']\n",
      "\n",
      "Fold 3: Macro F1 = 0.2652\n",
      "  Minority classes (3x weight): ['516', '517', '522']\n",
      "\n",
      "Fold 4: Macro F1 = 0.3394\n",
      "  Minority classes (3x weight): ['516', '501', '508']\n",
      "\n",
      "================================================================================\n",
      "Mean Macro F1: 0.2838 ± 0.0338\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for fold_num in [1, 2, 3, 4]:\n",
    "    print(f\"\\nFold {fold_num}: Macro F1 = {results[fold_num]['macro_f1']:.4f}\")\n",
    "    print(f\"  Minority classes (3x weight): {results[fold_num]['minority_classes']}\")\n",
    "\n",
    "macro_f1_scores = [results[i]['macro_f1'] for i in [1, 2, 3, 4]]\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Mean Macro F1: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nr8IDTbvvtX",
        "outputId": "6af1277e-4d85-4c6c-a7f2-f058cc0b195a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Input, Multiply, Permute, Reshape, Lambda\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from tensorflow.keras.layers import Bidirectional, GRU, Layer\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úì All imports successful\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdWWerAxvvvd",
        "outputId": "49b87d27-2fd5-4360-d2af-6ddfdfef028f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì All imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    Custom Attention Layer for Sequence Models\n",
        "\n",
        "    This layer learns which timesteps in the sequence are most important\n",
        "    for the classification task. It computes attention weights and returns\n",
        "    a weighted sum of the input sequence.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # input_shape: (batch_size, timesteps, features)\n",
        "        self.W = self.add_weight(\n",
        "            name='attention_weight',\n",
        "            shape=(input_shape[-1], 1),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            name='attention_bias',\n",
        "            shape=(1,),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        # inputs shape: (batch_size, timesteps, features)\n",
        "\n",
        "        # Compute attention scores: (batch_size, timesteps, 1)\n",
        "        attention_scores = K.tanh(K.dot(inputs, self.W) + self.b)\n",
        "\n",
        "        # Apply mask if provided (for padded sequences)\n",
        "        if mask is not None:\n",
        "            # Expand mask to match attention_scores shape\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            mask = K.expand_dims(mask, axis=-1)\n",
        "            # Set masked positions to very negative value\n",
        "            attention_scores = attention_scores * mask + (1 - mask) * (-1e10)\n",
        "\n",
        "        # Compute attention weights: (batch_size, timesteps, 1)\n",
        "        attention_weights = K.softmax(attention_scores, axis=1)\n",
        "\n",
        "        # Compute weighted sum: (batch_size, features)\n",
        "        context_vector = K.sum(inputs * attention_weights, axis=1)\n",
        "\n",
        "        return context_vector\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        # Output shape: (batch_size, features)\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "    def get_config(self):\n",
        "        return super(AttentionLayer, self).get_config()\n",
        "\n",
        "print(\"‚úÖ Custom Attention Layer defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvyce5W9vvyP",
        "outputId": "5a0b5953-23a6-4136-b5e1-519ee7332dca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Custom Attention Layer defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_filter_fold(i):\n",
        "    train_dir = f'/content/drive/MyDrive/split_data/fold{i}/train.csv'\n",
        "    test_dir = f'/content/drive/MyDrive/split_data/fold{i}/test.csv'\n",
        "    train_df = pd.read_csv(train_dir)\n",
        "    test_df = pd.read_csv(test_dir)\n",
        "\n",
        "    train_labels = list(train_df['room'].unique())\n",
        "    test_labels = list(test_df['room'].unique())\n",
        "    common_labels = list(set(train_labels) & set(test_labels))\n",
        "\n",
        "    train_df = train_df[train_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "    test_df = test_df[test_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Load all 4 folds\n",
        "train_df_1, test_df_1 = load_and_filter_fold(1)\n",
        "train_df_2, test_df_2 = load_and_filter_fold(2)\n",
        "train_df_3, test_df_3 = load_and_filter_fold(3)\n",
        "train_df_4, test_df_4 = load_and_filter_fold(4)\n",
        "\n",
        "print(\"‚úì All folds loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1CIs3c8vv0m",
        "outputId": "e60e1ece-86cc-4ce5-9b9b-8b1e036432e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì All folds loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "def create_room_groups(df):\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    df['room_group'] = (df['room'] != df['room'].shift()).cumsum()\n",
        "    return df\n",
        "\n",
        "def create_beacon_count_vectors(df):\n",
        "    \"\"\"Aggregates readings into 1s vectors. Handles data with or without 'room_group'.\"\"\"\n",
        "    vectors = []\n",
        "    has_groups = 'room_group' in df.columns\n",
        "\n",
        "    for _, group in df.groupby('timestamp'):\n",
        "        beacon_counts = group['mac address'].value_counts()\n",
        "        total_readings = len(group)\n",
        "\n",
        "        vector = [0.0] * 23\n",
        "        for beacon_id, count in beacon_counts.items():\n",
        "            if 1 <= beacon_id <= 23:\n",
        "                vector[int(beacon_id) - 1] = count / total_readings\n",
        "\n",
        "        entry = {\n",
        "            'timestamp': group['timestamp'].iloc[0],\n",
        "            'room': group['room'].iloc[0],\n",
        "            'beacon_vector': vector\n",
        "        }\n",
        "\n",
        "        if has_groups:\n",
        "            entry['room_group'] = group['room_group'].iloc[0]\n",
        "\n",
        "        vectors.append(entry)\n",
        "\n",
        "    return pd.DataFrame(vectors)\n",
        "\n",
        "def create_sequences_from_groups(vector_df, min_length=3, max_length=50):\n",
        "    \"\"\"Used for Training: Creates clean sequences where the room is constant.\"\"\"\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for (room, room_group), group in vector_df.groupby(['room', 'room_group']):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=False)\n",
        "        seq_length = len(group)\n",
        "\n",
        "        if seq_length < min_length:\n",
        "            continue\n",
        "\n",
        "        if seq_length > max_length:\n",
        "            group = group.tail(max_length)\n",
        "\n",
        "        sequence = [row['beacon_vector'] for _, row in group.iterrows()]\n",
        "        sequences.append(sequence)\n",
        "        labels.append(room)\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "print(\"‚úÖ Basic functions defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWxEgSlJvv3l",
        "outputId": "fb23ed26-e4e6-48cc-b95f-9c8b48c64b3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Basic functions defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bidirectional_gru_model_with_deep_attention(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Deep Bidirectional GRU Architecture with Attention\n",
        "\n",
        "    Architecture:\n",
        "    1. Masking layer\n",
        "    2. First Bi-GRU (128 units) with return_sequences=True\n",
        "    3. Dropout (0.3)\n",
        "    4. Second Bi-GRU (64 units) with return_sequences=True\n",
        "    5. Dropout (0.3)\n",
        "    6. Attention Layer - aggregates the deep sequence features\n",
        "    7. Dense layers + Output\n",
        "\n",
        "    This version keeps both Bi-GRU layers and adds attention on top.\n",
        "    Proven to be the most stable architecture.\n",
        "    \"\"\"\n",
        "    inputs = Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "    # Masking for padded sequences\n",
        "    masked = Masking(mask_value=0.0, name='masking')(inputs)\n",
        "\n",
        "    # First Bi-GRU layer\n",
        "    gru1 = Bidirectional(\n",
        "        GRU(128, return_sequences=True, name='gru_layer_1'),\n",
        "        name='bidirectional_gru_1'\n",
        "    )(masked)\n",
        "    gru1 = Dropout(0.3, name='dropout_1')(gru1)\n",
        "\n",
        "    # Second Bi-GRU layer\n",
        "    gru2 = Bidirectional(\n",
        "        GRU(64, return_sequences=True, name='gru_layer_2'),\n",
        "        name='bidirectional_gru_2'\n",
        "    )(gru1)\n",
        "    gru2 = Dropout(0.3, name='dropout_2')(gru2)\n",
        "\n",
        "    # Attention mechanism\n",
        "    attention_output = AttentionLayer(name='attention_layer')(gru2)\n",
        "\n",
        "    # Dense layers for classification\n",
        "    dense1 = Dense(32, activation='relu', name='dense_1')(attention_output)\n",
        "    dense1 = Dropout(0.2, name='dropout_3')(dense1)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(num_classes, activation='softmax', name='output_layer')(dense1)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='Deep_BiGRU_with_Attention')\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"‚úÖ Deep Attention model architecture defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pFGfkyAvv6t",
        "outputId": "a67adc15-62f5-4c88-97ee-31a5bdc28f2c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Deep Attention model architecture defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_extended_multidirectional_windows(vector_df):\n",
        "    \"\"\"\n",
        "    Create 7 types of sliding windows for extended multi-directional prediction\n",
        "\n",
        "    Directions:\n",
        "    1. backward_10:  [i-9 to i]     - 10s history, predict at i\n",
        "    2. centered_10:  [i-4 to i+5]   - 10s centered, predict at i\n",
        "    3. forward_10:   [i to i+9]     - 10s future, predict at i\n",
        "    4. backward_15:  [i-14 to i]    - 15s history (more context)\n",
        "    5. forward_15:   [i to i+14]    - 15s future (earlier transition detection)\n",
        "    6. asymm_past:   [i-11 to i+3]  - 12s past + 4s future (transition from old room)\n",
        "    7. asymm_future: [i-3 to i+11]  - 4s past + 12s future (entering new room)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with direction names as keys\n",
        "        Each contains: (sequences, labels, valid_indices)\n",
        "    \"\"\"\n",
        "    # Ensure chronological order and group by day\n",
        "    vector_df['dt'] = pd.to_datetime(vector_df['timestamp'])\n",
        "    vector_df['date'] = vector_df['dt'].dt.date\n",
        "\n",
        "    results = {\n",
        "        'backward_10': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'centered_10': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'forward_10': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'backward_15': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'forward_15': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'asymm_past': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'asymm_future': {'sequences': [], 'labels': [], 'indices': []},\n",
        "    }\n",
        "\n",
        "    for _, day_group in vector_df.groupby('date'):\n",
        "        day_group = day_group.sort_values('timestamp').reset_index(drop=True)\n",
        "        vectors = list(day_group['beacon_vector'])\n",
        "        rooms = list(day_group['room'])\n",
        "        n = len(vectors)\n",
        "\n",
        "        for i in range(n):\n",
        "            if i >= 9:\n",
        "                window = vectors[i - 9 : i + 1]\n",
        "                results['backward_10']['sequences'].append(window)\n",
        "                results['backward_10']['labels'].append(rooms[i])\n",
        "                results['backward_10']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            if i >= 4 and i + 5 < n:\n",
        "                window = vectors[i - 4 : i + 6]\n",
        "                results['centered_10']['sequences'].append(window)\n",
        "                results['centered_10']['labels'].append(rooms[i])\n",
        "                results['centered_10']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            if i + 9 < n:\n",
        "                window = vectors[i : i + 10]\n",
        "                results['forward_10']['sequences'].append(window)\n",
        "                results['forward_10']['labels'].append(rooms[i])\n",
        "                results['forward_10']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            if i >= 14:\n",
        "                window = vectors[i - 14 : i + 1]\n",
        "                results['backward_15']['sequences'].append(window)\n",
        "                results['backward_15']['labels'].append(rooms[i])\n",
        "                results['backward_15']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            if i + 14 < n:\n",
        "                window = vectors[i : i + 15]\n",
        "                results['forward_15']['sequences'].append(window)\n",
        "                results['forward_15']['labels'].append(rooms[i])\n",
        "                results['forward_15']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            if i >= 11 and i + 3 < n:\n",
        "                window = vectors[i - 11 : i + 4]\n",
        "                results['asymm_past']['sequences'].append(window)\n",
        "                results['asymm_past']['labels'].append(rooms[i])\n",
        "                results['asymm_past']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            if i >= 3 and i + 11 < n:\n",
        "                window = vectors[i - 3 : i + 12]\n",
        "                results['asymm_future']['sequences'].append(window)\n",
        "                results['asymm_future']['labels'].append(rooms[i])\n",
        "                results['asymm_future']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"‚úÖ Extended multi-directional window function defined (7 directions)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2aPKC6ivv9m",
        "outputId": "b48c4282-9aec-44c8-9506-71445f14f34a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extended multi-directional window function defined (7 directions)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ensemble_models_with_seeds(train_df, seed_list, verbose=False):\n",
        "    \"\"\"\n",
        "    Train ONE model for EACH seed in seed_list\n",
        "\n",
        "    Args:\n",
        "        train_df: Training dataframe\n",
        "        seed_list: List of seeds (e.g., [42, 1009, 2503, 4001, 5501, 7507, 9001])\n",
        "        verbose: Print progress\n",
        "\n",
        "    Returns:\n",
        "        models: List of trained models (one per seed)\n",
        "        label_encoder: Fitted label encoder\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(f\"  Training {len(seed_list)} models (one per seed)...\")\n",
        "\n",
        "    # Prepare data (same for all models)\n",
        "    train_df_grouped = create_room_groups(train_df)\n",
        "    train_vector_df = create_beacon_count_vectors(train_df_grouped)\n",
        "    X_train_seq, y_train_labels = create_sequences_from_groups(train_vector_df, max_length=50)\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train = label_encoder.fit_transform(y_train_labels)\n",
        "\n",
        "    # Pad sequences\n",
        "    X_train_padded = pad_sequences(X_train_seq, maxlen=50, padding='post', dtype='float32', value=0.0)\n",
        "\n",
        "    # Compute class weights\n",
        "    class_weights_array = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
        "\n",
        "    # Train one model per seed\n",
        "    models = []\n",
        "    for seed in seed_list:\n",
        "        set_seeds(seed)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"    Training model with seed {seed:5d}...\", end=\" \")\n",
        "\n",
        "        # Build deep attention model\n",
        "        model = build_bidirectional_gru_model_with_deep_attention(\n",
        "            input_shape=(50, 23),\n",
        "            num_classes=len(label_encoder.classes_)\n",
        "        )\n",
        "\n",
        "        # Callbacks\n",
        "        early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True, verbose=0)\n",
        "        reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, verbose=0, min_lr=1e-6)\n",
        "\n",
        "        # Train\n",
        "        model.fit(\n",
        "            X_train_padded, y_train,\n",
        "            epochs=30,\n",
        "            batch_size=32,\n",
        "            class_weight=class_weights,\n",
        "            callbacks=[early_stop, reduce_lr],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        models.append(model)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"‚úì\")\n",
        "\n",
        "    return models, label_encoder\n",
        "\n",
        "print(\"‚úÖ Ensemble training function defined (one model per seed)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHTDwnmpvwAG",
        "outputId": "02b45169-84c1-4869-856c-ae4e454decc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ensemble training function defined (one model per seed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_direction(models, sequences, max_seq_length=50):\n",
        "    \"\"\"\n",
        "    Get ensemble predictions for a single direction\n",
        "\n",
        "    Args:\n",
        "        models: List of models (7 models from 7 seeds)\n",
        "        sequences: Input sequences to predict\n",
        "\n",
        "    Returns:\n",
        "        ensemble_proba: (n_samples, n_classes) averaged probability matrix\n",
        "    \"\"\"\n",
        "    # Pad sequences\n",
        "    X_padded = pad_sequences(sequences, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "\n",
        "    # Get predictions from all models\n",
        "    all_predictions = []\n",
        "    for model in models:\n",
        "        proba = model.predict(X_padded, verbose=0)\n",
        "        all_predictions.append(proba)\n",
        "\n",
        "    # Average probabilities across all 7 models\n",
        "    ensemble_proba = np.mean(all_predictions, axis=0)\n",
        "\n",
        "    return ensemble_proba\n",
        "\n",
        "def combine_directional_predictions(direction_results, method='confidence_weighted'):\n",
        "    \"\"\"\n",
        "    Combine predictions from multiple directions using confidence weighting\n",
        "\n",
        "    Args:\n",
        "        direction_results: Dict with keys for all 7 directions\n",
        "        method: 'confidence_weighted', 'equal', or 'softmax'\n",
        "\n",
        "    Returns:\n",
        "        combined_proba: (n_positions, n_classes) final probability matrix\n",
        "        position_map: mapping from (date, position) to array index\n",
        "    \"\"\"\n",
        "    all_positions = set()\n",
        "    direction_names = ['backward_10', 'centered_10', 'forward_10',\n",
        "                      'backward_15', 'forward_15',\n",
        "                      'asymm_past', 'asymm_future']\n",
        "\n",
        "    for direction in direction_names:\n",
        "        all_positions.update(direction_results[direction]['indices'])\n",
        "\n",
        "    all_positions = sorted(all_positions)\n",
        "    position_map = {pos: idx for idx, pos in enumerate(all_positions)}\n",
        "\n",
        "    n_classes = direction_results['backward_10']['proba'].shape[1]\n",
        "    n_positions = len(all_positions)\n",
        "\n",
        "    combined_proba = np.zeros((n_positions, n_classes))\n",
        "    position_counts = np.zeros(n_positions)\n",
        "\n",
        "    for direction_name in direction_names:\n",
        "        direction_data = direction_results[direction_name]\n",
        "        proba = direction_data['proba']\n",
        "        indices = direction_data['indices']\n",
        "\n",
        "        confidences = np.max(proba, axis=1)\n",
        "\n",
        "        for i, pos in enumerate(indices):\n",
        "            pos_idx = position_map[pos]\n",
        "\n",
        "            if method == 'confidence_weighted':\n",
        "                weight = confidences[i]\n",
        "                combined_proba[pos_idx] += proba[i] * weight\n",
        "            elif method == 'equal':\n",
        "                combined_proba[pos_idx] += proba[i]\n",
        "\n",
        "            position_counts[pos_idx] += 1 if method == 'equal' else confidences[i]\n",
        "\n",
        "    for i in range(n_positions):\n",
        "        if position_counts[i] > 0:\n",
        "            combined_proba[i] /= position_counts[i]\n",
        "\n",
        "    return combined_proba, position_map\n",
        "\n",
        "print(\"‚úÖ Multi-directional prediction functions defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuTfYxdKvwDN",
        "outputId": "7bc4bc87-79f0-46b5-a2e7-624da48bb9bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Multi-directional prediction functions defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_confidence_weighted_voting(predictions_proba, vote_window=5):\n",
        "    \"\"\"\n",
        "    Confidence-weighted temporal voting\n",
        "\n",
        "    Args:\n",
        "        predictions_proba: (n_samples, n_classes) probability matrix\n",
        "        vote_window: window size for voting\n",
        "\n",
        "    Returns:\n",
        "        voted_predictions: (n_samples,) final class predictions\n",
        "    \"\"\"\n",
        "    n_samples, n_classes = predictions_proba.shape\n",
        "    voted_predictions = np.zeros(n_samples, dtype=int)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        half_window = vote_window // 2\n",
        "        start = max(0, i - half_window)\n",
        "        end = min(n_samples, i + half_window + 1)\n",
        "\n",
        "        window_proba = predictions_proba[start:end]\n",
        "        window_confidences = np.max(window_proba, axis=1)\n",
        "\n",
        "        weighted_votes = np.zeros(n_classes)\n",
        "        for j in range(len(window_proba)):\n",
        "            weighted_votes += window_proba[j] * window_confidences[j]\n",
        "\n",
        "        voted_predictions[i] = np.argmax(weighted_votes)\n",
        "\n",
        "    return voted_predictions\n",
        "\n",
        "print(\"‚úÖ Temporal voting function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adqcLsffvwGJ",
        "outputId": "f5357480-92df-4c15-9899-91776ed24f37"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Temporal voting function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_final_pipeline(train_df, test_df, seed_list,\n",
        "                       vote_window=5,\n",
        "                       combination_method='confidence_weighted',\n",
        "                       verbose=False):\n",
        "    \"\"\"\n",
        "    FINAL PIPELINE: 7 seeds ‚Üí 7 models ‚Üí Ensemble\n",
        "\n",
        "    Pipeline:\n",
        "    1. Train 7 models (one per seed) with DEEP ATTENTION\n",
        "    2. Create 7 directional windows\n",
        "    3. Get predictions for each direction (all 7 models ensemble)\n",
        "    4. Combine directions using confidence weighting\n",
        "    5. Apply temporal voting\n",
        "\n",
        "    Args:\n",
        "        seed_list: List of 7 seeds (e.g., [42, 1009, 2503, 4001, 5501, 7507, 9001])\n",
        "        vote_window: Temporal voting window size\n",
        "        combination_method: 'confidence_weighted' or 'equal'\n",
        "    \"\"\"\n",
        "    # Clear session\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n  Training {len(seed_list)} models with optimized seeds...\")\n",
        "\n",
        "    # 1. Train 7 Models (one per seed)\n",
        "    models, label_encoder = train_ensemble_models_with_seeds(\n",
        "        train_df,\n",
        "        seed_list=seed_list,\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "    if verbose:\n",
        "        print(\"  Creating extended multi-directional windows (7 directions)...\")\n",
        "\n",
        "    # 2. Prepare Test Data with Multi-Directional Windows\n",
        "    test_vectors = create_beacon_count_vectors(test_df)\n",
        "    direction_windows = create_extended_multidirectional_windows(test_vectors)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"  Getting directional predictions (7 models ensemble per direction)...\")\n",
        "\n",
        "    # 3. Get Predictions for Each Direction (all 7 models vote)\n",
        "    direction_results = {}\n",
        "    direction_names = ['backward_10', 'centered_10', 'forward_10',\n",
        "                      'backward_15', 'forward_15',\n",
        "                      'asymm_past', 'asymm_future']\n",
        "\n",
        "    for direction_name in direction_names:\n",
        "        if verbose:\n",
        "            print(f\"    Predicting {direction_name}...\", end=\" \")\n",
        "\n",
        "        sequences = direction_windows[direction_name]['sequences']\n",
        "        # All 7 models predict and ensemble here\n",
        "        proba = predict_single_direction(models, sequences, max_seq_length=50)\n",
        "\n",
        "        direction_results[direction_name] = {\n",
        "            'proba': proba,\n",
        "            'indices': direction_windows[direction_name]['indices'],\n",
        "            'labels': direction_windows[direction_name]['labels']\n",
        "        }\n",
        "\n",
        "        if verbose:\n",
        "            avg_conf = np.mean(np.max(proba, axis=1))\n",
        "            print(f\"avg confidence: {avg_conf:.3f}\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  Combining 7 directions using {combination_method}...\")\n",
        "\n",
        "    # 4. Combine Directional Predictions\n",
        "    combined_proba, position_map = combine_directional_predictions(\n",
        "        direction_results,\n",
        "        method=combination_method\n",
        "    )\n",
        "\n",
        "    # Get ground truth labels\n",
        "    y_test = []\n",
        "    for pos in sorted(position_map.keys()):\n",
        "        for direction_name in direction_names:\n",
        "            if pos in direction_results[direction_name]['indices']:\n",
        "                idx = direction_results[direction_name]['indices'].index(pos)\n",
        "                y_test.append(direction_results[direction_name]['labels'][idx])\n",
        "                break\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  Applying temporal voting (window={vote_window})...\")\n",
        "\n",
        "    # 5. Apply Confidence-Weighted Temporal Voting\n",
        "    y_pred_voted_encoded = apply_confidence_weighted_voting(combined_proba, vote_window=vote_window)\n",
        "    y_pred = label_encoder.inverse_transform(y_pred_voted_encoded)\n",
        "\n",
        "    # 6. Final Evaluation\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    per_class_f1 = f1_score(y_test, y_pred, average=None, labels=label_encoder.classes_, zero_division=0)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  ‚úì Macro F1: {macro_f1:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'macro_f1': macro_f1,\n",
        "        'per_class_f1': {label: f1 for label, f1 in zip(label_encoder.classes_, per_class_f1)},\n",
        "        'combination_method': combination_method,\n",
        "        'n_models': len(seed_list)\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Complete final pipeline defined (7 seeds ‚Üí 7 models ‚Üí ensemble)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUlRCp-6vwI-",
        "outputId": "409cff12-0348-486e-96f9-ff01028f49c4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Complete final pipeline defined (7 seeds ‚Üí 7 models ‚Üí ensemble)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Citkx7TmvwL-",
        "outputId": "b1e70737-68ff-4af2-d0e6-f2c2bc1a0ffb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7GUV5EeJvwOm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üèÜ OPTIMIZED PRIME SEEDS (Winner from seed optimization)\n",
        "OPTIMIZED_SEEDS = [42, 1009, 2503, 4001, 5501, 7507, 9001]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"FINAL EXPERIMENT: 7-MODEL ENSEMBLE WITH OPTIMIZED SEEDS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nSeeds: {OPTIMIZED_SEEDS}\")\n",
        "print(f\"Strategy: Each seed ‚Üí 1 model ‚Üí All 7 ensemble together\")\n",
        "print(f\"Architecture: Deep Bidirectional GRU with Attention\")\n",
        "print(f\"Directions: 7 (backward_10, centered_10, forward_10, backward_15, forward_15, asymm_past, asymm_future)\")\n",
        "print(f\"Temporal voting: 5-second window\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "folds = {\n",
        "    1: (train_df_1, test_df_1),\n",
        "    2: (train_df_2, test_df_2),\n",
        "    3: (train_df_3, test_df_3),\n",
        "    4: (train_df_4, test_df_4)\n",
        "}\n",
        "\n",
        "all_fold_results = {}\n",
        "\n",
        "for fold_num, (train_df, test_df) in folds.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"PROCESSING FOLD {fold_num}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    result = run_final_pipeline(\n",
        "        train_df, test_df,\n",
        "        seed_list=OPTIMIZED_SEEDS,\n",
        "        vote_window=5,\n",
        "        combination_method='confidence_weighted',\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    all_fold_results[fold_num] = result\n",
        "\n",
        "    print(f\"\\n  Fold {fold_num} Result: Macro F1 = {result['macro_f1']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ALL FOLDS COMPLETED!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bldeexFvwRl",
        "outputId": "1e83fe74-f274-42c5-ab7a-3ca47289ddda"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FINAL EXPERIMENT: 7-MODEL ENSEMBLE WITH OPTIMIZED SEEDS\n",
            "================================================================================\n",
            "\n",
            "Seeds: [42, 1009, 2503, 4001, 5501, 7507, 9001]\n",
            "Strategy: Each seed ‚Üí 1 model ‚Üí All 7 ensemble together\n",
            "Architecture: Deep Bidirectional GRU with Attention\n",
            "Directions: 7 (backward_10, centered_10, forward_10, backward_15, forward_15, asymm_past, asymm_future)\n",
            "Temporal voting: 5-second window\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 1\n",
            "================================================================================\n",
            "\n",
            "\n",
            "  Training 7 models with optimized seeds...\n",
            "  Training 7 models (one per seed)...\n",
            "    Training model with seed    42... ‚úì\n",
            "    Training model with seed  1009... ‚úì\n",
            "    Training model with seed  2503... ‚úì\n",
            "    Training model with seed  4001... ‚úì\n",
            "    Training model with seed  5501... ‚úì\n",
            "    Training model with seed  7507... ‚úì\n",
            "    Training model with seed  9001... ‚úì\n",
            "  Creating extended multi-directional windows (7 directions)...\n",
            "  Getting directional predictions (7 models ensemble per direction)...\n",
            "    Predicting backward_10... avg confidence: 0.609\n",
            "    Predicting centered_10... avg confidence: 0.609\n",
            "    Predicting forward_10... avg confidence: 0.609\n",
            "    Predicting backward_15... avg confidence: 0.648\n",
            "    Predicting forward_15... avg confidence: 0.648\n",
            "    Predicting asymm_past... avg confidence: 0.648\n",
            "    Predicting asymm_future... avg confidence: 0.648\n",
            "  Combining 7 directions using confidence_weighted...\n",
            "  Applying temporal voting (window=5)...\n",
            "  ‚úì Macro F1: 0.4773\n",
            "\n",
            "  Fold 1 Result: Macro F1 = 0.4773\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 2\n",
            "================================================================================\n",
            "\n",
            "\n",
            "  Training 7 models with optimized seeds...\n",
            "  Training 7 models (one per seed)...\n",
            "    Training model with seed    42... ‚úì\n",
            "    Training model with seed  1009... ‚úì\n",
            "    Training model with seed  2503... ‚úì\n",
            "    Training model with seed  4001... ‚úì\n",
            "    Training model with seed  5501... ‚úì\n",
            "    Training model with seed  7507... ‚úì\n",
            "    Training model with seed  9001... ‚úì\n",
            "  Creating extended multi-directional windows (7 directions)...\n",
            "  Getting directional predictions (7 models ensemble per direction)...\n",
            "    Predicting backward_10... avg confidence: 0.577\n",
            "    Predicting centered_10... avg confidence: 0.577\n",
            "    Predicting forward_10... avg confidence: 0.577\n",
            "    Predicting backward_15... avg confidence: 0.604\n",
            "    Predicting forward_15... avg confidence: 0.604\n",
            "    Predicting asymm_past... avg confidence: 0.604\n",
            "    Predicting asymm_future... avg confidence: 0.604\n",
            "  Combining 7 directions using confidence_weighted...\n",
            "  Applying temporal voting (window=5)...\n",
            "  ‚úì Macro F1: 0.4324\n",
            "\n",
            "  Fold 2 Result: Macro F1 = 0.4324\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 3\n",
            "================================================================================\n",
            "\n",
            "\n",
            "  Training 7 models with optimized seeds...\n",
            "  Training 7 models (one per seed)...\n",
            "    Training model with seed    42... ‚úì\n",
            "    Training model with seed  1009... ‚úì\n",
            "    Training model with seed  2503... ‚úì\n",
            "    Training model with seed  4001... ‚úì\n",
            "    Training model with seed  5501... ‚úì\n",
            "    Training model with seed  7507... ‚úì\n",
            "    Training model with seed  9001... ‚úì\n",
            "  Creating extended multi-directional windows (7 directions)...\n",
            "  Getting directional predictions (7 models ensemble per direction)...\n",
            "    Predicting backward_10... avg confidence: 0.601\n",
            "    Predicting centered_10... avg confidence: 0.601\n",
            "    Predicting forward_10... avg confidence: 0.601\n",
            "    Predicting backward_15... avg confidence: 0.645\n",
            "    Predicting forward_15... avg confidence: 0.645\n",
            "    Predicting asymm_past... avg confidence: 0.645\n",
            "    Predicting asymm_future... avg confidence: 0.645\n",
            "  Combining 7 directions using confidence_weighted...\n",
            "  Applying temporal voting (window=5)...\n",
            "  ‚úì Macro F1: 0.4240\n",
            "\n",
            "  Fold 3 Result: Macro F1 = 0.4240\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 4\n",
            "================================================================================\n",
            "\n",
            "\n",
            "  Training 7 models with optimized seeds...\n",
            "  Training 7 models (one per seed)...\n",
            "    Training model with seed    42... ‚úì\n",
            "    Training model with seed  1009... ‚úì\n",
            "    Training model with seed  2503... ‚úì\n",
            "    Training model with seed  4001... ‚úì\n",
            "    Training model with seed  5501... ‚úì\n",
            "    Training model with seed  7507... ‚úì\n",
            "    Training model with seed  9001... ‚úì\n",
            "  Creating extended multi-directional windows (7 directions)...\n",
            "  Getting directional predictions (7 models ensemble per direction)...\n",
            "    Predicting backward_10... avg confidence: 0.600\n",
            "    Predicting centered_10... avg confidence: 0.600\n",
            "    Predicting forward_10... avg confidence: 0.600\n",
            "    Predicting backward_15... avg confidence: 0.630\n",
            "    Predicting forward_15... avg confidence: 0.630\n",
            "    Predicting asymm_past... avg confidence: 0.630\n",
            "    Predicting asymm_future... avg confidence: 0.630\n",
            "  Combining 7 directions using confidence_weighted...\n",
            "  Applying temporal voting (window=5)...\n",
            "  ‚úì Macro F1: 0.4329\n",
            "\n",
            "  Fold 4 Result: Macro F1 = 0.4329\n",
            "\n",
            "================================================================================\n",
            "ALL FOLDS COMPLETED!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä FINAL RESULTS SUMMARY\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "fold_scores = [all_fold_results[i]['macro_f1'] for i in [1, 2, 3, 4]]\n",
        "\n",
        "print(\"PER-FOLD RESULTS:\")\n",
        "print(\"-\"*80)\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    score = all_fold_results[fold_num]['macro_f1']\n",
        "    print(f\"Fold {fold_num}: {score:.4f}\")\n",
        "\n",
        "overall_mean = np.mean(fold_scores)\n",
        "overall_std = np.std(fold_scores)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"OVERALL PERFORMANCE\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Mean Macro F1: {overall_mean:.4f} ¬± {overall_std:.4f}\")\n",
        "print(f\"Min: {np.min(fold_scores):.4f}\")\n",
        "print(f\"Max: {np.max(fold_scores):.4f}\")\n",
        "\n",
        "# Comparison to baselines\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"COMPARISON TO PREVIOUS APPROACHES\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "baseline_exp2 = 0.4384\n",
        "baseline_deep3seeds = 0.4438\n",
        "\n",
        "print(f\"\\nExperiment 2 (7 directions, no attention): 0.4384\")\n",
        "print(f\"Deep Attention (3 seeds √ó 5 models):      0.4438\")\n",
        "print(f\"Seed Optimization (7 seeds √ó 1 model):    0.4107 (unstable)\")\n",
        "print(f\"\\nüèÜ FINAL (7 seeds ‚Üí 7 models ensemble):    {overall_mean:.4f}\")\n",
        "\n",
        "improvement_from_exp2 = overall_mean - baseline_exp2\n",
        "improvement_from_deep = overall_mean - baseline_deep3seeds\n",
        "\n",
        "print(f\"\\nImprovement from Exp 2: {improvement_from_exp2:+.4f} ({improvement_from_exp2/baseline_exp2*100:+.2f}%)\")\n",
        "print(f\"Improvement from Deep (3 seeds): {improvement_from_deep:+.4f} ({improvement_from_deep/baseline_deep3seeds*100:+.2f}%)\")\n",
        "\n",
        "# Target achievement\n",
        "target = 0.45\n",
        "gap_to_target = target - overall_mean\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"TARGET ACHIEVEMENT\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Target: {target:.4f}\")\n",
        "print(f\"Current: {overall_mean:.4f}\")\n",
        "print(f\"Gap: {gap_to_target:.4f}\")\n",
        "\n",
        "if overall_mean >= target:\n",
        "    print(\"\\nüéØüéØüéØ TARGET ACHIEVED! üéØüéØüéØ\")\n",
        "    print(f\"‚úÖ Exceeded target by {overall_mean - target:+.4f}!\")\n",
        "    print(\"\\nüèÜ This is your FINAL PRODUCTION MODEL!\")\n",
        "elif gap_to_target <= 0.005:\n",
        "    print(\"\\nüéØ SO CLOSE!\")\n",
        "    print(f\"   Only {gap_to_target:.4f} away from target!\")\n",
        "    print(f\"   This is an excellent result - essentially at target considering variance.\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ Strong performance! {gap_to_target:.4f} away from target\")\n",
        "    print(f\"   Possible next steps:\")\n",
        "    print(f\"   ‚Ä¢ Try vote_window tuning (3, 7, 9)\")\n",
        "    print(f\"   ‚Ä¢ Consider larger ensemble (each seed ‚Üí 3-5 models)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45c9pm5_vwUe",
        "outputId": "9ce37ccc-79b8-49b3-c9cf-08e64624eba3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "PER-FOLD RESULTS:\n",
            "--------------------------------------------------------------------------------\n",
            "Fold 1: 0.4773\n",
            "Fold 2: 0.4324\n",
            "Fold 3: 0.4240\n",
            "Fold 4: 0.4329\n",
            "\n",
            "================================================================================\n",
            "OVERALL PERFORMANCE\n",
            "================================================================================\n",
            "Mean Macro F1: 0.4417 ¬± 0.0209\n",
            "Min: 0.4240\n",
            "Max: 0.4773\n",
            "\n",
            "================================================================================\n",
            "COMPARISON TO PREVIOUS APPROACHES\n",
            "================================================================================\n",
            "\n",
            "Experiment 2 (7 directions, no attention): 0.4384\n",
            "Deep Attention (3 seeds √ó 5 models):      0.4438\n",
            "Seed Optimization (7 seeds √ó 1 model):    0.4107 (unstable)\n",
            "\n",
            "üèÜ FINAL (7 seeds ‚Üí 7 models ensemble):    0.4417\n",
            "\n",
            "Improvement from Exp 2: +0.0033 (+0.74%)\n",
            "Improvement from Deep (3 seeds): -0.0021 (-0.48%)\n",
            "\n",
            "================================================================================\n",
            "TARGET ACHIEVEMENT\n",
            "================================================================================\n",
            "Target: 0.4500\n",
            "Current: 0.4417\n",
            "Gap: 0.0083\n",
            "\n",
            "‚úÖ Strong performance! 0.0083 away from target\n",
            "   Possible next steps:\n",
            "   ‚Ä¢ Try vote_window tuning (3, 7, 9)\n",
            "   ‚Ä¢ Consider larger ensemble (each seed ‚Üí 3-5 models)\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üíæ SAVE RESULTS TO FILE\n",
        "\n",
        "with open('final_7seed_ensemble_results.txt', 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"FINAL PRODUCTION MODEL RESULTS\\n\")\n",
        "    f.write(\"Deep Bidirectional GRU with Attention + 7-Seed Ensemble\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"CONFIGURATION:\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Seeds: {OPTIMIZED_SEEDS}\\n\")\n",
        "    f.write(\"Ensemble Strategy: 7 seeds ‚Üí 7 models ‚Üí All ensemble together\\n\")\n",
        "    f.write(\"Architecture: Deep Bi-GRU (128 ‚Üí 64) + Attention\\n\")\n",
        "    f.write(\"Directions: 7 (backward_10, centered_10, forward_10, backward_15, forward_15, asymm_past, asymm_future)\\n\")\n",
        "    f.write(\"Temporal Voting: 5-second window\\n\\n\")\n",
        "\n",
        "    f.write(\"OVERALL RESULTS:\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Overall Mean: {overall_mean:.4f} ¬± {overall_std:.4f}\\n\")\n",
        "    f.write(f\"Range: {np.min(fold_scores):.4f} to {np.max(fold_scores):.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"PER-FOLD RESULTS:\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        result = all_fold_results[fold_num]\n",
        "        f.write(f\"\\nFold {fold_num}: {result['macro_f1']:.4f}\\n\")\n",
        "        f.write(\"  Per-Class F1:\\n\")\n",
        "        for class_name, f1 in sorted(result['per_class_f1'].items()):\n",
        "            f.write(f\"    {class_name:20s}: {f1:.4f}\\n\")\n",
        "\n",
        "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "    f.write(\"COMPARISON TO BASELINES:\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(\"Experiment 2 (7 directions, no attention): 0.4384\\n\")\n",
        "    f.write(\"Deep Attention (3 seeds √ó 5 models):      0.4438\\n\")\n",
        "    f.write(f\"Final (7 seeds ‚Üí 7 models ensemble):       {overall_mean:.4f}\\n\\n\")\n",
        "    f.write(f\"Improvement from Exp 2: {improvement_from_exp2:+.4f}\\n\")\n",
        "    f.write(f\"Improvement from Deep (3 seeds): {improvement_from_deep:+.4f}\\n\")\n",
        "\n",
        "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "    f.write(f\"Gap to target (0.45): {gap_to_target:.4f}\\n\")\n",
        "    if overall_mean >= target:\n",
        "        f.write(\"\\nüéØ TARGET ACHIEVED!\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to final_7seed_ensemble_results.txt\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENT COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüèÜ Final Performance: {overall_mean:.4f} ¬± {overall_std:.4f}\")\n",
        "print(f\"üìä 7 optimized seeds working together!\")\n",
        "if overall_mean >= 0.45:\n",
        "    print(f\"üéØ TARGET ACHIEVED - This is your production model!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-B0D0IXwuUi",
        "outputId": "6bfa6892-e957-4b6b-99e6-4945886046b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Results saved to final_7seed_ensemble_results.txt\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "üèÜ Final Performance: 0.4417 ¬± 0.0209\n",
            "üìä 7 optimized seeds working together!\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}
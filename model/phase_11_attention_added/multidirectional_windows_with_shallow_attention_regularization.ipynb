{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di4AB792Xrho",
        "outputId": "6135694f-0f4c-4b29-fcb6-1405dd59b044"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Input, Multiply, Permute, Reshape, Lambda\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from tensorflow.keras.layers import Bidirectional, GRU, Layer\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers  # ðŸ†• ADD THIS LINE\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ“ All imports successful\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-X27x4yXrkI",
        "outputId": "62fb0d1d-4283-4a1c-f48c-da276868fc2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ All imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ†• Custom Attention Layer\n",
        "\n",
        "This attention mechanism learns to focus on the most important timesteps in the sequence.\n",
        "It computes attention weights for each timestep and creates a weighted representation."
      ],
      "metadata": {
        "id": "YLmmaxefdSl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    Custom Attention Layer for Sequence Models WITH REGULARIZATION\n",
        "\n",
        "    This layer learns which timesteps in the sequence are most important\n",
        "    for the classification task. It computes attention weights and returns\n",
        "    a weighted sum of the input sequence.\n",
        "\n",
        "    ðŸ†• Added L2 regularization to prevent overfitting on small datasets\n",
        "\n",
        "    Architecture:\n",
        "    1. Dense layer projects sequence to attention scores (with L2 regularization)\n",
        "    2. Softmax normalizes scores to weights\n",
        "    3. Weighted sum creates context vector\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # input_shape: (batch_size, timesteps, features)\n",
        "        # ðŸ†• Added L2 regularization (0.01) to attention weights\n",
        "        self.W = self.add_weight(\n",
        "            name='attention_weight',\n",
        "            shape=(input_shape[-1], 1),\n",
        "            initializer='glorot_uniform',\n",
        "            regularizer=regularizers.l2(0.01),  # ðŸ†• L2 regularization\n",
        "            trainable=True\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            name='attention_bias',\n",
        "            shape=(1,),\n",
        "            initializer='zeros',\n",
        "            regularizer=regularizers.l2(0.01),  # ðŸ†• L2 regularization for bias too\n",
        "            trainable=True\n",
        "        )\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        # inputs shape: (batch_size, timesteps, features)\n",
        "\n",
        "        # Compute attention scores: (batch_size, timesteps, 1)\n",
        "        attention_scores = K.tanh(K.dot(inputs, self.W) + self.b)\n",
        "\n",
        "        # Apply mask if provided (for padded sequences)\n",
        "        if mask is not None:\n",
        "            # Expand mask to match attention_scores shape\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            mask = K.expand_dims(mask, axis=-1)\n",
        "            # Set masked positions to very negative value\n",
        "            attention_scores = attention_scores * mask + (1 - mask) * (-1e10)\n",
        "\n",
        "        # Compute attention weights: (batch_size, timesteps, 1)\n",
        "        attention_weights = K.softmax(attention_scores, axis=1)\n",
        "\n",
        "        # Compute weighted sum: (batch_size, features)\n",
        "        context_vector = K.sum(inputs * attention_weights, axis=1)\n",
        "\n",
        "        return context_vector\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        # Output shape: (batch_size, features)\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "    def get_config(self):\n",
        "        return super(AttentionLayer, self).get_config()\n",
        "\n",
        "print(\"âœ… Custom Attention Layer defined (with L2 regularization)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYCRy5NwXrmo",
        "outputId": "b7336acd-fb7a-45fa-f598-ba201d0a0606"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Custom Attention Layer defined (with L2 regularization)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_filter_fold(i):\n",
        "    train_dir = f'/content/drive/MyDrive/split_data/fold{i}/train.csv'\n",
        "    test_dir = f'/content/drive/MyDrive/split_data/fold{i}/test.csv'\n",
        "    train_df = pd.read_csv(train_dir)\n",
        "    test_df = pd.read_csv(test_dir)\n",
        "\n",
        "    train_labels = list(train_df['room'].unique())\n",
        "    test_labels = list(test_df['room'].unique())\n",
        "    common_labels = list(set(train_labels) & set(test_labels))\n",
        "\n",
        "    train_df = train_df[train_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "    test_df = test_df[test_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Load all 4 folds\n",
        "train_df_1, test_df_1 = load_and_filter_fold(1)\n",
        "train_df_2, test_df_2 = load_and_filter_fold(2)\n",
        "train_df_3, test_df_3 = load_and_filter_fold(3)\n",
        "train_df_4, test_df_4 = load_and_filter_fold(4)\n",
        "\n",
        "print(\"âœ“ All folds loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZXApomZXrph",
        "outputId": "7a0dda68-e66c-45c9-cec7-3b839a0a4d83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ All folds loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "def create_room_groups(df):\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    df['room_group'] = (df['room'] != df['room'].shift()).cumsum()\n",
        "    return df\n",
        "\n",
        "def create_beacon_count_vectors(df):\n",
        "    \"\"\"Aggregates readings into 1s vectors. Handles data with or without 'room_group'.\"\"\"\n",
        "    vectors = []\n",
        "    has_groups = 'room_group' in df.columns # Check if we are in 'training' mode\n",
        "\n",
        "    for _, group in df.groupby('timestamp'):\n",
        "        beacon_counts = group['mac address'].value_counts()\n",
        "        total_readings = len(group)\n",
        "\n",
        "        vector = [0.0] * 23\n",
        "        for beacon_id, count in beacon_counts.items():\n",
        "            if 1 <= beacon_id <= 23:\n",
        "                vector[int(beacon_id) - 1] = count / total_readings\n",
        "\n",
        "        entry = {\n",
        "            'timestamp': group['timestamp'].iloc[0],\n",
        "            'room': group['room'].iloc[0],\n",
        "            'beacon_vector': vector\n",
        "        }\n",
        "\n",
        "        if has_groups:\n",
        "            entry['room_group'] = group['room_group'].iloc[0]\n",
        "\n",
        "        vectors.append(entry)\n",
        "\n",
        "    return pd.DataFrame(vectors)\n",
        "\n",
        "def create_sequences_from_groups(vector_df, min_length=3, max_length=50):\n",
        "    \"\"\"Used for Training: Creates clean sequences where the room is constant.\"\"\"\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for (room, room_group), group in vector_df.groupby(['room', 'room_group']):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=False)\n",
        "        seq_length = len(group)\n",
        "\n",
        "        if seq_length < min_length:\n",
        "            continue\n",
        "\n",
        "        if seq_length > max_length:\n",
        "            group = group.tail(max_length)\n",
        "\n",
        "        sequence = [row['beacon_vector'] for _, row in group.iterrows()]\n",
        "        sequences.append(sequence)\n",
        "        labels.append(room)\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "print(\"âœ… Basic functions defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2WK6ZKIXrry",
        "outputId": "a823de22-41c9-4a3a-e523-c1b670df16b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Basic functions defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ†• Updated Model Architecture with Attention\n",
        "\n",
        "The new architecture integrates attention in two ways:\n",
        "1. **Between Bi-GRU layers**: First Bi-GRU extracts features, attention focuses on important timesteps\n",
        "2. **After final Bi-GRU**: Second Bi-GRU output is attended to create final context vector\n",
        "\n",
        "This allows the model to:\n",
        "- Learn which parts of the 10s/15s window are most discriminative\n",
        "- Focus on room entry/exit moments rather than treating all timesteps equally\n",
        "- Handle noisy transition periods better"
      ],
      "metadata": {
        "id": "gKnz8DkcdWnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bidirectional_gru_model_with_attention(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Bidirectional GRU Architecture with Attention Mechanism + Regularization\n",
        "\n",
        "    Architecture:\n",
        "    1. Masking layer (handle variable-length sequences)\n",
        "    2. First Bi-GRU (128 units) with return_sequences=True\n",
        "    3. Dropout (0.3)\n",
        "    4. ðŸ†• ATTENTION LAYER (with L2 regularization) - learns which timesteps matter most\n",
        "    5. ðŸ†• Dropout after attention (0.3) - prevents attention overfitting\n",
        "    6. Dense layer (64 units)\n",
        "    7. Dropout (0.3)\n",
        "    8. Dense layer (32 units)\n",
        "    9. Dropout (0.2)\n",
        "    10. Output layer (softmax)\n",
        "\n",
        "    The attention mechanism replaces the second Bi-GRU layer with a learned\n",
        "    attention-based aggregation of the sequence. Regularization prevents\n",
        "    overfitting on small training sets (like Fold 3).\n",
        "    \"\"\"\n",
        "    inputs = Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "    # Masking for padded sequences\n",
        "    masked = Masking(mask_value=0.0, name='masking')(inputs)\n",
        "\n",
        "    # First Bi-GRU layer - extracts sequential features\n",
        "    gru1 = Bidirectional(\n",
        "        GRU(128, return_sequences=True, name='gru_layer_1'),\n",
        "        name='bidirectional_gru_1'\n",
        "    )(masked)\n",
        "    gru1 = Dropout(0.3, name='dropout_1')(gru1)\n",
        "\n",
        "    # ðŸ†• ATTENTION MECHANISM (with L2 regularization built-in)\n",
        "    # Instead of second Bi-GRU, use attention to aggregate the sequence\n",
        "    # This learns which timesteps are most important\n",
        "    attention_output = AttentionLayer(name='attention_layer')(gru1)\n",
        "\n",
        "    # ðŸ†• Dropout after attention to prevent overfitting\n",
        "    attention_output = Dropout(0.3, name='dropout_after_attention')(attention_output)\n",
        "\n",
        "    # Dense layers for classification\n",
        "    dense1 = Dense(64, activation='relu', name='dense_1')(attention_output)\n",
        "    dense1 = Dropout(0.3, name='dropout_2')(dense1)\n",
        "\n",
        "    dense2 = Dense(32, activation='relu', name='dense_2')(dense1)\n",
        "    dense2 = Dropout(0.2, name='dropout_3')(dense2)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(num_classes, activation='softmax', name='output_layer')(dense2)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='BiGRU_with_Attention')\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"âœ… Regularized Attention-based Bi-GRU model architecture defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcUKsVvlXrur",
        "outputId": "94e8e8b9-ba72-44b3-c52e-64da0615c8e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Regularized Attention-based Bi-GRU model architecture defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bidirectional_gru_model_with_deep_attention(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    ALTERNATIVE: Deeper Bidirectional GRU Architecture with Attention\n",
        "\n",
        "    Architecture:\n",
        "    1. Masking layer\n",
        "    2. First Bi-GRU (128 units) with return_sequences=True\n",
        "    3. Dropout (0.3)\n",
        "    4. Second Bi-GRU (64 units) with return_sequences=True\n",
        "    5. Dropout (0.3)\n",
        "    6. ðŸ†• ATTENTION LAYER - aggregates the deep sequence features\n",
        "    7. Dense layers + Output\n",
        "\n",
        "    This version keeps both Bi-GRU layers and adds attention on top.\n",
        "    More parameters but potentially better at learning complex patterns.\n",
        "    \"\"\"\n",
        "    inputs = Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "    # Masking for padded sequences\n",
        "    masked = Masking(mask_value=0.0, name='masking')(inputs)\n",
        "\n",
        "    # First Bi-GRU layer\n",
        "    gru1 = Bidirectional(\n",
        "        GRU(128, return_sequences=True, name='gru_layer_1'),\n",
        "        name='bidirectional_gru_1'\n",
        "    )(masked)\n",
        "    gru1 = Dropout(0.3, name='dropout_1')(gru1)\n",
        "\n",
        "    # Second Bi-GRU layer\n",
        "    gru2 = Bidirectional(\n",
        "        GRU(64, return_sequences=True, name='gru_layer_2'),\n",
        "        name='bidirectional_gru_2'\n",
        "    )(gru1)\n",
        "    gru2 = Dropout(0.3, name='dropout_2')(gru2)\n",
        "\n",
        "    # ðŸ†• ATTENTION MECHANISM\n",
        "    # Attention aggregates the deep bi-directional features\n",
        "    attention_output = AttentionLayer(name='attention_layer')(gru2)\n",
        "\n",
        "    # Dense layers for classification\n",
        "    dense1 = Dense(32, activation='relu', name='dense_1')(attention_output)\n",
        "    dense1 = Dropout(0.2, name='dropout_3')(dense1)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(num_classes, activation='softmax', name='output_layer')(dense1)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='Deep_BiGRU_with_Attention')\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"âœ… Deep Attention-based Bi-GRU model architecture defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTIZ-_8hXrxi",
        "outputId": "750dbbaa-ed18-48f7-ef55-8156eab8fd1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Deep Attention-based Bi-GRU model architecture defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ†• MODEL SELECTION FLAG\n",
        "# Set this to choose which attention architecture to use\n",
        "# Options: 'shallow' or 'deep'\n",
        "ATTENTION_MODEL_TYPE = 'shallow'  # Start with shallow, can try deep if needed\n",
        "\n",
        "def build_model_with_attention(input_shape, num_classes, model_type='shallow'):\n",
        "    \"\"\"\n",
        "    Wrapper function to build the selected attention model\n",
        "\n",
        "    Args:\n",
        "        input_shape: Input shape for the model\n",
        "        num_classes: Number of room classes\n",
        "        model_type: 'shallow' or 'deep'\n",
        "\n",
        "    Returns:\n",
        "        Compiled Keras model with attention\n",
        "    \"\"\"\n",
        "    if model_type == 'shallow':\n",
        "        return build_bidirectional_gru_model_with_attention(input_shape, num_classes)\n",
        "    elif model_type == 'deep':\n",
        "        return build_bidirectional_gru_model_with_deep_attention(input_shape, num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_type: {model_type}. Use 'shallow' or 'deep'.\")\n",
        "\n",
        "print(f\"âœ… Model selection wrapper defined. Current selection: {ATTENTION_MODEL_TYPE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lde-vm_rXr0Q",
        "outputId": "ad5e3a10-ef7b-45a3-94e2-e5ff9c0ca799"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model selection wrapper defined. Current selection: shallow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_extended_multidirectional_windows(vector_df):\n",
        "    \"\"\"\n",
        "    EXPERIMENT 2: Create 7 types of sliding windows for extended multi-directional prediction\n",
        "\n",
        "    Directions:\n",
        "    1. backward_10:  [i-9 to i]     - 10s history, predict at i\n",
        "    2. centered_10:  [i-4 to i+5]   - 10s centered, predict at i\n",
        "    3. forward_10:   [i to i+9]     - 10s future, predict at i\n",
        "    4. backward_15:  [i-14 to i]    - 15s history (more context)\n",
        "    5. forward_15:   [i to i+14]    - 15s future (earlier transition detection)\n",
        "    6. asymm_past:   [i-11 to i+3]  - 12s past + 4s future (transition from old room)\n",
        "    7. asymm_future: [i-3 to i+11]  - 4s past + 12s future (entering new room)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with direction names as keys\n",
        "        Each contains: (sequences, labels, valid_indices)\n",
        "    \"\"\"\n",
        "    # Ensure chronological order and group by day\n",
        "    vector_df['dt'] = pd.to_datetime(vector_df['timestamp'])\n",
        "    vector_df['date'] = vector_df['dt'].dt.date\n",
        "\n",
        "    results = {\n",
        "        'backward_10': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'centered_10': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'forward_10': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'backward_15': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'forward_15': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'asymm_past': {'sequences': [], 'labels': [], 'indices': []},\n",
        "        'asymm_future': {'sequences': [], 'labels': [], 'indices': []},\n",
        "    }\n",
        "\n",
        "    for _, day_group in vector_df.groupby('date'):\n",
        "        day_group = day_group.sort_values('timestamp').reset_index(drop=True)\n",
        "        vectors = list(day_group['beacon_vector'])\n",
        "        rooms = list(day_group['room'])\n",
        "        n = len(vectors)\n",
        "\n",
        "        for i in range(n):\n",
        "            # 1. BACKWARD_10: [i-9, ..., i] predict at i\n",
        "            if i >= 9:\n",
        "                window = vectors[i - 9 : i + 1]\n",
        "                results['backward_10']['sequences'].append(window)\n",
        "                results['backward_10']['labels'].append(rooms[i])\n",
        "                results['backward_10']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            # 2. CENTERED_10: [i-4, ..., i, ..., i+5] predict at i\n",
        "            if i >= 4 and i + 5 < n:\n",
        "                window = vectors[i - 4 : i + 6]\n",
        "                results['centered_10']['sequences'].append(window)\n",
        "                results['centered_10']['labels'].append(rooms[i])\n",
        "                results['centered_10']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            # 3. FORWARD_10: [i, ..., i+9] predict at i\n",
        "            if i + 9 < n:\n",
        "                window = vectors[i : i + 10]\n",
        "                results['forward_10']['sequences'].append(window)\n",
        "                results['forward_10']['labels'].append(rooms[i])\n",
        "                results['forward_10']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            # 4. BACKWARD_15: [i-14, ..., i] predict at i (MORE HISTORY)\n",
        "            if i >= 14:\n",
        "                window = vectors[i - 14 : i + 1]\n",
        "                results['backward_15']['sequences'].append(window)\n",
        "                results['backward_15']['labels'].append(rooms[i])\n",
        "                results['backward_15']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            # 5. FORWARD_15: [i, ..., i+14] predict at i (EARLIER TRANSITION DETECTION)\n",
        "            if i + 14 < n:\n",
        "                window = vectors[i : i + 15]\n",
        "                results['forward_15']['sequences'].append(window)\n",
        "                results['forward_15']['labels'].append(rooms[i])\n",
        "                results['forward_15']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            # 6. ASYMM_PAST: [i-11, ..., i, ..., i+3] predict at i (HEAVY PAST BIAS)\n",
        "            # Good for detecting we're leaving a room\n",
        "            if i >= 11 and i + 3 < n:\n",
        "                window = vectors[i - 11 : i + 4]\n",
        "                results['asymm_past']['sequences'].append(window)\n",
        "                results['asymm_past']['labels'].append(rooms[i])\n",
        "                results['asymm_past']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "            # 7. ASYMM_FUTURE: [i-3, ..., i, ..., i+11] predict at i (HEAVY FUTURE BIAS)\n",
        "            # Good for detecting we're entering a room\n",
        "            if i >= 3 and i + 11 < n:\n",
        "                window = vectors[i - 3 : i + 12]\n",
        "                results['asymm_future']['sequences'].append(window)\n",
        "                results['asymm_future']['labels'].append(rooms[i])\n",
        "                results['asymm_future']['indices'].append((day_group['date'].iloc[0], i))\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"âœ… Extended multi-directional window function defined (7 directions)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrHt6YYjXr3R",
        "outputId": "90ac733a-6934-4fdc-cfcf-6807129232aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Extended multi-directional window function defined (7 directions)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ensemble_models(train_df, n_models=5, base_seed=42, model_type='shallow', verbose=False):\n",
        "    \"\"\"\n",
        "    ðŸ†• UPDATED: Train multiple models with ATTENTION mechanism\n",
        "\n",
        "    Returns:\n",
        "        models: List of trained Keras models (with attention)\n",
        "        label_encoder: Fitted label encoder\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(f\"  Training ensemble of {n_models} models with ATTENTION ({model_type})...\")\n",
        "\n",
        "    # Prepare data (same for all models)\n",
        "    train_df_grouped = create_room_groups(train_df)\n",
        "    train_vector_df = create_beacon_count_vectors(train_df_grouped)\n",
        "    X_train_seq, y_train_labels = create_sequences_from_groups(train_vector_df, max_length=50)\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train = label_encoder.fit_transform(y_train_labels)\n",
        "\n",
        "    # Pad sequences\n",
        "    X_train_padded = pad_sequences(X_train_seq, maxlen=50, padding='post', dtype='float32', value=0.0)\n",
        "\n",
        "    # Compute class weights\n",
        "    class_weights_array = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
        "\n",
        "    # Train multiple models\n",
        "    models = []\n",
        "    for i in range(n_models):\n",
        "        model_seed = base_seed + i * 1000  # 42, 1042, 2042, 3042, 4042\n",
        "        set_seeds(model_seed)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"    Model {i+1}/{n_models} (seed {model_seed})...\", end=\" \")\n",
        "\n",
        "        # ðŸ†• BUILD ATTENTION MODEL\n",
        "        model = build_model_with_attention(\n",
        "            input_shape=(50, 23),\n",
        "            num_classes=len(label_encoder.classes_),\n",
        "            model_type=model_type\n",
        "        )\n",
        "\n",
        "        # Callbacks\n",
        "        early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True, verbose=0)\n",
        "        reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, verbose=0, min_lr=1e-6)\n",
        "\n",
        "        # Train\n",
        "        model.fit(\n",
        "            X_train_padded, y_train,\n",
        "            epochs=30,\n",
        "            batch_size=32,\n",
        "            class_weight=class_weights,\n",
        "            callbacks=[early_stop, reduce_lr],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        models.append(model)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"âœ“\")\n",
        "\n",
        "    return models, label_encoder\n",
        "\n",
        "print(\"âœ… Ensemble training function defined (with attention support)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH_iCbqLXr6S",
        "outputId": "c03e158a-54b9-4574-8468-4e274ea92c9a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Ensemble training function defined (with attention support)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_direction(models, sequences, max_seq_length=50):\n",
        "    \"\"\"\n",
        "    Get ensemble predictions for a single direction\n",
        "\n",
        "    Returns:\n",
        "        ensemble_proba: (n_samples, n_classes) averaged probability matrix\n",
        "    \"\"\"\n",
        "    # Pad sequences\n",
        "    X_padded = pad_sequences(sequences, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "\n",
        "    # Get predictions from all models\n",
        "    all_predictions = []\n",
        "    for model in models:\n",
        "        proba = model.predict(X_padded, verbose=0)\n",
        "        all_predictions.append(proba)\n",
        "\n",
        "    # Average probabilities across ensemble\n",
        "    ensemble_proba = np.mean(all_predictions, axis=0)\n",
        "\n",
        "    return ensemble_proba\n",
        "\n",
        "def combine_directional_predictions(direction_results, method='confidence_weighted'):\n",
        "    \"\"\"\n",
        "    Combine predictions from multiple directions using confidence weighting\n",
        "    Now handles 7 directions instead of 3\n",
        "\n",
        "    Args:\n",
        "        direction_results: Dict with keys for all 7 directions\n",
        "                          Each value is a dict with 'proba' and 'indices'\n",
        "        method: 'confidence_weighted', 'equal', or 'softmax'\n",
        "\n",
        "    Returns:\n",
        "        combined_proba: (n_positions, n_classes) final probability matrix\n",
        "        position_map: mapping from (date, position) to array index\n",
        "    \"\"\"\n",
        "    # Build a mapping of all unique positions\n",
        "    all_positions = set()\n",
        "    direction_names = ['backward_10', 'centered_10', 'forward_10',\n",
        "                      'backward_15', 'forward_15',\n",
        "                      'asymm_past', 'asymm_future']\n",
        "\n",
        "    for direction in direction_names:\n",
        "        all_positions.update(direction_results[direction]['indices'])\n",
        "\n",
        "    # Sort positions for consistent ordering\n",
        "    all_positions = sorted(all_positions)\n",
        "    position_map = {pos: idx for idx, pos in enumerate(all_positions)}\n",
        "\n",
        "    # Get number of classes from first available direction\n",
        "    n_classes = direction_results['backward_10']['proba'].shape[1]\n",
        "    n_positions = len(all_positions)\n",
        "\n",
        "    # Initialize combined predictions\n",
        "    combined_proba = np.zeros((n_positions, n_classes))\n",
        "    position_counts = np.zeros(n_positions)  # Track how many directions contributed\n",
        "\n",
        "    # For each direction, add its weighted contribution\n",
        "    for direction_name in direction_names:\n",
        "        direction_data = direction_results[direction_name]\n",
        "        proba = direction_data['proba']\n",
        "        indices = direction_data['indices']\n",
        "\n",
        "        # Get confidence (max probability) for each prediction\n",
        "        confidences = np.max(proba, axis=1)\n",
        "\n",
        "        # Add weighted contribution to combined predictions\n",
        "        for i, pos in enumerate(indices):\n",
        "            pos_idx = position_map[pos]\n",
        "\n",
        "            if method == 'confidence_weighted':\n",
        "                # Weight by confidence\n",
        "                weight = confidences[i]\n",
        "                combined_proba[pos_idx] += proba[i] * weight\n",
        "            elif method == 'equal':\n",
        "                # Equal weight\n",
        "                combined_proba[pos_idx] += proba[i]\n",
        "            elif method == 'softmax':\n",
        "                # Will apply softmax later\n",
        "                combined_proba[pos_idx] += proba[i] * confidences[i]\n",
        "\n",
        "            position_counts[pos_idx] += 1 if method == 'equal' else confidences[i]\n",
        "\n",
        "    # Normalize by total weight\n",
        "    for i in range(n_positions):\n",
        "        if position_counts[i] > 0:\n",
        "            combined_proba[i] /= position_counts[i]\n",
        "\n",
        "    return combined_proba, position_map\n",
        "\n",
        "print(\"âœ… Multi-directional prediction functions defined (handles 7 directions)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njn5oh4GXr9B",
        "outputId": "440de971-1c3c-479a-9ee6-771c60e54410"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Multi-directional prediction functions defined (handles 7 directions)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_confidence_weighted_voting(predictions_proba, vote_window=5):\n",
        "    \"\"\"\n",
        "    Confidence-weighted temporal voting\n",
        "\n",
        "    Instead of simple majority voting, weight each prediction by its confidence (max probability).\n",
        "\n",
        "    Args:\n",
        "        predictions_proba: (n_samples, n_classes) probability matrix from ensemble\n",
        "        vote_window: window size for voting\n",
        "\n",
        "    Returns:\n",
        "        voted_predictions: (n_samples,) final class predictions\n",
        "    \"\"\"\n",
        "    n_samples, n_classes = predictions_proba.shape\n",
        "    voted_predictions = np.zeros(n_samples, dtype=int)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        # Get window boundaries\n",
        "        half_window = vote_window // 2\n",
        "        start = max(0, i - half_window)\n",
        "        end = min(n_samples, i + half_window + 1)\n",
        "\n",
        "        # Get probabilities within window\n",
        "        window_proba = predictions_proba[start:end]  # (window_size, n_classes)\n",
        "\n",
        "        # Get confidence (max probability) for each prediction in window\n",
        "        window_confidences = np.max(window_proba, axis=1)  # (window_size,)\n",
        "\n",
        "        # Weight each prediction by its confidence\n",
        "        weighted_votes = np.zeros(n_classes)\n",
        "        for j in range(len(window_proba)):\n",
        "            # Each timestep contributes its probability * its confidence\n",
        "            weighted_votes += window_proba[j] * window_confidences[j]\n",
        "\n",
        "        # Final prediction: class with highest weighted vote\n",
        "        voted_predictions[i] = np.argmax(weighted_votes)\n",
        "\n",
        "    return voted_predictions\n",
        "\n",
        "print(\"âœ… Temporal voting function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSQ4kiUbXr_n",
        "outputId": "50df32e3-2ac0-472c-c2e1-40c86e08414d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Temporal voting function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_extended_multidirectional_pipeline(train_df, test_df, seed, n_ensemble=5,\n",
        "                                           vote_window=5,\n",
        "                                           combination_method='confidence_weighted',\n",
        "                                           model_type='shallow',\n",
        "                                           verbose=False):\n",
        "    \"\"\"\n",
        "    ðŸ†• UPDATED: Extended multi-directional windows with ATTENTION-based models\n",
        "\n",
        "    Pipeline:\n",
        "    1. Train ensemble of models WITH ATTENTION (shallow or deep)\n",
        "    2. Create 7 directional windows (backward_10, centered_10, forward_10, backward_15, forward_15, asymm_past, asymm_future)\n",
        "    3. Get ensemble predictions for each direction\n",
        "    4. Combine directions using confidence weighting\n",
        "    5. Apply temporal voting\n",
        "\n",
        "    Args:\n",
        "        model_type: 'shallow' or 'deep' attention architecture\n",
        "        combination_method: 'confidence_weighted', 'equal', or 'softmax'\n",
        "    \"\"\"\n",
        "    # 0. Clear session and set seeds\n",
        "    tf.keras.backend.clear_session()\n",
        "    set_seeds(seed)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n  Seed {seed}: Training ensemble with {model_type} attention...\")\n",
        "\n",
        "    # 1. Train Ensemble Models WITH ATTENTION\n",
        "    models, label_encoder = train_ensemble_models(\n",
        "        train_df,\n",
        "        n_models=n_ensemble,\n",
        "        base_seed=seed,\n",
        "        model_type=model_type,\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "    if verbose:\n",
        "        print(\"  Creating extended multi-directional windows (7 directions)...\")\n",
        "\n",
        "    # 2. Prepare Test Data with Extended Multi-Directional Windows\n",
        "    test_vectors = create_beacon_count_vectors(test_df)\n",
        "    direction_windows = create_extended_multidirectional_windows(test_vectors)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"    Backward_10 windows: {len(direction_windows['backward_10']['sequences'])}\")\n",
        "        print(f\"    Centered_10 windows: {len(direction_windows['centered_10']['sequences'])}\")\n",
        "        print(f\"    Forward_10 windows: {len(direction_windows['forward_10']['sequences'])}\")\n",
        "        print(f\"    Backward_15 windows: {len(direction_windows['backward_15']['sequences'])}\")\n",
        "        print(f\"    Forward_15 windows: {len(direction_windows['forward_15']['sequences'])}\")\n",
        "        print(f\"    Asymm_past windows: {len(direction_windows['asymm_past']['sequences'])}\")\n",
        "        print(f\"    Asymm_future windows: {len(direction_windows['asymm_future']['sequences'])}\")\n",
        "        print(\"  Getting directional predictions...\")\n",
        "\n",
        "    # 3. Get Predictions for Each Direction\n",
        "    direction_results = {}\n",
        "    direction_names = ['backward_10', 'centered_10', 'forward_10',\n",
        "                      'backward_15', 'forward_15',\n",
        "                      'asymm_past', 'asymm_future']\n",
        "\n",
        "    for direction_name in direction_names:\n",
        "        if verbose:\n",
        "            print(f\"    Predicting {direction_name}...\", end=\" \")\n",
        "\n",
        "        sequences = direction_windows[direction_name]['sequences']\n",
        "        proba = predict_single_direction(models, sequences, max_seq_length=50)\n",
        "\n",
        "        direction_results[direction_name] = {\n",
        "            'proba': proba,\n",
        "            'indices': direction_windows[direction_name]['indices'],\n",
        "            'labels': direction_windows[direction_name]['labels']\n",
        "        }\n",
        "\n",
        "        if verbose:\n",
        "            avg_conf = np.mean(np.max(proba, axis=1))\n",
        "            print(f\"avg confidence: {avg_conf:.3f}\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  Combining 7 directions using {combination_method}...\")\n",
        "\n",
        "    # 4. Combine Directional Predictions\n",
        "    combined_proba, position_map = combine_directional_predictions(\n",
        "        direction_results,\n",
        "        method=combination_method\n",
        "    )\n",
        "\n",
        "    # Get ground truth labels in same order as combined predictions\n",
        "    y_test = []\n",
        "    for pos in sorted(position_map.keys()):\n",
        "        # Use label from any direction (they should all be the same for a given position)\n",
        "        for direction_name in direction_names:\n",
        "            if pos in direction_results[direction_name]['indices']:\n",
        "                idx = direction_results[direction_name]['indices'].index(pos)\n",
        "                y_test.append(direction_results[direction_name]['labels'][idx])\n",
        "                break\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  Applying temporal voting (window={vote_window})...\")\n",
        "\n",
        "    # 5. Apply Confidence-Weighted Temporal Voting\n",
        "    y_pred_voted_encoded = apply_confidence_weighted_voting(combined_proba, vote_window=vote_window)\n",
        "    y_pred = label_encoder.inverse_transform(y_pred_voted_encoded)\n",
        "\n",
        "    # 6. Final Evaluation\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    per_class_f1 = f1_score(y_test, y_pred, average=None, labels=label_encoder.classes_, zero_division=0)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  âœ“ Macro F1: {macro_f1:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'seed': seed,\n",
        "        'macro_f1': macro_f1,\n",
        "        'per_class_f1': {label: f1 for label, f1 in zip(label_encoder.classes_, per_class_f1)},\n",
        "        'combination_method': combination_method,\n",
        "        'model_type': model_type\n",
        "    }\n",
        "\n",
        "print(\"âœ… Complete extended multi-directional pipeline defined (7 directions + ATTENTION)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9iSqiHLYXne",
        "outputId": "bcf469e2-d44f-4f7e-8230-dcf024d46ed5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Complete extended multi-directional pipeline defined (7 directions + ATTENTION)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸš€ EXPERIMENT 3: Multi-Directional Windows with Attention\n",
        "\n",
        "This experiment tests whether attention mechanisms can improve upon Experiment 2's results.\n",
        "\n",
        "**Key Changes:**\n",
        "- Replace standard Bi-GRU with attention-enhanced Bi-GRU\n",
        "- Two variants available: 'shallow' (faster) and 'deep' (more parameters)\n",
        "- All other components remain the same (7 directions, confidence weighting, temporal voting)\n",
        "\n",
        "**Expected Benefits:**\n",
        "- Attention helps model focus on critical timesteps (e.g., room transitions)\n",
        "- Should handle noisy periods better\n",
        "- May improve per-class F1 for difficult rooms\n",
        "\n",
        "**Current Target:** 0.45 macro F1  \n",
        "**Experiment 2 Result:** 0.4384 Â± 0.0329  \n",
        "**Gap to close:** 0.0116"
      ],
      "metadata": {
        "id": "OAYluZTNdiPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmCz5czmYZiS",
        "outputId": "a7f27007-aa41-4979-9a1d-958e176545f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FULL EXPERIMENT: All 4 folds, 3 seeds each, WITH ATTENTION\n",
        "print(\"=\"*80)\n",
        "print(\"FULL 4-FOLD CROSS-VALIDATION - EXPERIMENT 3 (WITH ATTENTION)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Model Type: {ATTENTION_MODEL_TYPE} attention\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "seeds = [42, 123, 456]\n",
        "folds = {\n",
        "    1: (train_df_1, test_df_1),\n",
        "    2: (train_df_2, test_df_2),\n",
        "    3: (train_df_3, test_df_3),\n",
        "    4: (train_df_4, test_df_4)\n",
        "}\n",
        "\n",
        "all_fold_results = {}\n",
        "\n",
        "for fold_num, (train_df, test_df) in folds.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"PROCESSING FOLD {fold_num}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    fold_results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"  Running seed {seed}...\", end=\" \")\n",
        "        result = run_extended_multidirectional_pipeline(\n",
        "            train_df, test_df,\n",
        "            seed=seed,\n",
        "            n_ensemble=5,\n",
        "            vote_window=5,\n",
        "            combination_method='confidence_weighted',\n",
        "            model_type=ATTENTION_MODEL_TYPE,  # ðŸ†• Use attention model\n",
        "            verbose=False\n",
        "        )\n",
        "        fold_results.append(result)\n",
        "        print(f\"Macro F1: {result['macro_f1']:.4f}\")\n",
        "\n",
        "    all_fold_results[fold_num] = fold_results\n",
        "\n",
        "    # Calculate fold statistics\n",
        "    macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "    print(f\"\\n  Fold {fold_num} Summary:\")\n",
        "    print(f\"    Mean Macro F1: {np.mean(macro_f1_scores):.4f} Â± {np.std(macro_f1_scores):.4f}\")\n",
        "    print(f\"    Min: {np.min(macro_f1_scores):.4f}, Max: {np.max(macro_f1_scores):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ALL FOLDS COMPLETED!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5xz2CMnYemh",
        "outputId": "b39629ae-7e86-448d-e168-8f32dba65424"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FULL 4-FOLD CROSS-VALIDATION - EXPERIMENT 3 (WITH ATTENTION)\n",
            "================================================================================\n",
            "Model Type: shallow attention\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 1\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.5059\n",
            "  Running seed 123... Macro F1: 0.4626\n",
            "  Running seed 456... Macro F1: 0.5083\n",
            "\n",
            "  Fold 1 Summary:\n",
            "    Mean Macro F1: 0.4923 Â± 0.0210\n",
            "    Min: 0.4626, Max: 0.5083\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 2\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.3871\n",
            "  Running seed 123... Macro F1: 0.3610\n",
            "  Running seed 456... Macro F1: 0.3774\n",
            "\n",
            "  Fold 2 Summary:\n",
            "    Mean Macro F1: 0.3752 Â± 0.0108\n",
            "    Min: 0.3610, Max: 0.3871\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 3\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.5068\n",
            "  Running seed 123... Macro F1: 0.3845\n",
            "  Running seed 456... Macro F1: 0.4949\n",
            "\n",
            "  Fold 3 Summary:\n",
            "    Mean Macro F1: 0.4621 Â± 0.0551\n",
            "    Min: 0.3845, Max: 0.5068\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 4\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.4648\n",
            "  Running seed 123... Macro F1: 0.4236\n",
            "  Running seed 456... Macro F1: 0.4257\n",
            "\n",
            "  Fold 4 Summary:\n",
            "    Mean Macro F1: 0.4380 Â± 0.0189\n",
            "    Min: 0.4236, Max: 0.4648\n",
            "\n",
            "================================================================================\n",
            "ALL FOLDS COMPLETED!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display summary and comparison\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"FINAL SUMMARY - EXPERIMENT 3 (7 DIRECTIONS + {ATTENTION_MODEL_TYPE.upper()} ATTENTION)\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    macro_f1_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "    print(f\"Fold {fold_num}: {np.mean(macro_f1_scores):.4f} Â± {np.std(macro_f1_scores):.4f}\")\n",
        "\n",
        "all_macro_f1 = []\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    all_macro_f1.extend([r['macro_f1'] for r in all_fold_results[fold_num]])\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Overall Mean: {np.mean(all_macro_f1):.4f} Â± {np.std(all_macro_f1):.4f}\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PROGRESSION:\")\n",
        "print(\"=\"*80)\n",
        "print(\"Baseline (Approach 24 - single direction):\")\n",
        "print(\"  Overall: 0.4106 Â± 0.0266\")\n",
        "print(f\"\\nExperiment 1 (3 directions):\")\n",
        "print(f\"  Overall: 0.4273 Â± 0.0312  (+0.0167 vs baseline)\")\n",
        "print(f\"\\nExperiment 2 (7 directions - NO attention):\")\n",
        "print(f\"  Overall: 0.4384 Â± 0.0329  (+0.0278 vs baseline)\")\n",
        "print(f\"\\nðŸ†• Experiment 3 (7 directions + {ATTENTION_MODEL_TYPE} attention):\")\n",
        "print(f\"  Overall: {np.mean(all_macro_f1):.4f} Â± {np.std(all_macro_f1):.4f}  ({np.mean(all_macro_f1) - 0.4384:+.4f} vs Exp2)\")\n",
        "\n",
        "total_gain = np.mean(all_macro_f1) - 0.4106\n",
        "attention_gain = np.mean(all_macro_f1) - 0.4384\n",
        "target_gap = 0.45 - np.mean(all_macro_f1)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Total gain from baseline: {total_gain:+.4f}\")\n",
        "print(f\"ðŸ†• Attention improvement: {attention_gain:+.4f}\")\n",
        "print(f\"Gap to target (0.45): {target_gap:.4f}\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "if np.mean(all_macro_f1) >= 0.45:\n",
        "    print(\"\\nðŸŽ¯ðŸŽ¯ðŸŽ¯ TARGET ACHIEVED! 0.45 F1 REACHED! ðŸŽ¯ðŸŽ¯ðŸŽ¯\")\n",
        "    print(\"âœ… Attention mechanism successfully closed the gap!\")\n",
        "elif attention_gain > 0.005:\n",
        "    print(f\"\\nâœ… Attention mechanism improved results by {attention_gain:+.4f}!\")\n",
        "    if target_gap < 0.01:\n",
        "        print(f\"   Almost there! Only {target_gap:.4f} away from target.\")\n",
        "        print(\"   Recommendation: Try hyperparameter tuning (vote_window, ensemble_size)\")\n",
        "    else:\n",
        "        print(f\"   Still {target_gap:.4f} away from target.\")\n",
        "        print(\"   Recommendation: Try deep attention or hyperparameter tuning\")\n",
        "elif attention_gain > 0:\n",
        "    print(f\"\\nâš ï¸  Attention provided minor improvement ({attention_gain:+.4f})\")\n",
        "    print(\"   Recommendation: Try deep attention or focus on hyperparameter tuning\")\n",
        "else:\n",
        "    print(f\"\\nâŒ Attention didn't improve results ({attention_gain:+.4f})\")\n",
        "    print(\"   Recommendation: Revert to Experiment 2 and focus on hyperparameter tuning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8KsleI8YfK6",
        "outputId": "9e884065-58c6-407b-bde6-da6b8fe06021"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL SUMMARY - EXPERIMENT 3 (7 DIRECTIONS + SHALLOW ATTENTION)\n",
            "================================================================================\n",
            "\n",
            "Fold 1: 0.4923 Â± 0.0210\n",
            "Fold 2: 0.3752 Â± 0.0108\n",
            "Fold 3: 0.4621 Â± 0.0551\n",
            "Fold 4: 0.4380 Â± 0.0189\n",
            "\n",
            "================================================================================\n",
            "Overall Mean: 0.4419 Â± 0.0533\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "PROGRESSION:\n",
            "================================================================================\n",
            "Baseline (Approach 24 - single direction):\n",
            "  Overall: 0.4106 Â± 0.0266\n",
            "\n",
            "Experiment 1 (3 directions):\n",
            "  Overall: 0.4273 Â± 0.0312  (+0.0167 vs baseline)\n",
            "\n",
            "Experiment 2 (7 directions - NO attention):\n",
            "  Overall: 0.4384 Â± 0.0329  (+0.0278 vs baseline)\n",
            "\n",
            "ðŸ†• Experiment 3 (7 directions + shallow attention):\n",
            "  Overall: 0.4419 Â± 0.0533  (+0.0035 vs Exp2)\n",
            "\n",
            "================================================================================\n",
            "Total gain from baseline: +0.0313\n",
            "ðŸ†• Attention improvement: +0.0035\n",
            "Gap to target (0.45): 0.0081\n",
            "================================================================================\n",
            "\n",
            "âš ï¸  Attention provided minor improvement (+0.0035)\n",
            "   Recommendation: Try deep attention or focus on hyperparameter tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to text file\n",
        "with open('experiment3_attention_results.txt', 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(f\"EXPERIMENT 3: MULTI-DIRECTIONAL (7 DIRECTIONS) + {ATTENTION_MODEL_TYPE.upper()} ATTENTION\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"Configuration:\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Model Architecture: Bidirectional GRU with {ATTENTION_MODEL_TYPE} Attention\\n\")\n",
        "    f.write(\"Directions (7 total):\\n\")\n",
        "    f.write(\"  1. backward_10:  [t-9 to t] - 10s history\\n\")\n",
        "    f.write(\"  2. centered_10:  [t-4 to t+5] - 10s centered\\n\")\n",
        "    f.write(\"  3. forward_10:   [t to t+9] - 10s future\\n\")\n",
        "    f.write(\"  4. backward_15:  [t-14 to t] - 15s history (more context)\\n\")\n",
        "    f.write(\"  5. forward_15:   [t to t+14] - 15s future (earlier transition)\\n\")\n",
        "    f.write(\"  6. asymm_past:   [t-11 to t+3] - heavy past bias\\n\")\n",
        "    f.write(\"  7. asymm_future: [t-3 to t+11] - heavy future bias\\n\")\n",
        "    f.write(\"\\nCombination method: Confidence-weighted\\n\")\n",
        "    f.write(\"Ensemble size: 5 models\\n\")\n",
        "    f.write(\"Temporal voting window: 5 seconds\\n\\n\")\n",
        "\n",
        "    # Overall summary\n",
        "    all_macro_f1 = []\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        fold_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "        all_macro_f1.extend(fold_scores)\n",
        "\n",
        "    f.write(\"OVERALL RESULTS:\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Mean Macro F1: {np.mean(all_macro_f1):.4f} Â± {np.std(all_macro_f1):.4f}\\n\")\n",
        "    f.write(f\"Min: {np.min(all_macro_f1):.4f}, Max: {np.max(all_macro_f1):.4f}\\n\\n\")\n",
        "\n",
        "    # Comparison\n",
        "    f.write(\"PROGRESSION:\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(\"Baseline (single direction backward): 0.4106 Â± 0.0266\\n\")\n",
        "    f.write(\"Experiment 1 (3 directions): 0.4273 Â± 0.0312\\n\")\n",
        "    f.write(\"Experiment 2 (7 directions - no attention): 0.4384 Â± 0.0329\\n\")\n",
        "    f.write(f\"Experiment 3 (7 directions + {ATTENTION_MODEL_TYPE} attention): {np.mean(all_macro_f1):.4f} Â± {np.std(all_macro_f1):.4f}\\n\\n\")\n",
        "\n",
        "    f.write(f\"Gain vs Baseline: {np.mean(all_macro_f1) - 0.4106:+.4f}\\n\")\n",
        "    f.write(f\"Gain vs Experiment 2 (attention improvement): {np.mean(all_macro_f1) - 0.4384:+.4f}\\n\")\n",
        "    f.write(f\"Gap to target (0.45): {0.45 - np.mean(all_macro_f1):.4f}\\n\\n\")\n",
        "\n",
        "    # Per-fold results\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        f.write(f\"\\n{'='*80}\\n\")\n",
        "        f.write(f\"FOLD {fold_num} RESULTS\\n\")\n",
        "        f.write(f\"{'='*80}\\n\\n\")\n",
        "\n",
        "        fold_results = all_fold_results[fold_num]\n",
        "        macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "\n",
        "        f.write(f\"Macro F1 Scores:\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        for i, result in enumerate(fold_results):\n",
        "            f.write(f\"  Seed {result['seed']:5d}: {result['macro_f1']:.4f}\\n\")\n",
        "\n",
        "        f.write(f\"\\nStatistics:\\n\")\n",
        "        f.write(f\"  Mean: {np.mean(macro_f1_scores):.4f} Â± {np.std(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Min:  {np.min(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Max:  {np.max(macro_f1_scores):.4f}\\n\")\n",
        "\n",
        "        # Per-class F1 (averaged across seeds)\n",
        "        f.write(f\"\\nPer-Class F1 Scores (averaged across seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "\n",
        "        # Collect all class names\n",
        "        all_classes = set()\n",
        "        for result in fold_results:\n",
        "            all_classes.update(result['per_class_f1'].keys())\n",
        "\n",
        "        # Average per-class F1 across seeds\n",
        "        for class_name in sorted(all_classes):\n",
        "            class_f1_scores = [r['per_class_f1'].get(class_name, 0) for r in fold_results]\n",
        "            mean_f1 = np.mean(class_f1_scores)\n",
        "            std_f1 = np.std(class_f1_scores)\n",
        "            f.write(f\"  {class_name:20s}: {mean_f1:.4f} Â± {std_f1:.4f}\\n\")\n",
        "\n",
        "print(f\"âœ… Results saved to experiment3_attention_results.txt\")\n",
        "\n",
        "# Also print comparison\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ATTENTION MECHANISM IMPACT\")\n",
        "print(\"=\"*80)\n",
        "attention_gain = np.mean(all_macro_f1) - 0.4384\n",
        "print(f\"Experiment 2 (no attention): 0.4384\")\n",
        "print(f\"Experiment 3 (with attention): {np.mean(all_macro_f1):.4f}\")\n",
        "print(f\"Improvement: {attention_gain:+.4f} ({attention_gain/0.4384*100:+.2f}%)\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvzVTd3UYhJa",
        "outputId": "d551cdb8-44ec-4d23-9c3c-b08b4f27a7c4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Results saved to experiment3_attention_results.txt\n",
            "\n",
            "================================================================================\n",
            "ATTENTION MECHANISM IMPACT\n",
            "================================================================================\n",
            "Experiment 2 (no attention): 0.4384\n",
            "Experiment 3 (with attention): 0.4419\n",
            "Improvement: +0.0035 (+0.80%)\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adec935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Bidirectional, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import random\n",
    "import os\n",
    "\n",
    "print(\"âœ… Imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47c2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_filter_fold(i):\n",
    "    train_dir = f'../../cleaned_dataset/split_data/fold{i}/train.csv'  \n",
    "    test_dir = f'../../cleaned_dataset/split_data/fold{i}/test.csv'   \n",
    "    # load the data \n",
    "    train_df = pd.read_csv(train_dir)\n",
    "    test_df = pd.read_csv(test_dir)\n",
    "\n",
    "    # Get all of the unique labels for train / test sets \n",
    "    train_labels = list(train_df['room'].unique())\n",
    "    test_labels = list(test_df['room'].unique())\n",
    "\n",
    "    # Labels that appear in BOTH train and test\n",
    "    common_labels = list(set(train_labels) & set(test_labels))\n",
    "\n",
    "    # Filter to just keep the records with labels in common labels list\n",
    "    train_df = train_df[train_df['room'].isin(common_labels)].reset_index(drop=True)\n",
    "    test_df  = test_df[test_df['room'].isin(common_labels)].reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# Load fold 1\n",
    "train_df, test_df = load_and_filter_fold(1)\n",
    "\n",
    "# Load fold 2\n",
    "train_df_2, test_df_2 = load_and_filter_fold(2)\n",
    "\n",
    "# Load fold 3\n",
    "train_df_3, test_df_3 = load_and_filter_fold(3)\n",
    "\n",
    "# Load fold 4\n",
    "train_df_4, test_df_4 = load_and_filter_fold(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a356c268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_beacon_count_vectors(df):\n",
    "    \"\"\"Aggregates readings into 1s vectors.\"\"\"\n",
    "    vectors = []\n",
    "\n",
    "    for _, group in df.groupby('timestamp'):\n",
    "        beacon_counts = group['mac address'].value_counts()\n",
    "        total_readings = len(group)\n",
    "\n",
    "        vector = [0.0] * 23\n",
    "        for beacon_id, count in beacon_counts.items():\n",
    "            if 1 <= beacon_id <= 23:\n",
    "                vector[int(beacon_id) - 1] = count / total_readings\n",
    "\n",
    "        entry = {\n",
    "            'timestamp': group['timestamp'].iloc[0],\n",
    "            'room': group['room'].iloc[0],\n",
    "            'beacon_vector': vector\n",
    "        }\n",
    "\n",
    "        vectors.append(entry)\n",
    "\n",
    "    return pd.DataFrame(vectors)\n",
    "\n",
    "print(\"âœ… Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "105189e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Change point detection evaluation function ready\n"
     ]
    }
   ],
   "source": [
    "def evaluate_change_point_detection(test_df, penalty=20, min_size=5):\n",
    "    \"\"\"\n",
    "    Evaluate change point detection quality WITHOUT using the model.\n",
    "    Just check: do detected boundaries match true room changes?\n",
    "    \"\"\"\n",
    "    from ruptures import Pelt\n",
    "    \n",
    "    # Prepare data\n",
    "    test_vectors = create_beacon_count_vectors(test_df)\n",
    "    test_vectors = test_vectors.sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    # Build beacon sequence\n",
    "    beacon_sequence = np.array([v for v in test_vectors['beacon_vector']])\n",
    "    \n",
    "    # Detect change points\n",
    "    algo = Pelt(model=\"rbf\", min_size=min_size, jump=1)\n",
    "    algo.fit(beacon_sequence)\n",
    "    detected_changes = algo.predict(pen=penalty)\n",
    "    \n",
    "    # Get TRUE room change points\n",
    "    test_vectors['room_changed'] = (test_vectors['room'] != test_vectors['room'].shift()).astype(int)\n",
    "    true_changes = test_vectors[test_vectors['room_changed'] == 1].index.tolist()\n",
    "    true_changes.append(len(test_vectors))  # Add end point\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CHANGE POINT DETECTION EVALUATION (penalty={penalty})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"True room changes: {len(true_changes)-1}\")\n",
    "    print(f\"Detected changes:  {len(detected_changes)-1}\")\n",
    "    \n",
    "    # Calculate segment purity\n",
    "    purities = []\n",
    "    detected_segments_info = []\n",
    "    \n",
    "    for i in range(len(detected_changes) - 1):\n",
    "        start, end = detected_changes[i], detected_changes[i+1]\n",
    "        segment = test_vectors.iloc[start:end]\n",
    "        \n",
    "        if len(segment) == 0:\n",
    "            continue\n",
    "        \n",
    "        # What's the most common room in this segment?\n",
    "        most_common_room = segment['room'].mode()[0]\n",
    "        purity = (segment['room'] == most_common_room).sum() / len(segment)\n",
    "        \n",
    "        purities.append(purity)\n",
    "        detected_segments_info.append({\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'length': len(segment),\n",
    "            'dominant_room': most_common_room,\n",
    "            'purity': purity,\n",
    "            'num_rooms': segment['room'].nunique()\n",
    "        })\n",
    "    \n",
    "    # Calculate boundary matching accuracy\n",
    "    def find_nearby_matches(detected, true, tolerance=5):\n",
    "        \"\"\"Count how many detected boundaries are within tolerance of true boundaries\"\"\"\n",
    "        matches = 0\n",
    "        for d in detected[:-1]:  # Exclude last point\n",
    "            for t in true[:-1]:\n",
    "                if abs(d - t) <= tolerance:\n",
    "                    matches += 1\n",
    "                    break\n",
    "        return matches\n",
    "    \n",
    "    boundary_precision = find_nearby_matches(detected_changes, true_changes, tolerance=5) / max(len(detected_changes)-1, 1)\n",
    "    boundary_recall = find_nearby_matches(true_changes, detected_changes, tolerance=5) / max(len(true_changes)-1, 1)\n",
    "    \n",
    "    print(f\"\\nBoundary Detection (Â±5 frame tolerance):\")\n",
    "    print(f\"  Precision: {boundary_precision:.3f} (detected boundaries that are correct)\")\n",
    "    print(f\"  Recall:    {boundary_recall:.3f} (true boundaries that were detected)\")\n",
    "    \n",
    "    print(f\"\\nSegment Purity:\")\n",
    "    print(f\"  Mean purity: {np.mean(purities):.3f} (1.0 = perfect, each segment is one room)\")\n",
    "    print(f\"  Median purity: {np.median(purities):.3f}\")\n",
    "    print(f\"  Min purity: {np.min(purities):.3f}\")\n",
    "    \n",
    "    # Show worst segments (mixed rooms)\n",
    "    print(f\"\\nWorst Segments (most mixed):\")\n",
    "    worst_segments = sorted(detected_segments_info, key=lambda x: x['purity'])[:5]\n",
    "    for seg in worst_segments:\n",
    "        print(f\"  Frames {seg['start']}-{seg['end']} (len={seg['length']}): \"\n",
    "              f\"purity={seg['purity']:.3f}, {seg['num_rooms']} rooms, dominant={seg['dominant_room']}\")\n",
    "    \n",
    "    return {\n",
    "        'detected_changes': detected_changes,\n",
    "        'true_changes': true_changes,\n",
    "        'boundary_precision': boundary_precision,\n",
    "        'boundary_recall': boundary_recall,\n",
    "        'mean_purity': np.mean(purities),\n",
    "        'segments_info': detected_segments_info\n",
    "    }\n",
    "\n",
    "print(\"âœ… Change point detection evaluation function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8abc73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Change Point Detection Quality\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CHANGE POINT DETECTION EVALUATION (penalty=5)\n",
      "================================================================================\n",
      "True room changes: 51\n",
      "Detected changes:  23\n",
      "\n",
      "Boundary Detection (Â±5 frame tolerance):\n",
      "  Precision: 0.609 (detected boundaries that are correct)\n",
      "  Recall:    0.373 (true boundaries that were detected)\n",
      "\n",
      "Segment Purity:\n",
      "  Mean purity: 0.822 (1.0 = perfect, each segment is one room)\n",
      "  Median purity: 0.854\n",
      "  Min purity: 0.409\n",
      "\n",
      "Worst Segments (most mixed):\n",
      "  Frames 1636-1724 (len=88): purity=0.409, 4 rooms, dominant=cleaning\n",
      "  Frames 1001-1122 (len=121): purity=0.529, 3 rooms, dominant=kitchen\n",
      "  Frames 1280-1395 (len=115): purity=0.565, 3 rooms, dominant=513\n",
      "  Frames 2322-2399 (len=77): purity=0.636, 2 rooms, dominant=kitchen\n",
      "  Frames 1883-2080 (len=197): purity=0.701, 2 rooms, dominant=kitchen\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CHANGE POINT DETECTION EVALUATION (penalty=10)\n",
      "================================================================================\n",
      "True room changes: 51\n",
      "Detected changes:  12\n",
      "\n",
      "Boundary Detection (Â±5 frame tolerance):\n",
      "  Precision: 0.583 (detected boundaries that are correct)\n",
      "  Recall:    0.157 (true boundaries that were detected)\n",
      "\n",
      "Segment Purity:\n",
      "  Mean purity: 0.772 (1.0 = perfect, each segment is one room)\n",
      "  Median purity: 0.727\n",
      "  Min purity: 0.469\n",
      "\n",
      "Worst Segments (most mixed):\n",
      "  Frames 1377-1878 (len=501): purity=0.469, 6 rooms, dominant=nurse station\n",
      "  Frames 998-1281 (len=283): purity=0.512, 4 rooms, dominant=kitchen\n",
      "  Frames 2321-2399 (len=78): purity=0.628, 2 rooms, dominant=kitchen\n",
      "  Frames 1281-1377 (len=96): purity=0.677, 3 rooms, dominant=513\n",
      "  Frames 1878-2080 (len=202): purity=0.683, 2 rooms, dominant=kitchen\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CHANGE POINT DETECTION EVALUATION (penalty=20)\n",
      "================================================================================\n",
      "True room changes: 51\n",
      "Detected changes:  5\n",
      "\n",
      "Boundary Detection (Â±5 frame tolerance):\n",
      "  Precision: 0.600 (detected boundaries that are correct)\n",
      "  Recall:    0.078 (true boundaries that were detected)\n",
      "\n",
      "Segment Purity:\n",
      "  Mean purity: 0.630 (1.0 = perfect, each segment is one room)\n",
      "  Median purity: 0.649\n",
      "  Min purity: 0.278\n",
      "\n",
      "Worst Segments (most mixed):\n",
      "  Frames 985-1877 (len=892): purity=0.278, 9 rooms, dominant=cafeteria\n",
      "  Frames 2305-2481 (len=176): purity=0.443, 3 rooms, dominant=nurse station\n",
      "  Frames 216-985 (len=769): purity=0.649, 7 rooms, dominant=nurse station\n",
      "  Frames 1877-2212 (len=335): purity=0.791, 3 rooms, dominant=kitchen\n",
      "  Frames 2212-2305 (len=93): purity=0.989, 2 rooms, dominant=523\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m penalty \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m50\u001b[39m]:\n\u001b[1;32m----> 5\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_change_point_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     results[penalty] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m, in \u001b[0;36mevaluate_change_point_detection\u001b[1;34m(test_df, penalty, min_size)\u001b[0m\n\u001b[0;32m     16\u001b[0m algo \u001b[38;5;241m=\u001b[39m Pelt(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m\"\u001b[39m, min_size\u001b[38;5;241m=\u001b[39mmin_size, jump\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m algo\u001b[38;5;241m.\u001b[39mfit(beacon_sequence)\n\u001b[1;32m---> 18\u001b[0m detected_changes \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Get TRUE room change points\u001b[39;00m\n\u001b[0;32m     21\u001b[0m test_vectors[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroom_changed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (test_vectors[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroom\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m test_vectors[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroom\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshift())\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ruptures\\detection\\pelt.py:131\u001b[0m, in \u001b[0;36mPelt.predict\u001b[1;34m(self, pen)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sanity_check(\n\u001b[0;32m    124\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    125\u001b[0m     n_bkps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    126\u001b[0m     jump\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjump,\n\u001b[0;32m    127\u001b[0m     min_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_size,\n\u001b[0;32m    128\u001b[0m ):\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadSegmentationParameters\n\u001b[1;32m--> 131\u001b[0m partition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_seg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m bkps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(e \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m partition\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bkps\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ruptures\\detection\\pelt.py:72\u001b[0m, in \u001b[0;36mPelt._seg\u001b[1;34m(self, pen)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# we update with the right partition\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     tmp_partition\u001b[38;5;241m.\u001b[39mupdate({(t, bkp): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbkp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m pen})\n\u001b[0;32m     73\u001b[0m     subproblems\u001b[38;5;241m.\u001b[39mappend(tmp_partition)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# finding the optimal partition\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ruptures\\costs\\costrbf.py:81\u001b[0m, in \u001b[0;36mCostRbf.error\u001b[1;34m(self, start, end)\u001b[0m\n\u001b[0;32m     79\u001b[0m sub_gram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgram[start:end, start:end]\n\u001b[0;32m     80\u001b[0m val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiagonal(sub_gram)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m---> 81\u001b[0m val \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43msub_gram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m (end \u001b[38;5;241m-\u001b[39m start)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:52\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     51\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Testing Change Point Detection Quality\\n\")\n",
    "\n",
    "results = {}\n",
    "for penalty in [5, 10, 20, 30, 50]:\n",
    "    result = evaluate_change_point_detection(test_df, penalty=penalty, min_size=5)\n",
    "    results[penalty] = result\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff244b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: Which penalty works best?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = []\n",
    "for penalty, result in results.items():\n",
    "    comparison.append({\n",
    "        'Penalty': penalty,\n",
    "        'Precision': f\"{result['boundary_precision']:.3f}\",\n",
    "        'Recall': f\"{result['boundary_recall']:.3f}\",\n",
    "        'Purity': f\"{result['mean_purity']:.3f}\",\n",
    "        'Num Segments': len(result['segments_info'])\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ’¡ Look for:\")\n",
    "print(\"   â€¢ Precision > 0.6 (not too many false alarms)\")\n",
    "print(\"   â€¢ Recall > 0.7 (catches most real transitions)\")\n",
    "print(\"   â€¢ Purity > 0.8 (segments are mostly one room)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

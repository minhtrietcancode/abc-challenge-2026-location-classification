{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCteGDqVMHm1",
        "outputId": "f734116e-8c0d-484a-8622-de91172eceb0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from tensorflow.keras.layers import Bidirectional, GRU\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ All imports successful\")"
      ],
      "metadata": {
        "id": "1g2zbYa7z3B-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4231b07-8b53-4a32-b859-7ebc6658c24d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_filter_fold(i):\n",
        "    train_dir = f'/content/drive/MyDrive/split_data/fold{i}/train.csv'\n",
        "    test_dir = f'/content/drive/MyDrive/split_data/fold{i}/test.csv'\n",
        "    train_df = pd.read_csv(train_dir)\n",
        "    test_df = pd.read_csv(test_dir)\n",
        "\n",
        "    train_labels = list(train_df['room'].unique())\n",
        "    test_labels = list(test_df['room'].unique())\n",
        "    common_labels = list(set(train_labels) & set(test_labels))\n",
        "\n",
        "    train_df = train_df[train_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "    test_df = test_df[test_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Load all 4 folds\n",
        "train_df_1, test_df_1 = load_and_filter_fold(1)\n",
        "train_df_2, test_df_2 = load_and_filter_fold(2)\n",
        "train_df_3, test_df_3 = load_and_filter_fold(3)\n",
        "train_df_4, test_df_4 = load_and_filter_fold(4)\n",
        "\n",
        "print(\"✓ All folds loaded\")"
      ],
      "metadata": {
        "id": "e_L4-lEf0AOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd4d6f84-e6d3-411d-9f74-3d9529c924f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All folds loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "def create_room_groups(df):\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    df['room_group'] = (df['room'] != df['room'].shift()).cumsum()\n",
        "    return df\n",
        "\n",
        "def create_beacon_count_vectors(df):\n",
        "    vectors = []\n",
        "    for _, group in df.groupby('timestamp'):\n",
        "        beacon_counts = group['mac address'].value_counts()\n",
        "        total_readings = len(group)\n",
        "\n",
        "        vector = [0.0] * 23\n",
        "        for beacon_id, count in beacon_counts.items():\n",
        "            if 1 <= beacon_id <= 23:\n",
        "                vector[beacon_id - 1] = count / total_readings\n",
        "\n",
        "        vectors.append({\n",
        "            'timestamp': group['timestamp'].iloc[0],\n",
        "            'room': group['room'].iloc[0],\n",
        "            'room_group': group['room_group'].iloc[0],\n",
        "            'beacon_vector': vector\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(vectors)\n",
        "\n",
        "def create_sequences_from_groups(vector_df, min_length=3, max_length=50):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for (room, room_group), group in vector_df.groupby(['room', 'room_group']):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=False)\n",
        "        seq_length = len(group)\n",
        "\n",
        "        if seq_length < min_length:\n",
        "            continue\n",
        "\n",
        "        if seq_length > max_length:\n",
        "            group = group.tail(max_length)\n",
        "            seq_length = max_length\n",
        "\n",
        "        sequence = [row['beacon_vector'] for _, row in group.iterrows()]\n",
        "        sequences.append(sequence)\n",
        "        labels.append(room)\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "def build_gru_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Regular (unidirectional) GRU:\n",
        "    - Even simpler than Bidirectional GRU\n",
        "    - Might generalize even better to noisy data\n",
        "    - Faster training\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Masking(mask_value=0.0, input_shape=input_shape),\n",
        "\n",
        "        GRU(128, return_sequences=True),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        GRU(64, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"✅ Helper functions defined (with regular GRU)\")"
      ],
      "metadata": {
        "id": "3-iQL_Go0AX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01d75a8-73d7-4e56-a0d9-4ef589c07a12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Helper functions defined (with regular GRU)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline_single_seed(train_df, test_df, seed, verbose=False):\n",
        "    \"\"\"Run pipeline for a single seed\"\"\"\n",
        "    set_seeds(seed)\n",
        "\n",
        "    # Preprocessing\n",
        "    train_df = create_room_groups(train_df)\n",
        "    test_df = create_room_groups(test_df)\n",
        "\n",
        "    train_vectors = create_beacon_count_vectors(train_df)\n",
        "    test_vectors = create_beacon_count_vectors(test_df)\n",
        "\n",
        "    # Sequence creation\n",
        "    X_train, y_train = create_sequences_from_groups(train_vectors)\n",
        "    X_test, y_test = create_sequences_from_groups(test_vectors)\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(y_train + y_test)\n",
        "    y_train_encoded = label_encoder.transform(y_train)\n",
        "    y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "    # Pad sequences\n",
        "    max_seq_length = 50\n",
        "    X_train_padded = pad_sequences(X_train, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "    X_test_padded = pad_sequences(X_test, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(y_train_encoded),\n",
        "        y=y_train_encoded\n",
        "    )\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    # Build and train model\n",
        "    model = build_gru_model(\n",
        "        input_shape=(max_seq_length, 23),\n",
        "        num_classes=len(label_encoder.classes_)\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=0)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_padded, y_train_encoded,\n",
        "        validation_data=(X_test_padded, y_test_encoded),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        class_weight=class_weight_dict,\n",
        "        callbacks=callbacks,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Predictions (sequence level only - no frame propagation)\n",
        "    y_pred_probs = model.predict(X_test_padded, verbose=0)\n",
        "    y_pred_encoded = np.argmax(y_pred_probs, axis=1)\n",
        "    y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "    # Calculate macro F1\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    # Calculate per-class F1\n",
        "    per_class_f1 = f1_score(y_test, y_pred, average=None, labels=label_encoder.classes_, zero_division=0)\n",
        "    per_class_f1_dict = {label: f1 for label, f1 in zip(label_encoder.classes_, per_class_f1)}\n",
        "\n",
        "    return {\n",
        "        'seed': seed,\n",
        "        'macro_f1': macro_f1,\n",
        "        'per_class_f1': per_class_f1_dict\n",
        "    }\n",
        "\n",
        "print(\"✓ Pipeline function defined\")"
      ],
      "metadata": {
        "id": "AKeSNENp0AdC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1fc0a47-06b0-4436-a271-4b67106a0fa6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Pipeline function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run 10 seeds for each of 4 folds\n",
        "seeds = [42, 123, 456, 789, 2024, 3141, 5926, 8888, 1337, 9999]\n",
        "folds = {\n",
        "    1: (train_df_1, test_df_1),\n",
        "    2: (train_df_2, test_df_2),\n",
        "    3: (train_df_3, test_df_3),\n",
        "    4: (train_df_4, test_df_4)\n",
        "}\n",
        "\n",
        "all_fold_results = {}\n",
        "\n",
        "for fold_num, (train_df, test_df) in folds.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"PROCESSING FOLD {fold_num}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    fold_results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"  Running seed {seed}...\", end=\" \")\n",
        "        result = run_pipeline_single_seed(train_df, test_df, seed, verbose=False)\n",
        "        fold_results.append(result)\n",
        "        print(f\"Macro F1: {result['macro_f1']:.4f}\")\n",
        "\n",
        "    all_fold_results[fold_num] = fold_results\n",
        "\n",
        "    # Calculate fold statistics\n",
        "    macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "    print(f\"\\n  Fold {fold_num} Summary:\")\n",
        "    print(f\"    Mean Macro F1: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\")\n",
        "    print(f\"    Min: {np.min(macro_f1_scores):.4f}, Max: {np.max(macro_f1_scores):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ALL FOLDS COMPLETED!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "UwtmIkdc0AkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df955593-f55f-4066-90ca-669038407ec6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 1\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.4806\n",
            "  Running seed 123... Macro F1: 0.5221\n",
            "  Running seed 456... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a5248a78d60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a5248a78d60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro F1: 0.5358\n",
            "  Running seed 789... Macro F1: 0.5672\n",
            "  Running seed 2024... Macro F1: 0.4309\n",
            "  Running seed 3141... Macro F1: 0.4997\n",
            "  Running seed 5926... Macro F1: 0.5053\n",
            "  Running seed 8888... Macro F1: 0.4389\n",
            "  Running seed 1337... Macro F1: 0.5216\n",
            "  Running seed 9999... Macro F1: 0.4467\n",
            "\n",
            "  Fold 1 Summary:\n",
            "    Mean Macro F1: 0.4949 ± 0.0427\n",
            "    Min: 0.4309, Max: 0.5672\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 2\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.4226\n",
            "  Running seed 123... Macro F1: 0.4384\n",
            "  Running seed 456... Macro F1: 0.5043\n",
            "  Running seed 789... Macro F1: 0.4660\n",
            "  Running seed 2024... Macro F1: 0.4804\n",
            "  Running seed 3141... Macro F1: 0.3136\n",
            "  Running seed 5926... Macro F1: 0.4363\n",
            "  Running seed 8888... Macro F1: 0.3096\n",
            "  Running seed 1337... Macro F1: 0.4497\n",
            "  Running seed 9999... Macro F1: 0.4292\n",
            "\n",
            "  Fold 2 Summary:\n",
            "    Mean Macro F1: 0.4250 ± 0.0614\n",
            "    Min: 0.3096, Max: 0.5043\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 3\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.2870\n",
            "  Running seed 123... Macro F1: 0.5707\n",
            "  Running seed 456... Macro F1: 0.5205\n",
            "  Running seed 789... Macro F1: 0.4696\n",
            "  Running seed 2024... Macro F1: 0.4925\n",
            "  Running seed 3141... Macro F1: 0.4567\n",
            "  Running seed 5926... Macro F1: 0.5424\n",
            "  Running seed 8888... Macro F1: 0.4102\n",
            "  Running seed 1337... Macro F1: 0.4672\n",
            "  Running seed 9999... Macro F1: 0.5996\n",
            "\n",
            "  Fold 3 Summary:\n",
            "    Mean Macro F1: 0.4816 ± 0.0843\n",
            "    Min: 0.2870, Max: 0.5996\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 4\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.5788\n",
            "  Running seed 123... Macro F1: 0.5386\n",
            "  Running seed 456... Macro F1: 0.4535\n",
            "  Running seed 789... Macro F1: 0.5766\n",
            "  Running seed 2024... Macro F1: 0.4450\n",
            "  Running seed 3141... Macro F1: 0.5325\n",
            "  Running seed 5926... Macro F1: 0.4493\n",
            "  Running seed 8888... Macro F1: 0.4145\n",
            "  Running seed 1337... Macro F1: 0.3156\n",
            "  Running seed 9999... Macro F1: 0.4732\n",
            "\n",
            "  Fold 4 Summary:\n",
            "    Mean Macro F1: 0.4778 ± 0.0771\n",
            "    Min: 0.3156, Max: 0.5788\n",
            "\n",
            "================================================================================\n",
            "ALL FOLDS COMPLETED!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to text file\n",
        "with open('4fold_10seed_results.txt', 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"4-FOLD CROSS-VALIDATION WITH 10 SEEDS PER FOLD\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    # Overall summary\n",
        "    all_macro_f1 = []\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        fold_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "        all_macro_f1.extend(fold_scores)\n",
        "\n",
        "    f.write(\"OVERALL RESULTS (40 runs total):\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Mean Macro F1: {np.mean(all_macro_f1):.4f} ± {np.std(all_macro_f1):.4f}\\n\")\n",
        "    f.write(f\"Min: {np.min(all_macro_f1):.4f}, Max: {np.max(all_macro_f1):.4f}\\n\\n\")\n",
        "\n",
        "    # Per-fold results\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        f.write(f\"\\n{'='*80}\\n\")\n",
        "        f.write(f\"FOLD {fold_num} RESULTS\\n\")\n",
        "        f.write(f\"{'='*80}\\n\\n\")\n",
        "\n",
        "        fold_results = all_fold_results[fold_num]\n",
        "        macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "\n",
        "        f.write(f\"Macro F1 Scores (10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        for i, result in enumerate(fold_results):\n",
        "            f.write(f\"  Seed {result['seed']:5d}: {result['macro_f1']:.4f}\\n\")\n",
        "\n",
        "        f.write(f\"\\nStatistics:\\n\")\n",
        "        f.write(f\"  Mean: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Min:  {np.min(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Max:  {np.max(macro_f1_scores):.4f}\\n\")\n",
        "\n",
        "        # Per-class F1 (averaged across 10 seeds)\n",
        "        f.write(f\"\\nPer-Class F1 Scores (averaged across 10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "\n",
        "        # Collect all class names\n",
        "        all_classes = set()\n",
        "        for result in fold_results:\n",
        "            all_classes.update(result['per_class_f1'].keys())\n",
        "\n",
        "        # Average per-class F1 across seeds\n",
        "        for class_name in sorted(all_classes):\n",
        "            class_f1_scores = [r['per_class_f1'].get(class_name, 0) for r in fold_results]\n",
        "            mean_f1 = np.mean(class_f1_scores)\n",
        "            std_f1 = np.std(class_f1_scores)\n",
        "            f.write(f\"  {class_name:20s}: {mean_f1:.4f} ± {std_f1:.4f}\\n\")\n",
        "\n",
        "print(\"✅ Results saved to 4fold_10seed_results.txt\")"
      ],
      "metadata": {
        "id": "qW1ONWux0Aqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2935fa31-cf26-4f1e-e0f1-1ec23a30ece2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Results saved to 4fold_10seed_results.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY - 4 FOLDS × 10 SEEDS = 40 TOTAL RUNS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    macro_f1_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "    print(f\"Fold {fold_num}: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\")\n",
        "\n",
        "all_macro_f1 = []\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    all_macro_f1.extend([r['macro_f1'] for r in all_fold_results[fold_num]])\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Overall Mean: {np.mean(all_macro_f1):.4f} ± {np.std(all_macro_f1):.4f}\")\n",
        "print(f\"{'='*80}\")"
      ],
      "metadata": {
        "id": "DvBBNZMT0JNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc1c998-8c8d-4a04-cd56-e215ce3677a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY - 4 FOLDS × 10 SEEDS = 40 TOTAL RUNS\n",
            "================================================================================\n",
            "\n",
            "Fold 1: 0.4949 ± 0.0427\n",
            "Fold 2: 0.4250 ± 0.0614\n",
            "Fold 3: 0.4816 ± 0.0843\n",
            "Fold 4: 0.4778 ± 0.0771\n",
            "\n",
            "================================================================================\n",
            "Overall Mean: 0.4698 ± 0.0733\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Setup and Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ All imports successful\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g2zbYa7z3B-",
        "outputId": "d7b249a5-7f1e-4afc-f197-9da21716abc6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_filter_fold(i):\n",
        "    train_dir = f'/content/drive/MyDrive/split_data/fold{i}/train.csv'\n",
        "    test_dir = f'/content/drive/MyDrive/split_data/fold{i}/test.csv'\n",
        "    train_df = pd.read_csv(train_dir)\n",
        "    test_df = pd.read_csv(test_dir)\n",
        "\n",
        "    train_labels = list(train_df['room'].unique())\n",
        "    test_labels = list(test_df['room'].unique())\n",
        "    common_labels = list(set(train_labels) & set(test_labels))\n",
        "\n",
        "    train_df = train_df[train_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "    test_df = test_df[test_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Load all 4 folds\n",
        "train_df_1, test_df_1 = load_and_filter_fold(1)\n",
        "train_df_2, test_df_2 = load_and_filter_fold(2)\n",
        "train_df_3, test_df_3 = load_and_filter_fold(3)\n",
        "train_df_4, test_df_4 = load_and_filter_fold(4)\n",
        "\n",
        "print(\"✓ All folds loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_L4-lEf0AOf",
        "outputId": "3deaf186-fc4e-4ea0-e72f-05177eebb173"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All folds loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "def create_room_groups(df):\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    df['room_group'] = (df['room'] != df['room'].shift()).cumsum()\n",
        "    return df\n",
        "\n",
        "def create_beacon_count_vectors(df):\n",
        "    vectors = []\n",
        "    for _, group in df.groupby('timestamp'):\n",
        "        beacon_counts = group['mac address'].value_counts()\n",
        "        total_readings = len(group)\n",
        "\n",
        "        vector = [0.0] * 23\n",
        "        for beacon_id, count in beacon_counts.items():\n",
        "            if 1 <= beacon_id <= 23:\n",
        "                vector[beacon_id - 1] = count / total_readings\n",
        "\n",
        "        vectors.append({\n",
        "            'timestamp': group['timestamp'].iloc[0],\n",
        "            'room': group['room'].iloc[0],\n",
        "            'room_group': group['room_group'].iloc[0],\n",
        "            'beacon_vector': vector\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(vectors)\n",
        "\n",
        "def create_sequences_from_groups(vector_df, min_length=3, max_length=50):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for (room, room_group), group in vector_df.groupby(['room', 'room_group']):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=False)\n",
        "        seq_length = len(group)\n",
        "\n",
        "        if seq_length < min_length:\n",
        "            continue\n",
        "\n",
        "        if seq_length > max_length:\n",
        "            group = group.tail(max_length)\n",
        "            seq_length = max_length\n",
        "\n",
        "        sequence = [row['beacon_vector'] for _, row in group.iterrows()]\n",
        "        sequences.append(sequence)\n",
        "        labels.append(room)\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "def build_cnn_lstm_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    CNN-LSTM Architecture:\n",
        "    - 1D CNN layers extract local beacon co-occurrence patterns\n",
        "    - LSTM layers model temporal evolution of these patterns\n",
        "    - Dense layers perform final classification\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential([\n",
        "        # Masking layer for padded sequences\n",
        "        Masking(mask_value=0.0, input_shape=input_shape),\n",
        "\n",
        "        # First CNN block - detect local beacon patterns\n",
        "        Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Second CNN block - learn complex beacon combinations\n",
        "        Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Third CNN block - higher-level pattern extraction\n",
        "        Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # LSTM layers - model temporal evolution\n",
        "        LSTM(128, return_sequences=True),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Dense layers - final classification\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"✅ Helper functions defined (with CNN-LSTM architecture)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-iQL_Go0AX-",
        "outputId": "fd665b5b-b89e-4a55-8e63-81bb674dac1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Helper functions defined (with CNN-LSTM architecture)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline_single_seed(train_df, test_df, seed, verbose=False):\n",
        "    \"\"\"Run pipeline for a single seed\"\"\"\n",
        "    set_seeds(seed)\n",
        "\n",
        "    # Preprocessing\n",
        "    train_df = create_room_groups(train_df)\n",
        "    test_df = create_room_groups(test_df)\n",
        "\n",
        "    train_vectors = create_beacon_count_vectors(train_df)\n",
        "    test_vectors = create_beacon_count_vectors(test_df)\n",
        "\n",
        "    # Sequence creation\n",
        "    X_train, y_train = create_sequences_from_groups(train_vectors)\n",
        "    X_test, y_test = create_sequences_from_groups(test_vectors)\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(y_train + y_test)\n",
        "    y_train_encoded = label_encoder.transform(y_train)\n",
        "    y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "    # Pad sequences\n",
        "    max_seq_length = 50\n",
        "    X_train_padded = pad_sequences(X_train, maxlen=max_seq_length, dtype='float32', padding='pre', value=0.0)\n",
        "    X_test_padded = pad_sequences(X_test, maxlen=max_seq_length, dtype='float32', padding='pre', value=0.0)\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(y_train_encoded),\n",
        "        y=y_train_encoded\n",
        "    )\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    # Build and train model\n",
        "    model = build_cnn_lstm_model(\n",
        "        input_shape=(max_seq_length, 23),\n",
        "        num_classes=len(label_encoder.classes_)\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=0)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_padded, y_train_encoded,\n",
        "        validation_data=(X_test_padded, y_test_encoded),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        class_weight=class_weight_dict,\n",
        "        callbacks=callbacks,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Predictions (sequence level only - no frame propagation)\n",
        "    y_pred_probs = model.predict(X_test_padded, verbose=0)\n",
        "    y_pred_encoded = np.argmax(y_pred_probs, axis=1)\n",
        "    y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "    # Calculate macro F1\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    # Calculate per-class F1\n",
        "    per_class_f1 = f1_score(y_test, y_pred, average=None, labels=label_encoder.classes_, zero_division=0)\n",
        "    per_class_f1_dict = {label: f1 for label, f1 in zip(label_encoder.classes_, per_class_f1)}\n",
        "\n",
        "    return {\n",
        "        'seed': seed,\n",
        "        'macro_f1': macro_f1,\n",
        "        'per_class_f1': per_class_f1_dict\n",
        "    }\n",
        "\n",
        "print(\"✓ Pipeline function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKeSNENp0AdC",
        "outputId": "3458875a-bee1-4c81-92f4-fbec05530ac2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Pipeline function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run 10 seeds for each of 4 folds\n",
        "seeds = [42, 123, 456, 789, 2024, 3141, 5926, 8888, 1337, 9999]\n",
        "folds = {\n",
        "    1: (train_df_1, test_df_1),\n",
        "    2: (train_df_2, test_df_2),\n",
        "    3: (train_df_3, test_df_3),\n",
        "    4: (train_df_4, test_df_4)\n",
        "}\n",
        "\n",
        "all_fold_results = {}\n",
        "\n",
        "for fold_num, (train_df, test_df) in folds.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"PROCESSING FOLD {fold_num}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    fold_results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"  Running seed {seed}...\", end=\" \")\n",
        "        result = run_pipeline_single_seed(train_df, test_df, seed, verbose=False)\n",
        "        fold_results.append(result)\n",
        "        print(f\"Macro F1: {result['macro_f1']:.4f}\")\n",
        "\n",
        "    all_fold_results[fold_num] = fold_results\n",
        "\n",
        "    # Calculate fold statistics\n",
        "    macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "    print(f\"\\n  Fold {fold_num} Summary:\")\n",
        "    print(f\"    Mean Macro F1: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\")\n",
        "    print(f\"    Min: {np.min(macro_f1_scores):.4f}, Max: {np.max(macro_f1_scores):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ALL FOLDS COMPLETED!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwtmIkdc0AkP",
        "outputId": "3a269f81-127b-487d-93a7-c84cffe5cd4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 1\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.0487\n",
            "  Running seed 123... Macro F1: 0.2783\n",
            "  Running seed 456... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78c073d44720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78c073d44720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro F1: 0.5137\n",
            "  Running seed 789... Macro F1: 0.1522\n",
            "  Running seed 2024... Macro F1: 0.0030\n",
            "  Running seed 3141... Macro F1: 0.1484\n",
            "  Running seed 5926... Macro F1: 0.2083\n",
            "  Running seed 8888... Macro F1: 0.1114\n",
            "  Running seed 1337... Macro F1: 0.0314\n",
            "  Running seed 9999... Macro F1: 0.1110\n",
            "\n",
            "  Fold 1 Summary:\n",
            "    Mean Macro F1: 0.1607 ± 0.1414\n",
            "    Min: 0.0030, Max: 0.5137\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 2\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.0463\n",
            "  Running seed 123... Macro F1: 0.1161\n",
            "  Running seed 456... Macro F1: 0.0836\n",
            "  Running seed 789... Macro F1: 0.4297\n",
            "  Running seed 2024... Macro F1: 0.0040\n",
            "  Running seed 3141... Macro F1: 0.0568\n",
            "  Running seed 5926... Macro F1: 0.0286\n",
            "  Running seed 8888... Macro F1: 0.0743\n",
            "  Running seed 1337... Macro F1: 0.0243\n",
            "  Running seed 9999... Macro F1: 0.0124\n",
            "\n",
            "  Fold 2 Summary:\n",
            "    Mean Macro F1: 0.0876 ± 0.1187\n",
            "    Min: 0.0040, Max: 0.4297\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 3\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.0233\n",
            "  Running seed 123... Macro F1: 0.0233\n",
            "  Running seed 456... Macro F1: 0.4098\n",
            "  Running seed 789... Macro F1: 0.0233\n",
            "  Running seed 2024... Macro F1: 0.0233\n",
            "  Running seed 3141... Macro F1: 0.0020\n",
            "  Running seed 5926... Macro F1: 0.5717\n",
            "  Running seed 8888... Macro F1: 0.3487\n",
            "  Running seed 1337... Macro F1: 0.0228\n",
            "  Running seed 9999... Macro F1: 0.0123\n",
            "\n",
            "  Fold 3 Summary:\n",
            "    Mean Macro F1: 0.1461 ± 0.2015\n",
            "    Min: 0.0020, Max: 0.5717\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 4\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.0445\n",
            "  Running seed 123... Macro F1: 0.1618\n",
            "  Running seed 456... Macro F1: 0.1249\n",
            "  Running seed 789... Macro F1: 0.0373\n",
            "  Running seed 2024... Macro F1: 0.5428\n",
            "  Running seed 3141... Macro F1: 0.5727\n",
            "  Running seed 5926... Macro F1: 0.1010\n",
            "  Running seed 8888... Macro F1: 0.0446\n",
            "  Running seed 1337... Macro F1: 0.0067\n",
            "  Running seed 9999... Macro F1: 0.0446\n",
            "\n",
            "  Fold 4 Summary:\n",
            "    Mean Macro F1: 0.1681 ± 0.1999\n",
            "    Min: 0.0067, Max: 0.5727\n",
            "\n",
            "================================================================================\n",
            "ALL FOLDS COMPLETED!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to text file\n",
        "with open('4fold_10seed_results.txt', 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"4-FOLD CROSS-VALIDATION WITH 10 SEEDS PER FOLD\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    # Overall summary\n",
        "    all_macro_f1 = []\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        fold_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "        all_macro_f1.extend(fold_scores)\n",
        "\n",
        "    f.write(\"OVERALL RESULTS (40 runs total):\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Mean Macro F1: {np.mean(all_macro_f1):.4f} ± {np.std(all_macro_f1):.4f}\\n\")\n",
        "    f.write(f\"Min: {np.min(all_macro_f1):.4f}, Max: {np.max(all_macro_f1):.4f}\\n\\n\")\n",
        "\n",
        "    # Per-fold results\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        f.write(f\"\\n{'='*80}\\n\")\n",
        "        f.write(f\"FOLD {fold_num} RESULTS\\n\")\n",
        "        f.write(f\"{'='*80}\\n\\n\")\n",
        "\n",
        "        fold_results = all_fold_results[fold_num]\n",
        "        macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "\n",
        "        f.write(f\"Macro F1 Scores (10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        for i, result in enumerate(fold_results):\n",
        "            f.write(f\"  Seed {result['seed']:5d}: {result['macro_f1']:.4f}\\n\")\n",
        "\n",
        "        f.write(f\"\\nStatistics:\\n\")\n",
        "        f.write(f\"  Mean: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Min:  {np.min(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Max:  {np.max(macro_f1_scores):.4f}\\n\")\n",
        "\n",
        "        # Per-class F1 (averaged across 10 seeds)\n",
        "        f.write(f\"\\nPer-Class F1 Scores (averaged across 10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "\n",
        "        # Collect all class names\n",
        "        all_classes = set()\n",
        "        for result in fold_results:\n",
        "            all_classes.update(result['per_class_f1'].keys())\n",
        "\n",
        "        # Average per-class F1 across seeds\n",
        "        for class_name in sorted(all_classes):\n",
        "            class_f1_scores = [r['per_class_f1'].get(class_name, 0) for r in fold_results]\n",
        "            mean_f1 = np.mean(class_f1_scores)\n",
        "            std_f1 = np.std(class_f1_scores)\n",
        "            f.write(f\"  {class_name:20s}: {mean_f1:.4f} ± {std_f1:.4f}\\n\")\n",
        "\n",
        "print(\"✅ Results saved to 4fold_10seed_results.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW1ONWux0Aqi",
        "outputId": "ddde2652-37f3-4918-d83f-50951e3d3184"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Results saved to 4fold_10seed_results.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY - 4 FOLDS × 10 SEEDS = 40 TOTAL RUNS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    macro_f1_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "    print(f\"Fold {fold_num}: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\")\n",
        "\n",
        "all_macro_f1 = []\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    all_macro_f1.extend([r['macro_f1'] for r in all_fold_results[fold_num]])\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Overall Mean: {np.mean(all_macro_f1):.4f} ± {np.std(all_macro_f1):.4f}\")\n",
        "print(f\"{'='*80}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvBBNZMT0JNw",
        "outputId": "5162a7bb-ae49-4991-e90d-f9a3bb6f450c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY - 4 FOLDS × 10 SEEDS = 40 TOTAL RUNS\n",
            "================================================================================\n",
            "\n",
            "Fold 1: 0.1607 ± 0.1414\n",
            "Fold 2: 0.0876 ± 0.1187\n",
            "Fold 3: 0.1461 ± 0.2015\n",
            "Fold 4: 0.1681 ± 0.1999\n",
            "\n",
            "================================================================================\n",
            "Overall Mean: 0.1406 ± 0.1722\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}
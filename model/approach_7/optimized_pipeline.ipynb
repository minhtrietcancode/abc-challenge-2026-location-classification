{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e60ca7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 920927 windows, 16 rooms\n",
      "Test set: 141425 windows, 16 rooms\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Load and prepare data (SAME AS BEFORE)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv(\"../../cleaned_dataset/split_data/model_selection/train.csv\")\n",
    "test_df = pd.read_csv(\"../../cleaned_dataset/split_data/model_selection/test.csv\")\n",
    "\n",
    "# Get common labels\n",
    "train_labels = list(train_df['room'].unique())\n",
    "test_labels = list(test_df['room'].unique())\n",
    "common_labels = list(set(train_labels) & set(test_labels))\n",
    "\n",
    "# Filter to common labels\n",
    "train_df = train_df[train_df['room'].isin(common_labels)].reset_index(drop=True)\n",
    "test_df = test_df[test_df['room'].isin(common_labels)].reset_index(drop=True)\n",
    "\n",
    "# Sort by timestamp\n",
    "train_df = train_df.sort_values('timestamp').reset_index(drop=True)\n",
    "test_df = test_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} windows, {train_df['room'].nunique()} rooms\")\n",
    "print(f\"Test set: {len(test_df)} windows, {test_df['room'].nunique()} rooms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b13a8889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating beacon vectors with time_delta for train set...\n",
      "✓ Train vectors: 15052 windows\n",
      "\n",
      "Creating beacon vectors with time_delta for test set...\n",
      "✓ Test vectors: 5889 windows\n",
      "\n",
      "Example with time deltas:\n",
      "                  timestamp       room  time_delta\n",
      "0 2023-04-10 14:21:46+09:00    kitchen         0.0\n",
      "1 2023-04-10 14:21:47+09:00    kitchen         1.0\n",
      "2 2023-04-10 14:21:48+09:00    kitchen         1.0\n",
      "3 2023-04-10 14:21:49+09:00    kitchen         1.0\n",
      "4 2023-04-10 14:21:50+09:00    kitchen         1.0\n",
      "5 2023-04-10 14:21:57+09:00  cafeteria         7.0\n",
      "6 2023-04-10 14:21:58+09:00  cafeteria         1.0\n",
      "7 2023-04-10 14:21:59+09:00  cafeteria         1.0\n",
      "8 2023-04-10 14:22:06+09:00  cafeteria         7.0\n",
      "9 2023-04-10 14:22:07+09:00  cafeteria         1.0\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Create 23-dim beacon vectors WITH time_delta feature\n",
    "def create_beacon_vectors_with_time_delta(df):\n",
    "    \"\"\"\n",
    "    For each window, create:\n",
    "    - 23-dim beacon count vector\n",
    "    - time_delta (seconds since previous window)\n",
    "    \"\"\"\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    vectors = []\n",
    "    prev_timestamp = None\n",
    "    \n",
    "    for timestamp, group in df.groupby('timestamp'):\n",
    "        # Calculate time delta\n",
    "        if prev_timestamp is None:\n",
    "            time_delta = 0.0\n",
    "        else:\n",
    "            time_delta = (timestamp - prev_timestamp).total_seconds()\n",
    "        \n",
    "        # Count beacon frequencies\n",
    "        beacon_counts = group['mac address'].value_counts()\n",
    "        total_readings = len(group)\n",
    "        \n",
    "        # Create 23-dim vector\n",
    "        vector = [0.0] * 23\n",
    "        for beacon_id, count in beacon_counts.items():\n",
    "            if 1 <= beacon_id <= 23:\n",
    "                vector[beacon_id - 1] = count / total_readings\n",
    "        \n",
    "        vectors.append({\n",
    "            'timestamp': timestamp,\n",
    "            'room': group['room'].iloc[0],\n",
    "            'beacon_vector': vector,\n",
    "            'time_delta': time_delta\n",
    "        })\n",
    "        \n",
    "        prev_timestamp = timestamp\n",
    "    \n",
    "    return pd.DataFrame(vectors)\n",
    "\n",
    "# Create vectors\n",
    "print(\"Creating beacon vectors with time_delta for train set...\")\n",
    "train_vectors = create_beacon_vectors_with_time_delta(train_df)\n",
    "print(f\"✓ Train vectors: {len(train_vectors)} windows\")\n",
    "\n",
    "print(\"\\nCreating beacon vectors with time_delta for test set...\")\n",
    "test_vectors = create_beacon_vectors_with_time_delta(test_df)\n",
    "print(f\"✓ Test vectors: {len(test_vectors)} windows\")\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nExample with time deltas:\")\n",
    "print(train_vectors[['timestamp', 'room', 'time_delta']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76b3f1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sliding window sequences (window_size=100, stride=50)...\n",
      "\n",
      "✓ Train sequences: 300\n",
      "✓ Test sequences: 116\n",
      "\n",
      "Each sequence shape: (100, 24) (window_size, num_features)\n",
      "Features: 23 beacons + 1 time_delta = 24 features\n",
      "\n",
      "Example sequence (first 5 windows):\n",
      "  Window 0: time_delta=0.0s, room=kitchen\n",
      "  Window 1: time_delta=1.0s, room=kitchen\n",
      "  Window 2: time_delta=1.0s, room=kitchen\n",
      "  Window 3: time_delta=1.0s, room=kitchen\n",
      "  Window 4: time_delta=1.0s, room=kitchen\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Create sliding window sequences (sequence-to-sequence)\n",
    "def create_sliding_sequences(vector_df, window_size=100, stride=50):\n",
    "    \"\"\"\n",
    "    Create overlapping sequences with sliding window approach.\n",
    "    Each sequence contains window_size consecutive windows.\n",
    "    \n",
    "    Returns:\n",
    "    - X: List of sequences, each sequence is (window_size, 24) \n",
    "         where 24 = 23 beacons + 1 time_delta\n",
    "    - y: List of label sequences, each is (window_size,) room labels\n",
    "    \"\"\"\n",
    "    X_sequences = []\n",
    "    y_sequences = []\n",
    "    \n",
    "    # Get total number of windows\n",
    "    n_windows = len(vector_df)\n",
    "    \n",
    "    # Slide window across data\n",
    "    for start_idx in range(0, n_windows - window_size + 1, stride):\n",
    "        end_idx = start_idx + window_size\n",
    "        \n",
    "        sequence_data = vector_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Extract features: beacon_vector (23-dim) + time_delta (1-dim) = 24-dim\n",
    "        X_seq = []\n",
    "        y_seq = []\n",
    "        \n",
    "        for _, row in sequence_data.iterrows():\n",
    "            # Combine beacon vector with time_delta\n",
    "            features = row['beacon_vector'] + [row['time_delta']]\n",
    "            X_seq.append(features)\n",
    "            y_seq.append(row['room'])\n",
    "        \n",
    "        X_sequences.append(np.array(X_seq))\n",
    "        y_sequences.append(y_seq)\n",
    "    \n",
    "    return X_sequences, y_sequences\n",
    "\n",
    "# Create sequences\n",
    "window_size = 100  # 100-second windows\n",
    "stride = 50        # 50% overlap\n",
    "\n",
    "print(f\"Creating sliding window sequences (window_size={window_size}, stride={stride})...\")\n",
    "X_train_seq, y_train_seq = create_sliding_sequences(train_vectors, window_size, stride)\n",
    "X_test_seq, y_test_seq = create_sliding_sequences(test_vectors, window_size, stride)\n",
    "\n",
    "print(f\"\\n✓ Train sequences: {len(X_train_seq)}\")\n",
    "print(f\"✓ Test sequences: {len(X_test_seq)}\")\n",
    "print(f\"\\nEach sequence shape: {X_train_seq[0].shape} (window_size, num_features)\")\n",
    "print(f\"Features: 23 beacons + 1 time_delta = 24 features\")\n",
    "\n",
    "# Show example\n",
    "print(f\"\\nExample sequence (first 5 windows):\")\n",
    "for i in range(5):\n",
    "    print(f\"  Window {i}: time_delta={X_train_seq[0][i, -1]:.1f}s, room={y_train_seq[0][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe100645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 16\n",
      "Classes: ['501' '502' '506' '511' '512' '513' '517' '518' '520' '522' '523'\n",
      " 'cafeteria' 'cleaning' 'hallway' 'kitchen' 'nurse station']\n",
      "\n",
      "✓ Encoded train sequences: 300\n",
      "✓ Encoded test sequences: 116\n",
      "\n",
      "Example encoded sequence (first 5): [14 14 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Encode labels for sequence-to-sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fit label encoder on all unique rooms\n",
    "all_rooms = list(set(train_df['room'].unique()) | set(test_df['room'].unique()))\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_rooms)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Classes: {label_encoder.classes_}\")\n",
    "\n",
    "# Encode sequences (each window in sequence gets encoded)\n",
    "def encode_sequence_labels(y_sequences, label_encoder):\n",
    "    \"\"\"Encode labels for each window in each sequence\"\"\"\n",
    "    encoded_sequences = []\n",
    "    for y_seq in y_sequences:\n",
    "        encoded_seq = label_encoder.transform(y_seq)\n",
    "        encoded_sequences.append(encoded_seq)\n",
    "    return encoded_sequences\n",
    "\n",
    "y_train_encoded = encode_sequence_labels(y_train_seq, label_encoder)\n",
    "y_test_encoded = encode_sequence_labels(y_test_seq, label_encoder)\n",
    "\n",
    "print(f\"\\n✓ Encoded train sequences: {len(y_train_encoded)}\")\n",
    "print(f\"✓ Encoded test sequences: {len(y_test_encoded)}\")\n",
    "print(f\"\\nExample encoded sequence (first 5): {y_train_encoded[0][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98d0b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (300, 100, 24)\n",
      "  (num_sequences, window_size, num_features)\n",
      "\n",
      "y_train shape: (300, 100, 16)\n",
      "  (num_sequences, window_size, num_classes)\n",
      "\n",
      "X_test shape: (116, 100, 24)\n",
      "y_test shape: (116, 100, 16)\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Convert to numpy arrays and one-hot encode\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = np.array(X_train_seq)\n",
    "X_test = np.array(X_test_seq)\n",
    "\n",
    "# One-hot encode each window in each sequence\n",
    "y_train_onehot = np.array([to_categorical(seq, num_classes=num_classes) for seq in y_train_encoded])\n",
    "y_test_onehot = np.array([to_categorical(seq, num_classes=num_classes) for seq in y_test_encoded])\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"  (num_sequences, window_size, num_features)\")\n",
    "print(f\"\\ny_train shape: {y_train_onehot.shape}\")\n",
    "print(f\"  (num_sequences, window_size, num_classes)\")\n",
    "print(f\"\\nX_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test_onehot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bea5eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence-to-Sequence LSTM Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m78,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m528\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130,352</span> (509.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m130,352\u001b[0m (509.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130,352</span> (509.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m130,352\u001b[0m (509.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 6: Build sequence-to-sequence LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed\n",
    "\n",
    "model = Sequential([\n",
    "    # Input: (window_size, 24 features)\n",
    "    \n",
    "    # LSTM layers - return_sequences=True for sequence-to-sequence\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # TimeDistributed applies Dense layer to each time step independently\n",
    "    TimeDistributed(Dense(32, activation='relu')),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Output layer: predict class at each time step\n",
    "    TimeDistributed(Dense(num_classes, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Sequence-to-Sequence LSTM Model:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "733e354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: Custom Macro F1 callback for sequence-to-sequence\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class SequenceToSequenceMacroF1Callback(Callback):\n",
    "    \"\"\"\n",
    "    Monitor macro F1 at the WINDOW level (not sequence level)\n",
    "    Flatten all predictions and labels across all sequences\n",
    "    \"\"\"\n",
    "    def __init__(self, validation_data, patience=10):\n",
    "        super().__init__()\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.patience = patience\n",
    "        self.best_macro_f1 = 0\n",
    "        self.wait = 0\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Predict on validation set\n",
    "        y_pred_probs = self.model.predict(self.X_val, verbose=0)\n",
    "        \n",
    "        # Flatten: (num_sequences, window_size, num_classes) -> (total_windows, num_classes)\n",
    "        y_pred_flat = y_pred_probs.reshape(-1, y_pred_probs.shape[-1])\n",
    "        y_true_flat = self.y_val.reshape(-1, self.y_val.shape[-1])\n",
    "        \n",
    "        # Get class predictions\n",
    "        y_pred_classes = np.argmax(y_pred_flat, axis=1)\n",
    "        y_true_classes = np.argmax(y_true_flat, axis=1)\n",
    "        \n",
    "        # Calculate macro F1\n",
    "        macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro', zero_division=0)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}: val_macro_f1 = {macro_f1:.4f}\")\n",
    "        \n",
    "        # Check if best\n",
    "        if macro_f1 > self.best_macro_f1:\n",
    "            self.best_macro_f1 = macro_f1\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            print(f\"  → New best macro F1! Saving weights.\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            print(f\"  → No improvement (patience: {self.wait}/{self.patience})\")\n",
    "            \n",
    "            if self.wait >= self.patience:\n",
    "                print(f\"\\n⚠️ Early stopping! Restoring best weights (macro F1 = {self.best_macro_f1:.4f})\")\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c47d5774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: 240 sequences\n",
      "Val split: 60 sequences\n",
      "\n",
      "Class weights:\n",
      "  501: 15.00\n",
      "  502: 166.67\n",
      "  506: 20.83\n",
      "  511: 9.15\n",
      "  512: 5.30\n",
      "  513: 100.00\n",
      "  517: 57.69\n",
      "  518: 300.00\n",
      "  520: 14.71\n",
      "  522: 4.27\n",
      "  523: 3.98\n",
      "  cafeteria: 0.28\n",
      "  cleaning: 9.49\n",
      "  hallway: 1.73\n",
      "  kitchen: 0.32\n",
      "  nurse station: 0.13\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Split train into train/val and compute class weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Split for validation\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train_onehot,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train split: {X_train_split.shape[0]} sequences\")\n",
    "print(f\"Val split: {X_val_split.shape[0]} sequences\")\n",
    "\n",
    "# Compute class weights on flattened labels\n",
    "y_train_flat = y_train_split.reshape(-1, y_train_split.shape[-1])\n",
    "y_train_classes_flat = np.argmax(y_train_flat, axis=1)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train_classes_flat),\n",
    "    y=y_train_classes_flat\n",
    ")\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "print(\"\\nClass weights:\")\n",
    "for i, weight in class_weight_dict.items():\n",
    "    print(f\"  {label_encoder.classes_[i]}: {weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b764e8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Sequence-to-Sequence LSTM (Option 3)...\n",
      "================================================================================\n",
      "\n",
      "Note: class_weight not supported for sequence-to-sequence models\n",
      "Class imbalance will be handled through macro F1 optimization instead\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3648 - loss: 2.3358\n",
      "Epoch 1: val_macro_f1 = 0.0442\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 371ms/step - accuracy: 0.4173 - loss: 2.0652 - val_accuracy: 0.4940 - val_loss: 1.4939 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5271 - loss: 1.5170\n",
      "Epoch 2: val_macro_f1 = 0.0958\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.5361 - loss: 1.4888 - val_accuracy: 0.6325 - val_loss: 1.2383 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5964 - loss: 1.3874\n",
      "Epoch 3: val_macro_f1 = 0.0973\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.5895 - loss: 1.3461 - val_accuracy: 0.6278 - val_loss: 1.1633 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6103 - loss: 1.3075\n",
      "Epoch 4: val_macro_f1 = 0.1133\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.6092 - loss: 1.2673 - val_accuracy: 0.6517 - val_loss: 1.1227 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6209 - loss: 1.1768\n",
      "Epoch 5: val_macro_f1 = 0.1051\n",
      "  → No improvement (patience: 1/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.6242 - loss: 1.1855 - val_accuracy: 0.6375 - val_loss: 1.0649 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6464 - loss: 1.1814\n",
      "Epoch 6: val_macro_f1 = 0.1055\n",
      "  → No improvement (patience: 2/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.6313 - loss: 1.1482 - val_accuracy: 0.6547 - val_loss: 1.0170 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6101 - loss: 1.1740\n",
      "Epoch 7: val_macro_f1 = 0.1120\n",
      "  → No improvement (patience: 3/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.6295 - loss: 1.1121 - val_accuracy: 0.6573 - val_loss: 1.0318 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6184 - loss: 1.1295\n",
      "Epoch 8: val_macro_f1 = 0.1060\n",
      "  → No improvement (patience: 4/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.6149 - loss: 1.1588 - val_accuracy: 0.6260 - val_loss: 1.0126 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6300 - loss: 1.0816\n",
      "Epoch 9: val_macro_f1 = 0.1112\n",
      "  → No improvement (patience: 5/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.6315 - loss: 1.0757 - val_accuracy: 0.6595 - val_loss: 0.9412 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6324 - loss: 1.0095\n",
      "Epoch 10: val_macro_f1 = 0.1088\n",
      "  → No improvement (patience: 6/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.6364 - loss: 1.0141 - val_accuracy: 0.6532 - val_loss: 0.9068 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6281 - loss: 1.0370\n",
      "Epoch 11: val_macro_f1 = 0.1206\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6389 - loss: 0.9678 - val_accuracy: 0.6668 - val_loss: 0.8835 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6158 - loss: 1.0310\n",
      "Epoch 12: val_macro_f1 = 0.1416\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6402 - loss: 0.9415 - val_accuracy: 0.6623 - val_loss: 0.8597 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6779 - loss: 0.8707\n",
      "Epoch 13: val_macro_f1 = 0.1612\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.6512 - loss: 0.9217 - val_accuracy: 0.6578 - val_loss: 0.8408 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6703 - loss: 0.8790\n",
      "Epoch 14: val_macro_f1 = 0.1990\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6588 - loss: 0.8953 - val_accuracy: 0.6828 - val_loss: 0.8239 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6941 - loss: 0.8145\n",
      "Epoch 15: val_macro_f1 = 0.2087\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6525 - loss: 0.8902 - val_accuracy: 0.7123 - val_loss: 0.7898 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6557 - loss: 0.9092\n",
      "Epoch 16: val_macro_f1 = 0.1680\n",
      "  → No improvement (patience: 1/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.6571 - loss: 0.8608 - val_accuracy: 0.6635 - val_loss: 0.7948 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6448 - loss: 0.8705\n",
      "Epoch 17: val_macro_f1 = 0.2012\n",
      "  → No improvement (patience: 2/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.6574 - loss: 0.8405 - val_accuracy: 0.6997 - val_loss: 0.7675 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6552 - loss: 0.8392\n",
      "Epoch 18: val_macro_f1 = 0.2413\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.6655 - loss: 0.8240 - val_accuracy: 0.7123 - val_loss: 0.8035 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6870 - loss: 0.7894\n",
      "Epoch 19: val_macro_f1 = 0.2584\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6769 - loss: 0.8133 - val_accuracy: 0.7268 - val_loss: 0.7473 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6749 - loss: 0.7881\n",
      "Epoch 20: val_macro_f1 = 0.2208\n",
      "  → No improvement (patience: 1/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6788 - loss: 0.7954 - val_accuracy: 0.6960 - val_loss: 0.7710 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6961 - loss: 0.7544\n",
      "Epoch 21: val_macro_f1 = 0.2147\n",
      "  → No improvement (patience: 2/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6800 - loss: 0.7962 - val_accuracy: 0.6823 - val_loss: 0.8252 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6536 - loss: 0.8855\n",
      "Epoch 22: val_macro_f1 = 0.2438\n",
      "  → No improvement (patience: 3/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.6785 - loss: 0.8009 - val_accuracy: 0.6837 - val_loss: 0.8216 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6786 - loss: 0.8086\n",
      "Epoch 23: val_macro_f1 = 0.2509\n",
      "  → No improvement (patience: 4/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.6763 - loss: 0.8120 - val_accuracy: 0.7143 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6804 - loss: 0.7671\n",
      "Epoch 24: val_macro_f1 = 0.2453\n",
      "  → No improvement (patience: 5/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.6800 - loss: 0.7774 - val_accuracy: 0.7043 - val_loss: 0.7498 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.7428\n",
      "Epoch 25: val_macro_f1 = 0.2507\n",
      "  → No improvement (patience: 6/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.6856 - loss: 0.7561 - val_accuracy: 0.7267 - val_loss: 0.7465 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6855 - loss: 0.7748\n",
      "Epoch 26: val_macro_f1 = 0.2709\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.6843 - loss: 0.7706 - val_accuracy: 0.7100 - val_loss: 0.7335 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7131 - loss: 0.6869\n",
      "Epoch 27: val_macro_f1 = 0.2632\n",
      "  → No improvement (patience: 1/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.6922 - loss: 0.7299 - val_accuracy: 0.7148 - val_loss: 0.7782 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6710 - loss: 0.7759\n",
      "Epoch 28: val_macro_f1 = 0.2472\n",
      "  → No improvement (patience: 2/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6919 - loss: 0.7318 - val_accuracy: 0.7120 - val_loss: 0.7231 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7258 - loss: 0.6844\n",
      "Epoch 29: val_macro_f1 = 0.2503\n",
      "  → No improvement (patience: 3/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7020 - loss: 0.7282 - val_accuracy: 0.7237 - val_loss: 0.7323 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7109 - loss: 0.7401\n",
      "Epoch 30: val_macro_f1 = 0.2443\n",
      "  → No improvement (patience: 4/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7037 - loss: 0.7246 - val_accuracy: 0.7123 - val_loss: 0.7724 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7085 - loss: 0.7093\n",
      "Epoch 31: val_macro_f1 = 0.2841\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7016 - loss: 0.7205 - val_accuracy: 0.7107 - val_loss: 0.7314 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7068 - loss: 0.7159\n",
      "Epoch 32: val_macro_f1 = 0.2711\n",
      "  → No improvement (patience: 1/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7142 - loss: 0.6926 - val_accuracy: 0.7000 - val_loss: 0.7617 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7058 - loss: 0.6780\n",
      "Epoch 33: val_macro_f1 = 0.2495\n",
      "  → No improvement (patience: 2/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7108 - loss: 0.6892 - val_accuracy: 0.6925 - val_loss: 0.7620 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6899 - loss: 0.7207\n",
      "Epoch 34: val_macro_f1 = 0.2537\n",
      "  → No improvement (patience: 3/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.7050 - loss: 0.6975 - val_accuracy: 0.7227 - val_loss: 0.7279 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7197 - loss: 0.6540\n",
      "Epoch 35: val_macro_f1 = 0.2759\n",
      "  → No improvement (patience: 4/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7217 - loss: 0.6574 - val_accuracy: 0.7050 - val_loss: 0.7518 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7105 - loss: 0.6624\n",
      "Epoch 36: val_macro_f1 = 0.2599\n",
      "  → No improvement (patience: 5/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6963 - loss: 0.7074 - val_accuracy: 0.7053 - val_loss: 0.7269 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7363 - loss: 0.6562\n",
      "Epoch 37: val_macro_f1 = 0.2784\n",
      "  → No improvement (patience: 6/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.7169 - loss: 0.6739 - val_accuracy: 0.7128 - val_loss: 0.6932 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7152 - loss: 0.6976\n",
      "Epoch 38: val_macro_f1 = 0.2788\n",
      "  → No improvement (patience: 7/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7278 - loss: 0.6530 - val_accuracy: 0.7143 - val_loss: 0.6790 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7298 - loss: 0.6232\n",
      "Epoch 39: val_macro_f1 = 0.2634\n",
      "  → No improvement (patience: 8/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7172 - loss: 0.6448 - val_accuracy: 0.7230 - val_loss: 0.7088 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7273 - loss: 0.5717\n",
      "Epoch 40: val_macro_f1 = 0.2924\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7211 - loss: 0.6371 - val_accuracy: 0.7155 - val_loss: 0.6985 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7394 - loss: 0.6297\n",
      "Epoch 41: val_macro_f1 = 0.2598\n",
      "  → No improvement (patience: 1/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7347 - loss: 0.6346 - val_accuracy: 0.7212 - val_loss: 0.6840 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7330 - loss: 0.6205\n",
      "Epoch 42: val_macro_f1 = 0.3453\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.7299 - loss: 0.6465 - val_accuracy: 0.7052 - val_loss: 0.6954 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7683 - loss: 0.5851\n",
      "Epoch 43: val_macro_f1 = 0.2790\n",
      "  → No improvement (patience: 1/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7287 - loss: 0.6383 - val_accuracy: 0.6945 - val_loss: 0.7116 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7332 - loss: 0.6238\n",
      "Epoch 44: val_macro_f1 = 0.3233\n",
      "  → No improvement (patience: 2/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7370 - loss: 0.6253 - val_accuracy: 0.7372 - val_loss: 0.6913 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7364 - loss: 0.6269\n",
      "Epoch 45: val_macro_f1 = 0.3409\n",
      "  → No improvement (patience: 3/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.7388 - loss: 0.6138 - val_accuracy: 0.7325 - val_loss: 0.6709 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7399 - loss: 0.5793\n",
      "Epoch 46: val_macro_f1 = 0.3498\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7508 - loss: 0.6012 - val_accuracy: 0.7422 - val_loss: 0.7207 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7588 - loss: 0.5747\n",
      "Epoch 47: val_macro_f1 = 0.3091\n",
      "  → No improvement (patience: 1/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7580 - loss: 0.5801 - val_accuracy: 0.7285 - val_loss: 0.7029 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7902 - loss: 0.5192\n",
      "Epoch 48: val_macro_f1 = 0.3634\n",
      "  → New best macro F1! Saving weights.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7627 - loss: 0.5720 - val_accuracy: 0.7317 - val_loss: 0.6685 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7770 - loss: 0.5372\n",
      "Epoch 49: val_macro_f1 = 0.3543\n",
      "  → No improvement (patience: 1/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7572 - loss: 0.5822 - val_accuracy: 0.7185 - val_loss: 0.7146 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7534 - loss: 0.6144\n",
      "Epoch 50: val_macro_f1 = 0.3630\n",
      "  → No improvement (patience: 2/10)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.7493 - loss: 0.5988 - val_accuracy: 0.7237 - val_loss: 0.6714 - learning_rate: 0.0010\n",
      "\n",
      "✓ Training complete!\n",
      "✓ Best validation macro F1: 0.3634\n"
     ]
    }
   ],
   "source": [
    "# CELL 9: Train the model (FIXED - no class_weight for seq2seq)\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Recreate the callback class\n",
    "class SequenceToSequenceMacroF1Callback(Callback):\n",
    "    \"\"\"\n",
    "    Monitor macro F1 at the WINDOW level (not sequence level)\n",
    "    Flatten all predictions and labels across all sequences\n",
    "    \"\"\"\n",
    "    def __init__(self, validation_data, patience=10):\n",
    "        super().__init__()\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.patience = patience\n",
    "        self.best_macro_f1 = 0\n",
    "        self.wait = 0\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Predict on validation set\n",
    "        y_pred_probs = self.model.predict(self.X_val, verbose=0)\n",
    "        \n",
    "        # Flatten: (num_sequences, window_size, num_classes) -> (total_windows, num_classes)\n",
    "        y_pred_flat = y_pred_probs.reshape(-1, y_pred_probs.shape[-1])\n",
    "        y_true_flat = self.y_val.reshape(-1, self.y_val.shape[-1])\n",
    "        \n",
    "        # Get class predictions\n",
    "        y_pred_classes = np.argmax(y_pred_flat, axis=1)\n",
    "        y_true_classes = np.argmax(y_true_flat, axis=1)\n",
    "        \n",
    "        # Calculate macro F1\n",
    "        macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro', zero_division=0)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}: val_macro_f1 = {macro_f1:.4f}\")\n",
    "        \n",
    "        # Check if best\n",
    "        if macro_f1 > self.best_macro_f1:\n",
    "            self.best_macro_f1 = macro_f1\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            print(f\"  → New best macro F1! Saving weights.\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            print(f\"  → No improvement (patience: {self.wait}/{self.patience})\")\n",
    "            \n",
    "            if self.wait >= self.patience:\n",
    "                print(f\"\\n⚠️ Early stopping! Restoring best weights (macro F1 = {self.best_macro_f1:.4f})\")\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "# Initialize callbacks\n",
    "macro_f1_callback = SequenceToSequenceMacroF1Callback(\n",
    "    validation_data=(X_val_split, y_val_split),\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Training Sequence-to-Sequence LSTM (Option 3)...\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nNote: class_weight not supported for sequence-to-sequence models\")\n",
    "print(\"Class imbalance will be handled through macro F1 optimization instead\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    validation_data=(X_val_split, y_val_split),\n",
    "    epochs=50,\n",
    "    batch_size=16,  # Adjust if memory issues\n",
    "    # NO class_weight parameter - doesn't work with seq2seq!\n",
    "    callbacks=[macro_f1_callback, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Training complete!\")\n",
    "print(f\"✓ Best validation macro F1: {macro_f1_callback.best_macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44e022cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test set...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\n",
      "================================================================================\n",
      "SEQUENCE-TO-SEQUENCE LSTM EVALUATION (OPTION 3)\n",
      "================================================================================\n",
      "\n",
      "🎯 MACRO F1 SCORE: 0.2702\n",
      "   Option 2 (room-segmented) was: 0.37\n",
      "   XGBoost baseline was: 0.30\n",
      "   ✗ Decline: -27.0%\n",
      "\n",
      "================================================================================\n",
      "PER-CLASS F1 SCORES\n",
      "================================================================================\n",
      "\n",
      "Room                 F1 Score     Support   \n",
      "--------------------------------------------------------------------------------\n",
      "kitchen              0.7246       3306      \n",
      "512                  0.6339       266       \n",
      "nurse station        0.6108       2502      \n",
      "523                  0.5961       220       \n",
      "520                  0.4199       380       \n",
      "506                  0.3926       194       \n",
      "cafeteria            0.3917       2446      \n",
      "522                  0.2500       34        \n",
      "501                  0.1688       30        \n",
      "cleaning             0.1236       950       \n",
      "hallway              0.0107       652       \n",
      "502                  0.0000       138       \n",
      "511                  0.0000       92        \n",
      "513                  0.0000       360       \n",
      "517                  0.0000       4         \n",
      "518                  0.0000       26        \n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Average F1 (macro): 0.2702\n",
      "Best room: kitchen (F1=0.7246)\n",
      "Worst room: 518 (F1=0.0000)\n",
      "Rooms with F1 > 0.5: 4/16\n",
      "Rooms with F1 < 0.2: 8/16\n"
     ]
    }
   ],
   "source": [
    "# CELL 10: Evaluate on test set\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict on test set\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred_probs = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Flatten predictions and labels\n",
    "y_pred_flat = y_pred_probs.reshape(-1, y_pred_probs.shape[-1])\n",
    "y_test_flat = y_test_onehot.reshape(-1, y_test_onehot.shape[-1])\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred_flat, axis=1)\n",
    "y_true_classes = np.argmax(y_test_flat, axis=1)\n",
    "\n",
    "# Decode to room names\n",
    "y_pred = label_encoder.inverse_transform(y_pred_classes)\n",
    "y_true = label_encoder.inverse_transform(y_true_classes)\n",
    "\n",
    "# Calculate macro F1\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SEQUENCE-TO-SEQUENCE LSTM EVALUATION (OPTION 3)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n🎯 MACRO F1 SCORE: {macro_f1:.4f}\")\n",
    "print(f\"   Option 2 (room-segmented) was: 0.37\")\n",
    "print(f\"   XGBoost baseline was: 0.30\")\n",
    "\n",
    "if macro_f1 > 0.37:\n",
    "    improvement = (macro_f1 - 0.37) / 0.37 * 100\n",
    "    print(f\"   ✓ Improvement over Option 2: +{improvement:.1f}%\")\n",
    "else:\n",
    "    decline = (0.37 - macro_f1) / 0.37 * 100\n",
    "    print(f\"   ✗ Decline: -{decline:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PER-CLASS F1 SCORES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get per-class F1\n",
    "report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "class_f1_scores = []\n",
    "for class_name in sorted(set(y_true)):\n",
    "    if class_name in report:\n",
    "        f1 = report[class_name]['f1-score']\n",
    "        support = report[class_name]['support']\n",
    "        class_f1_scores.append((class_name, f1, support))\n",
    "\n",
    "class_f1_scores.sort(key=lambda x: -x[1])\n",
    "\n",
    "print(f\"\\n{'Room':<20s} {'F1 Score':<12s} {'Support':<10s}\")\n",
    "print(\"-\" * 80)\n",
    "for room, f1, support in class_f1_scores:\n",
    "    print(f\"{room:<20s} {f1:<12.4f} {int(support):<10d}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Average F1 (macro): {macro_f1:.4f}\")\n",
    "print(f\"Best room: {class_f1_scores[0][0]} (F1={class_f1_scores[0][1]:.4f})\")\n",
    "print(f\"Worst room: {class_f1_scores[-1][0]} (F1={class_f1_scores[-1][1]:.4f})\")\n",
    "print(f\"Rooms with F1 > 0.5: {sum(1 for _, f1, _ in class_f1_scores if f1 > 0.5)}/{len(class_f1_scores)}\")\n",
    "print(f\"Rooms with F1 < 0.2: {sum(1 for _, f1, _ in class_f1_scores if f1 < 0.2)}/{len(class_f1_scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Setup and Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ All imports successful\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61IKvrDz67X8",
        "outputId": "203194f6-c602-4a29-e618-a74f9b769d6c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_filter_fold(i):\n",
        "    train_dir = f'/content/drive/MyDrive/split_data/fold{i}/train.csv'\n",
        "    test_dir = f'/content/drive/MyDrive/split_data/fold{i}/test.csv'\n",
        "    train_df = pd.read_csv(train_dir)\n",
        "    test_df = pd.read_csv(test_dir)\n",
        "\n",
        "    train_labels = list(train_df['room'].unique())\n",
        "    test_labels = list(test_df['room'].unique())\n",
        "    common_labels = list(set(train_labels) & set(test_labels))\n",
        "\n",
        "    train_df = train_df[train_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "    test_df = test_df[test_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Load all 4 folds\n",
        "train_df_1, test_df_1 = load_and_filter_fold(1)\n",
        "train_df_2, test_df_2 = load_and_filter_fold(2)\n",
        "train_df_3, test_df_3 = load_and_filter_fold(3)\n",
        "train_df_4, test_df_4 = load_and_filter_fold(4)\n",
        "\n",
        "print(\"✓ All folds loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpmdGbCk8Gvu",
        "outputId": "a6f9db6f-60c1-499f-99e4-367e03c068d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All folds loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "def create_room_groups(df):\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    df['room_group'] = (df['room'] != df['room'].shift()).cumsum()\n",
        "    return df\n",
        "\n",
        "def create_beacon_count_vectors(df):\n",
        "    \"\"\"Aggregates readings into 1s vectors. Handles data with or without 'room_group'.\"\"\"\n",
        "    vectors = []\n",
        "    has_groups = 'room_group' in df.columns # Check if we are in 'training' mode\n",
        "\n",
        "    for _, group in df.groupby('timestamp'):\n",
        "        beacon_counts = group['mac address'].value_counts()\n",
        "        total_readings = len(group)\n",
        "\n",
        "        vector = [0.0] * 23\n",
        "        for beacon_id, count in beacon_counts.items():\n",
        "            if 1 <= beacon_id <= 23:\n",
        "                vector[int(beacon_id) - 1] = count / total_readings\n",
        "\n",
        "        entry = {\n",
        "            'timestamp': group['timestamp'].iloc[0],\n",
        "            'room': group['room'].iloc[0],\n",
        "            'beacon_vector': vector\n",
        "        }\n",
        "\n",
        "        if has_groups:\n",
        "            entry['room_group'] = group['room_group'].iloc[0]\n",
        "\n",
        "        vectors.append(entry)\n",
        "\n",
        "    return pd.DataFrame(vectors)\n",
        "\n",
        "def create_sequences_from_groups(vector_df, min_length=3, max_length=50):\n",
        "    \"\"\"Used for Training: Creates clean sequences where the room is constant.\"\"\"\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for (room, room_group), group in vector_df.groupby(['room', 'room_group']):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=False)\n",
        "        seq_length = len(group)\n",
        "\n",
        "        if seq_length < min_length:\n",
        "            continue\n",
        "\n",
        "        if seq_length > max_length:\n",
        "            group = group.tail(max_length)\n",
        "\n",
        "        sequence = [row['beacon_vector'] for _, row in group.iterrows()]\n",
        "        sequences.append(sequence)\n",
        "        labels.append(room)\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "def create_sliding_windows_by_day(vector_df, window_size=10):\n",
        "    \"\"\"Used for Inference: Creates a sequence for every frame, respecting day boundaries.\"\"\"\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    # Ensure chronological order and group by day\n",
        "    vector_df['dt'] = pd.to_datetime(vector_df['timestamp'])\n",
        "    vector_df['date'] = vector_df['dt'].dt.date\n",
        "\n",
        "    for _, day_group in vector_df.groupby('date'):\n",
        "        day_group = day_group.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "        if len(day_group) >= window_size:\n",
        "            vectors = list(day_group['beacon_vector'])\n",
        "            rooms = list(day_group['room'])\n",
        "\n",
        "            for i in range(len(vectors) - window_size + 1):\n",
        "                window = vectors[i : i + window_size]\n",
        "                sequences.append(window)\n",
        "                # Goal: Predict the room at the final timestamp of the window\n",
        "                labels.append(rooms[i + window_size - 1])\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "def build_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Masking(mask_value=0.0, input_shape=input_shape),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "print(\"✓ Updated Helper functions defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJqM0q478Yk5",
        "outputId": "6413fa9e-ac4c-4b33-f7c0-c2539d9c9233"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Updated Helper functions defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline_single_seed(train_df, test_df, seed, verbose=False):\n",
        "    \"\"\"Run realistic pipeline: Train on segments, Test on sliding windows.\"\"\"\n",
        "    set_seeds(seed)\n",
        "    window_size = 10    # Sliding window for inference\n",
        "    max_seq_length = 50 # Maximum sequence length for the LSTM\n",
        "\n",
        "    # 1. Preprocessing\n",
        "    # Only train uses room_group segmentation to learn pure room signatures\n",
        "    train_df = create_room_groups(train_df)\n",
        "\n",
        "    train_vectors = create_beacon_count_vectors(train_df)\n",
        "    test_vectors = create_beacon_count_vectors(test_df)\n",
        "\n",
        "    # 2. Sequence Creation\n",
        "    X_train, y_train = create_sequences_from_groups(train_vectors, max_length=max_seq_length)\n",
        "    X_test, y_test = create_sliding_windows_by_day(test_vectors, window_size=window_size)\n",
        "\n",
        "    # 3. Encoding & Padding\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(list(y_train) + list(y_test))\n",
        "    y_train_encoded = label_encoder.transform(y_train)\n",
        "    y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "    # Pad to match LSTM input shape (max_seq_length, 23)\n",
        "    X_train_padded = pad_sequences(X_train, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "    X_test_padded = pad_sequences(X_test, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "\n",
        "    # 4. Train Model with Macro F1 Optimization (Class Weights)\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    model = build_lstm_model(input_shape=(max_seq_length, 23), num_classes=len(label_encoder.classes_))\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=0)\n",
        "    ]\n",
        "\n",
        "    model.fit(\n",
        "        X_train_padded, y_train_encoded,\n",
        "        validation_data=(X_test_padded, y_test_encoded),\n",
        "        epochs=100, batch_size=32,\n",
        "        class_weight=class_weight_dict,\n",
        "        callbacks=callbacks, verbose=0\n",
        "    )\n",
        "\n",
        "    # 5. Evaluate (Predict on every frame generated by the sliding window)\n",
        "    y_pred_probs = model.predict(X_test_padded, verbose=0)\n",
        "    y_pred_encoded = np.argmax(y_pred_probs, axis=1)\n",
        "    y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    per_class_f1 = f1_score(y_test, y_pred, average=None, labels=label_encoder.classes_, zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'seed': seed,\n",
        "        'macro_f1': macro_f1,\n",
        "        'per_class_f1': {label: f1 for label, f1 in zip(label_encoder.classes_, per_class_f1)}\n",
        "    }\n",
        "\n",
        "print(\"✓ Updated Pipeline function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOJQePab8fvV",
        "outputId": "59c34560-5108-4330-c31b-00813929b0ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Updated Pipeline function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-VAhGL085lf",
        "outputId": "c4dec05c-88b9-4a22-ab39-a8429dafc0df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run 10 seeds for each of 4 folds\n",
        "seeds = [42, 123, 456, 789, 2024, 3141, 5926, 8888, 1337, 9999]\n",
        "folds = {\n",
        "    1: (train_df_1, test_df_1),\n",
        "    2: (train_df_2, test_df_2),\n",
        "    3: (train_df_3, test_df_3),\n",
        "    4: (train_df_4, test_df_4)\n",
        "}\n",
        "\n",
        "all_fold_results = {}\n",
        "\n",
        "for fold_num, (train_df, test_df) in folds.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"PROCESSING FOLD {fold_num}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    fold_results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"  Running seed {seed}...\", end=\" \")\n",
        "        result = run_pipeline_single_seed(train_df, test_df, seed, verbose=False)\n",
        "        fold_results.append(result)\n",
        "        print(f\"Macro F1: {result['macro_f1']:.4f}\")\n",
        "\n",
        "    all_fold_results[fold_num] = fold_results\n",
        "\n",
        "    # Calculate fold statistics\n",
        "    macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "    print(f\"\\n  Fold {fold_num} Summary:\")\n",
        "    print(f\"    Mean Macro F1: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\")\n",
        "    print(f\"    Min: {np.min(macro_f1_scores):.4f}, Max: {np.max(macro_f1_scores):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ALL FOLDS COMPLETED!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mhhfMG_F8hg5",
        "outputId": "5932fc8c-ef88-4ac8-cde5-14888fccde54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 1\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.3516\n",
            "  Running seed 123... Macro F1: 0.4018\n",
            "  Running seed 456... Macro F1: 0.4365\n",
            "  Running seed 789... Macro F1: 0.2880\n",
            "  Running seed 2024... Macro F1: 0.3394\n",
            "  Running seed 3141... Macro F1: 0.3776\n",
            "  Running seed 5926... Macro F1: 0.3810\n",
            "  Running seed 8888... Macro F1: 0.3558\n",
            "  Running seed 1337... Macro F1: 0.3295\n",
            "  Running seed 9999... Macro F1: 0.2646\n",
            "\n",
            "  Fold 1 Summary:\n",
            "    Mean Macro F1: 0.3526 ± 0.0485\n",
            "    Min: 0.2646, Max: 0.4365\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 2\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.3012\n",
            "  Running seed 123... Macro F1: 0.1865\n",
            "  Running seed 456... Macro F1: 0.2957\n",
            "  Running seed 789... Macro F1: 0.3060\n",
            "  Running seed 2024... Macro F1: 0.2311\n",
            "  Running seed 3141... Macro F1: 0.2172\n",
            "  Running seed 5926... Macro F1: 0.2868\n",
            "  Running seed 8888... Macro F1: 0.2856\n",
            "  Running seed 1337... Macro F1: 0.3136\n",
            "  Running seed 9999... Macro F1: 0.2299\n",
            "\n",
            "  Fold 2 Summary:\n",
            "    Mean Macro F1: 0.2654 ± 0.0424\n",
            "    Min: 0.1865, Max: 0.3136\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 3\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.2975\n",
            "  Running seed 123... Macro F1: 0.2607\n",
            "  Running seed 456... Macro F1: 0.2552\n",
            "  Running seed 789... Macro F1: 0.3114\n",
            "  Running seed 2024... Macro F1: 0.3625\n",
            "  Running seed 3141... Macro F1: 0.3070\n",
            "  Running seed 5926... Macro F1: 0.3460\n",
            "  Running seed 8888... Macro F1: 0.2724\n",
            "  Running seed 1337... Macro F1: 0.2274\n",
            "  Running seed 9999... Macro F1: 0.2479\n",
            "\n",
            "  Fold 3 Summary:\n",
            "    Mean Macro F1: 0.2888 ± 0.0415\n",
            "    Min: 0.2274, Max: 0.3625\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 4\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.3976\n",
            "  Running seed 123... Macro F1: 0.3094\n",
            "  Running seed 456... Macro F1: 0.3449\n",
            "  Running seed 789... Macro F1: 0.2669\n",
            "  Running seed 2024... Macro F1: 0.2944\n",
            "  Running seed 3141... Macro F1: 0.3606\n",
            "  Running seed 5926... Macro F1: 0.3661\n",
            "  Running seed 8888... Macro F1: 0.3336\n",
            "  Running seed 1337... Macro F1: 0.2470\n",
            "  Running seed 9999... Macro F1: 0.3547\n",
            "\n",
            "  Fold 4 Summary:\n",
            "    Mean Macro F1: 0.3275 ± 0.0449\n",
            "    Min: 0.2470, Max: 0.3976\n",
            "\n",
            "================================================================================\n",
            "ALL FOLDS COMPLETED!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to text file\n",
        "with open('4fold_10seed_results.txt', 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"4-FOLD CROSS-VALIDATION WITH 10 SEEDS PER FOLD\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    # Overall summary\n",
        "    all_macro_f1 = []\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        fold_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "        all_macro_f1.extend(fold_scores)\n",
        "\n",
        "    f.write(\"OVERALL RESULTS (40 runs total):\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Mean Macro F1: {np.mean(all_macro_f1):.4f} ± {np.std(all_macro_f1):.4f}\\n\")\n",
        "    f.write(f\"Min: {np.min(all_macro_f1):.4f}, Max: {np.max(all_macro_f1):.4f}\\n\\n\")\n",
        "\n",
        "    # Per-fold results\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        f.write(f\"\\n{'='*80}\\n\")\n",
        "        f.write(f\"FOLD {fold_num} RESULTS\\n\")\n",
        "        f.write(f\"{'='*80}\\n\\n\")\n",
        "\n",
        "        fold_results = all_fold_results[fold_num]\n",
        "        macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "\n",
        "        f.write(f\"Macro F1 Scores (10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        for i, result in enumerate(fold_results):\n",
        "            f.write(f\"  Seed {result['seed']:5d}: {result['macro_f1']:.4f}\\n\")\n",
        "\n",
        "        f.write(f\"\\nStatistics:\\n\")\n",
        "        f.write(f\"  Mean: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Min:  {np.min(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Max:  {np.max(macro_f1_scores):.4f}\\n\")\n",
        "\n",
        "        # Per-class F1 (averaged across 10 seeds)\n",
        "        f.write(f\"\\nPer-Class F1 Scores (averaged across 10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "\n",
        "        # Collect all class names\n",
        "        all_classes = set()\n",
        "        for result in fold_results:\n",
        "            all_classes.update(result['per_class_f1'].keys())\n",
        "\n",
        "        # Average per-class F1 across seeds\n",
        "        for class_name in sorted(all_classes):\n",
        "            class_f1_scores = [r['per_class_f1'].get(class_name, 0) for r in fold_results]\n",
        "            mean_f1 = np.mean(class_f1_scores)\n",
        "            std_f1 = np.std(class_f1_scores)\n",
        "            f.write(f\"  {class_name:20s}: {mean_f1:.4f} ± {std_f1:.4f}\\n\")\n",
        "\n",
        "print(\"✅ Results saved to 4fold_10seed_results.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1MjD0t5LFuB",
        "outputId": "a3784b1c-4362-4fd7-edf7-c06d534bb0a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Results saved to 4fold_10seed_results.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY - 4 FOLDS × 10 SEEDS = 40 TOTAL RUNS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    macro_f1_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "    print(f\"Fold {fold_num}: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\")\n",
        "\n",
        "all_macro_f1 = []\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    all_macro_f1.extend([r['macro_f1'] for r in all_fold_results[fold_num]])\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Overall Mean: {np.mean(all_macro_f1):.4f} ± {np.std(all_macro_f1):.4f}\")\n",
        "print(f\"{'='*80}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZpF6nDeLJCU",
        "outputId": "835051ec-e931-4a44-8ddd-dbc8f2e2ab84"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY - 4 FOLDS × 10 SEEDS = 40 TOTAL RUNS\n",
            "================================================================================\n",
            "\n",
            "Fold 1: 0.3526 ± 0.0485\n",
            "Fold 2: 0.2654 ± 0.0424\n",
            "Fold 3: 0.2888 ± 0.0415\n",
            "Fold 4: 0.3275 ± 0.0449\n",
            "\n",
            "================================================================================\n",
            "Overall Mean: 0.3086 ± 0.0558\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}
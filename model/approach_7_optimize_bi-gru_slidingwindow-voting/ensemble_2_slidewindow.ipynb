{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "60VMoKcqNeNE",
        "outputId": "f5078800-616e-46ea-a981-0b5c953b4091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from tensorflow.keras.layers import Bidirectional, GRU\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úì All imports successful\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmy0nM8ONqO2",
        "outputId": "a79e2792-4a6f-448c-b1a7-21303cd64e4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì All imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_filter_fold(i):\n",
        "    train_dir = f'/content/drive/MyDrive/split_data/fold{i}/train.csv'\n",
        "    test_dir = f'/content/drive/MyDrive/split_data/fold{i}/test.csv'\n",
        "    train_df = pd.read_csv(train_dir)\n",
        "    test_df = pd.read_csv(test_dir)\n",
        "\n",
        "    train_labels = list(train_df['room'].unique())\n",
        "    test_labels = list(test_df['room'].unique())\n",
        "    common_labels = list(set(train_labels) & set(test_labels))\n",
        "\n",
        "    train_df = train_df[train_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "    test_df = test_df[test_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Load all 4 folds\n",
        "train_df_1, test_df_1 = load_and_filter_fold(1)\n",
        "train_df_2, test_df_2 = load_and_filter_fold(2)\n",
        "train_df_3, test_df_3 = load_and_filter_fold(3)\n",
        "train_df_4, test_df_4 = load_and_filter_fold(4)\n",
        "\n",
        "print(\"‚úì All folds loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Scobs0NqRs",
        "outputId": "32f5a92a-73cc-402c-81da-2c3dfbf20815"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì All folds loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "def create_room_groups(df):\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    df['room_group'] = (df['room'] != df['room'].shift()).cumsum()\n",
        "    return df\n",
        "\n",
        "def create_beacon_count_vectors(df):\n",
        "    \"\"\"Aggregates readings into 1s vectors. Handles data with or without 'room_group'.\"\"\"\n",
        "    vectors = []\n",
        "    has_groups = 'room_group' in df.columns # Check if we are in 'training' mode\n",
        "\n",
        "    for _, group in df.groupby('timestamp'):\n",
        "        beacon_counts = group['mac address'].value_counts()\n",
        "        total_readings = len(group)\n",
        "\n",
        "        vector = [0.0] * 23\n",
        "        for beacon_id, count in beacon_counts.items():\n",
        "            if 1 <= beacon_id <= 23:\n",
        "                vector[int(beacon_id) - 1] = count / total_readings\n",
        "\n",
        "        entry = {\n",
        "            'timestamp': group['timestamp'].iloc[0],\n",
        "            'room': group['room'].iloc[0],\n",
        "            'beacon_vector': vector\n",
        "        }\n",
        "\n",
        "        if has_groups:\n",
        "            entry['room_group'] = group['room_group'].iloc[0]\n",
        "\n",
        "        vectors.append(entry)\n",
        "\n",
        "    return pd.DataFrame(vectors)\n",
        "\n",
        "def create_sequences_from_groups(vector_df, min_length=3, max_length=50):\n",
        "    \"\"\"Used for Training: Creates clean sequences where the room is constant.\"\"\"\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for (room, room_group), group in vector_df.groupby(['room', 'room_group']):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=False)\n",
        "        seq_length = len(group)\n",
        "\n",
        "        if seq_length < min_length:\n",
        "            continue\n",
        "\n",
        "        if seq_length > max_length:\n",
        "            group = group.tail(max_length)\n",
        "\n",
        "        sequence = [row['beacon_vector'] for _, row in group.iterrows()]\n",
        "        sequences.append(sequence)\n",
        "        labels.append(room)\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "def create_sliding_windows_by_day(vector_df, window_size=10):\n",
        "    \"\"\"Used for Inference: Creates a sequence for every frame, respecting day boundaries.\"\"\"\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    # Ensure chronological order and group by day\n",
        "    vector_df['dt'] = pd.to_datetime(vector_df['timestamp'])\n",
        "    vector_df['date'] = vector_df['dt'].dt.date\n",
        "\n",
        "    for _, day_group in vector_df.groupby('date'):\n",
        "        day_group = day_group.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "        if len(day_group) >= window_size:\n",
        "            vectors = list(day_group['beacon_vector'])\n",
        "            rooms = list(day_group['room'])\n",
        "\n",
        "            for i in range(len(vectors) - window_size + 1):\n",
        "                window = vectors[i : i + window_size]\n",
        "                sequences.append(window)\n",
        "                # Goal: Predict the room at the final timestamp of the window\n",
        "                labels.append(rooms[i + window_size - 1])\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "def build_bidirectional_gru_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Bidirectional GRU Architecture\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Masking(mask_value=0.0, input_shape=input_shape),\n",
        "\n",
        "        Bidirectional(GRU(128, return_sequences=True)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Bidirectional(GRU(64, return_sequences=False)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def create_bidirectional_windows_by_day(vector_df, window_size=10):\n",
        "    \"\"\"\n",
        "    Creates 2 types of windows for each timestamp:\n",
        "    1. Backward-looking: [t-9, t-8, ..., t-1, t]\n",
        "    2. Forward-looking: [t, t+1, ..., t+8, t+9]\n",
        "\n",
        "    Returns sequences for both window types + ground truth labels.\n",
        "    Uses right-padding for cuDNN compatibility.\n",
        "    \"\"\"\n",
        "    backward_sequences = []\n",
        "    forward_sequences = []\n",
        "    labels = []\n",
        "\n",
        "    # Ensure chronological order and group by day\n",
        "    vector_df['dt'] = pd.to_datetime(vector_df['timestamp'])\n",
        "    vector_df['date'] = vector_df['dt'].dt.date\n",
        "\n",
        "    for _, day_group in vector_df.groupby('date'):\n",
        "        day_group = day_group.sort_values('timestamp').reset_index(drop=True)\n",
        "        vectors = list(day_group['beacon_vector'])\n",
        "        rooms = list(day_group['room'])\n",
        "        day_length = len(vectors)\n",
        "\n",
        "        if day_length < window_size:\n",
        "            continue\n",
        "\n",
        "        zero_vector = [0.0] * len(vectors[0])\n",
        "\n",
        "        # For each position in the day\n",
        "        for i in range(day_length):\n",
        "\n",
        "            # === BACKWARD WINDOW: [t-9, ..., t] ===\n",
        "            if i >= window_size - 1:\n",
        "                # Full backward window available\n",
        "                backward_window = vectors[i - window_size + 1 : i + 1]\n",
        "            else:\n",
        "                # Not enough history - take what we have and RIGHT-PAD\n",
        "                backward_window = vectors[0 : i + 1]\n",
        "                padding_needed = window_size - len(backward_window)\n",
        "                backward_window = backward_window + [zero_vector] * padding_needed\n",
        "\n",
        "            backward_sequences.append(backward_window)\n",
        "\n",
        "            # === FORWARD WINDOW: [t, t+1, ..., t+9] ===\n",
        "            if i + window_size <= day_length:\n",
        "                # Full forward window available\n",
        "                forward_window = vectors[i : i + window_size]\n",
        "            else:\n",
        "                # Not enough future - take what we have and RIGHT-PAD\n",
        "                forward_window = vectors[i : day_length]\n",
        "                padding_needed = window_size - len(forward_window)\n",
        "                forward_window = forward_window + [zero_vector] * padding_needed\n",
        "\n",
        "            forward_sequences.append(forward_window)\n",
        "\n",
        "            # Ground truth label for this position\n",
        "            labels.append(rooms[i])\n",
        "\n",
        "    return backward_sequences, forward_sequences, labels\n",
        "\n",
        "def ensemble_predictions_with_confidence(model, X_backward, X_forward):\n",
        "    \"\"\"\n",
        "    Gets predictions from both window types and selects the one with highest confidence.\n",
        "    Uses only backward and forward windows for stability.\n",
        "    \"\"\"\n",
        "    # Get probability predictions from both models\n",
        "    probs_backward = model.predict(X_backward, verbose=0)\n",
        "    probs_forward = model.predict(X_forward, verbose=0)\n",
        "\n",
        "    # Extract max confidence and predicted class for each\n",
        "    conf_backward = np.max(probs_backward, axis=1)\n",
        "    pred_backward = np.argmax(probs_backward, axis=1)\n",
        "\n",
        "    conf_forward = np.max(probs_forward, axis=1)\n",
        "    pred_forward = np.argmax(probs_forward, axis=1)\n",
        "\n",
        "    # For each sample, choose prediction with highest confidence\n",
        "    final_predictions = []\n",
        "\n",
        "    for i in range(len(pred_backward)):\n",
        "        # Compare confidences from both windows\n",
        "        if conf_backward[i] > conf_forward[i]:\n",
        "            final_predictions.append(pred_backward[i])\n",
        "        else:\n",
        "            final_predictions.append(pred_forward[i])\n",
        "\n",
        "    return np.array(final_predictions)\n",
        "\n",
        "def analyze_confidence_differences(model, X_backward, X_forward, sample_size=1000):\n",
        "    \"\"\"Debug: Analyze how different backward vs forward confidences are\"\"\"\n",
        "    probs_backward = model.predict(X_backward[:sample_size], verbose=0)\n",
        "    probs_forward = model.predict(X_forward[:sample_size], verbose=0)\n",
        "\n",
        "    conf_backward = np.max(probs_backward, axis=1)\n",
        "    conf_forward = np.max(probs_forward, axis=1)\n",
        "\n",
        "    pred_backward = np.argmax(probs_backward, axis=1)\n",
        "    pred_forward = np.argmax(probs_forward, axis=1)\n",
        "\n",
        "    # Cases where predictions differ\n",
        "    disagreements = pred_backward != pred_forward\n",
        "\n",
        "    print(f\"\\nüîç CONFIDENCE ANALYSIS (first {sample_size} samples):\")\n",
        "    print(f\"  Predictions disagree: {disagreements.sum()} / {sample_size} ({100*disagreements.sum()/sample_size:.1f}%)\")\n",
        "    print(f\"  Avg confidence (backward): {conf_backward.mean():.3f}\")\n",
        "    print(f\"  Avg confidence (forward):  {conf_forward.mean():.3f}\")\n",
        "\n",
        "    if disagreements.sum() > 0:\n",
        "        print(f\"\\n  When predictions DISAGREE:\")\n",
        "        print(f\"    Avg conf difference: {np.abs(conf_backward[disagreements] - conf_forward[disagreements]).mean():.3f}\")\n",
        "        print(f\"    Max conf difference: {np.abs(conf_backward[disagreements] - conf_forward[disagreements]).max():.3f}\")\n",
        "        print(f\"    Backward higher: {(conf_backward[disagreements] > conf_forward[disagreements]).sum()}\")\n",
        "        print(f\"    Forward higher:  {(conf_forward[disagreements] > conf_backward[disagreements]).sum()}\")\n",
        "\n",
        "print(\"‚úÖ Bidirectional ensemble functions defined (Backward + Forward only)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FG2rO5MNqUE",
        "outputId": "993538b9-0136-4b2b-e3b5-944f09202340"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Bidirectional ensemble functions defined (Backward + Forward only)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline_single_seed(train_df, test_df, seed, verbose=False, debug_confidence=False):\n",
        "    \"\"\"\n",
        "    Run realistic pipeline with Bidirectional Ensemble (Backward + Forward) + Temporal Voting.\n",
        "    Includes optional confidence analysis for debugging.\n",
        "\n",
        "    1. Resets memory/seeds.\n",
        "    2. Trains on pure segments.\n",
        "    3. Infers with 2 sliding window directions (backward, forward).\n",
        "    4. Ensemble: Chooses prediction with highest confidence.\n",
        "    5. Smooths predictions with a Majority Vote filter.\n",
        "    6. (Optional) Analyzes confidence distributions for debugging.\n",
        "    \"\"\"\n",
        "    # 0. PREVENT MEMORY LEAKS & ENSURE SEEDING\n",
        "    tf.keras.backend.clear_session()\n",
        "    set_seeds(seed)\n",
        "\n",
        "    # HYPERPARAMETERS\n",
        "    window_size = 10     # Window size for both directions\n",
        "    vote_window = 5      # The smoothing neighborhood (5 seconds)\n",
        "    max_seq_length = 50\n",
        "\n",
        "    # 1. Preprocessing\n",
        "    train_df = create_room_groups(train_df)\n",
        "    train_vectors = create_beacon_count_vectors(train_df)\n",
        "    test_vectors = create_beacon_count_vectors(test_df)\n",
        "\n",
        "    # 2. Sequence Creation\n",
        "    X_train, y_train = create_sequences_from_groups(train_vectors, max_length=max_seq_length)\n",
        "\n",
        "    # Create bidirectional windows for test\n",
        "    X_test_backward, X_test_forward, y_test = \\\n",
        "        create_bidirectional_windows_by_day(test_vectors, window_size=window_size)\n",
        "\n",
        "    # 3. Encoding & Padding\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(list(y_train) + list(y_test))\n",
        "    y_train_encoded = label_encoder.transform(y_train)\n",
        "    y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "    X_train_padded = pad_sequences(X_train, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "\n",
        "    # Pad both test window types\n",
        "    X_test_backward_padded = pad_sequences(X_test_backward, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "    X_test_forward_padded = pad_sequences(X_test_forward, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "\n",
        "    # 4. Train Model with Macro F1 Optimization\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    model = build_bidirectional_gru_model(input_shape=(max_seq_length, 23), num_classes=len(label_encoder.classes_))\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=0)\n",
        "    ]\n",
        "\n",
        "    # Use backward window for validation (standard approach)\n",
        "    model.fit(\n",
        "        X_train_padded, y_train_encoded,\n",
        "        validation_data=(X_test_backward_padded, y_test_encoded),\n",
        "        epochs=100, batch_size=32,\n",
        "        class_weight=class_weight_dict,\n",
        "        callbacks=callbacks, verbose=0\n",
        "    )\n",
        "\n",
        "    # 5. CONFIDENCE ANALYSIS (Optional Debug)\n",
        "    if debug_confidence:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"üîç CONFIDENCE ANALYSIS - Seed {seed}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Analyze on full test set\n",
        "        sample_size = min(1000, len(X_test_backward_padded))\n",
        "\n",
        "        probs_backward = model.predict(X_test_backward_padded[:sample_size], verbose=0)\n",
        "        probs_forward = model.predict(X_test_forward_padded[:sample_size], verbose=0)\n",
        "\n",
        "        conf_backward = np.max(probs_backward, axis=1)\n",
        "        conf_forward = np.max(probs_forward, axis=1)\n",
        "\n",
        "        pred_backward = np.argmax(probs_backward, axis=1)\n",
        "        pred_forward = np.argmax(probs_forward, axis=1)\n",
        "\n",
        "        # Cases where predictions differ\n",
        "        disagreements = pred_backward != pred_forward\n",
        "        agreements = pred_backward == pred_forward\n",
        "\n",
        "        print(f\"\\nüìä Overall Statistics (first {sample_size} samples):\")\n",
        "        print(f\"  Total samples analyzed: {sample_size}\")\n",
        "        print(f\"  Predictions AGREE:     {agreements.sum():4d} ({100*agreements.sum()/sample_size:5.1f}%)\")\n",
        "        print(f\"  Predictions DISAGREE:  {disagreements.sum():4d} ({100*disagreements.sum()/sample_size:5.1f}%)\")\n",
        "\n",
        "        print(f\"\\nüìà Confidence Scores:\")\n",
        "        print(f\"  Backward window - Mean: {conf_backward.mean():.4f}, Std: {conf_backward.std():.4f}\")\n",
        "        print(f\"  Forward window  - Mean: {conf_forward.mean():.4f}, Std: {conf_forward.std():.4f}\")\n",
        "\n",
        "        if disagreements.sum() > 0:\n",
        "            conf_diff_when_disagree = np.abs(conf_backward[disagreements] - conf_forward[disagreements])\n",
        "\n",
        "            print(f\"\\n‚ö° When Predictions DISAGREE ({disagreements.sum()} cases):\")\n",
        "            print(f\"  Confidence difference:\")\n",
        "            print(f\"    Mean:   {conf_diff_when_disagree.mean():.4f}\")\n",
        "            print(f\"    Median: {np.median(conf_diff_when_disagree):.4f}\")\n",
        "            print(f\"    Std:    {conf_diff_when_disagree.std():.4f}\")\n",
        "            print(f\"    Min:    {conf_diff_when_disagree.min():.4f}\")\n",
        "            print(f\"    Max:    {conf_diff_when_disagree.max():.4f}\")\n",
        "\n",
        "            # Distribution of differences\n",
        "            print(f\"\\n  Confidence difference distribution:\")\n",
        "            print(f\"    < 0.05 (very small): {(conf_diff_when_disagree < 0.05).sum():3d} ({100*(conf_diff_when_disagree < 0.05).sum()/disagreements.sum():5.1f}%)\")\n",
        "            print(f\"    0.05-0.10:           {((conf_diff_when_disagree >= 0.05) & (conf_diff_when_disagree < 0.10)).sum():3d} ({100*((conf_diff_when_disagree >= 0.05) & (conf_diff_when_disagree < 0.10)).sum()/disagreements.sum():5.1f}%)\")\n",
        "            print(f\"    0.10-0.20:           {((conf_diff_when_disagree >= 0.10) & (conf_diff_when_disagree < 0.20)).sum():3d} ({100*((conf_diff_when_disagree >= 0.10) & (conf_diff_when_disagree < 0.20)).sum()/disagreements.sum():5.1f}%)\")\n",
        "            print(f\"    >= 0.20 (large):     {(conf_diff_when_disagree >= 0.20).sum():3d} ({100*(conf_diff_when_disagree >= 0.20).sum()/disagreements.sum():5.1f}%)\")\n",
        "\n",
        "            print(f\"\\n  Which window is more confident when they disagree:\")\n",
        "            backward_higher = (conf_backward[disagreements] > conf_forward[disagreements]).sum()\n",
        "            forward_higher = (conf_forward[disagreements] > conf_backward[disagreements]).sum()\n",
        "            print(f\"    Backward higher: {backward_higher:3d} ({100*backward_higher/disagreements.sum():5.1f}%)\")\n",
        "            print(f\"    Forward higher:  {forward_higher:3d} ({100*forward_higher/disagreements.sum():5.1f}%)\")\n",
        "\n",
        "            # Check correctness when they disagree\n",
        "            y_test_sample = y_test_encoded[:sample_size]\n",
        "            backward_correct = pred_backward[disagreements] == y_test_sample[disagreements]\n",
        "            forward_correct = pred_forward[disagreements] == y_test_sample[disagreements]\n",
        "\n",
        "            print(f\"\\n  Accuracy when predictions disagree:\")\n",
        "            print(f\"    Backward correct: {backward_correct.sum():3d} / {disagreements.sum()} ({100*backward_correct.sum()/disagreements.sum():5.1f}%)\")\n",
        "            print(f\"    Forward correct:  {forward_correct.sum():3d} / {disagreements.sum()} ({100*forward_correct.sum()/disagreements.sum():5.1f}%)\")\n",
        "            print(f\"    Both wrong:       {(~backward_correct & ~forward_correct).sum():3d} / {disagreements.sum()} ({100*(~backward_correct & ~forward_correct).sum()/disagreements.sum():5.1f}%)\")\n",
        "\n",
        "        print(f\"\\n{'='*80}\\n\")\n",
        "\n",
        "    # 6. BIDIRECTIONAL ENSEMBLE INFERENCE\n",
        "    y_pred_raw_encoded = ensemble_predictions_with_confidence(\n",
        "        model,\n",
        "        X_test_backward_padded,\n",
        "        X_test_forward_padded\n",
        "    )\n",
        "\n",
        "    # 7. TEMPORAL VOTING (Smoothing)\n",
        "    def apply_temporal_voting(preds, v_window):\n",
        "        \"\"\"Applies a majority vote filter to smooth room predictions.\"\"\"\n",
        "        smoothed = []\n",
        "        for i in range(len(preds)):\n",
        "            start = max(0, i - v_window // 2)\n",
        "            end = min(len(preds), i + v_window // 2 + 1)\n",
        "            neighborhood = preds[start:end]\n",
        "            smoothed.append(np.bincount(neighborhood).argmax())\n",
        "        return np.array(smoothed)\n",
        "\n",
        "    y_pred_voted_encoded = apply_temporal_voting(y_pred_raw_encoded, vote_window)\n",
        "    y_pred = label_encoder.inverse_transform(y_pred_voted_encoded)\n",
        "\n",
        "    # 8. Final Evaluation\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    per_class_f1 = f1_score(y_test, y_pred, average=None, labels=label_encoder.classes_, zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'seed': seed,\n",
        "        'macro_f1': macro_f1,\n",
        "        'per_class_f1': {label: f1 for label, f1 in zip(label_encoder.classes_, per_class_f1)}\n",
        "    }\n",
        "\n",
        "print(\"‚úì Pipeline updated with confidence analysis (use debug_confidence=True to enable)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rc_pqeTjhyw",
        "outputId": "a1bda8d2-4834-4237-e3a7-da0ae9a644a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Pipeline updated with confidence analysis (use debug_confidence=True to enable)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rt7ry8WNqbj",
        "outputId": "7a66b9df-1f3b-4f1a-d1f8-ff3ceaf192a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run 10 seeds for each of 4 folds\n",
        "seeds = [42, 123, 456, 789, 2024, 3141, 5926, 8888, 1337, 9999]\n",
        "folds = {\n",
        "    1: (train_df_1, test_df_1),\n",
        "    2: (train_df_2, test_df_2),\n",
        "    3: (train_df_3, test_df_3),\n",
        "    4: (train_df_4, test_df_4)\n",
        "}\n",
        "\n",
        "all_fold_results = {}\n",
        "\n",
        "for fold_num, (train_df, test_df) in folds.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"PROCESSING FOLD {fold_num}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    fold_results = []\n",
        "\n",
        "    for idx, seed in enumerate(seeds):\n",
        "        # Enable debug only for first seed of each fold\n",
        "        debug_mode = (idx == 0)\n",
        "\n",
        "        if debug_mode:\n",
        "            print(f\"  Running seed {seed} [WITH DEBUG]...\")\n",
        "        else:\n",
        "            print(f\"  Running seed {seed}...\", end=\" \")\n",
        "\n",
        "        result = run_pipeline_single_seed(train_df, test_df, seed, verbose=False, debug_confidence=debug_mode)\n",
        "        fold_results.append(result)\n",
        "        print(f\"Macro F1: {result['macro_f1']:.4f}\")\n",
        "\n",
        "    all_fold_results[fold_num] = fold_results\n",
        "\n",
        "    # Calculate fold statistics\n",
        "    macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "    print(f\"\\n  Fold {fold_num} Summary:\")\n",
        "    print(f\"    Mean Macro F1: {np.mean(macro_f1_scores):.4f} ¬± {np.std(macro_f1_scores):.4f}\")\n",
        "    print(f\"    Min: {np.min(macro_f1_scores):.4f}, Max: {np.max(macro_f1_scores):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ALL FOLDS COMPLETED!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bOCMii8ENqeP",
        "outputId": "953cb15c-d018-40f3-aaea-af88f197f3e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 1\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42 [WITH DEBUG]...\n",
            "\n",
            "================================================================================\n",
            "üîç CONFIDENCE ANALYSIS - Seed 42\n",
            "================================================================================\n",
            "\n",
            "üìä Overall Statistics (first 1000 samples):\n",
            "  Total samples analyzed: 1000\n",
            "  Predictions AGREE:      492 ( 49.2%)\n",
            "  Predictions DISAGREE:   508 ( 50.8%)\n",
            "\n",
            "üìà Confidence Scores:\n",
            "  Backward window - Mean: 0.3976, Std: 0.1277\n",
            "  Forward window  - Mean: 0.3974, Std: 0.1270\n",
            "\n",
            "‚ö° When Predictions DISAGREE (508 cases):\n",
            "  Confidence difference:\n",
            "    Mean:   0.1090\n",
            "    Median: 0.0829\n",
            "    Std:    0.0941\n",
            "    Min:    0.0009\n",
            "    Max:    0.4135\n",
            "\n",
            "  Confidence difference distribution:\n",
            "    < 0.05 (very small): 172 ( 33.9%)\n",
            "    0.05-0.10:           122 ( 24.0%)\n",
            "    0.10-0.20:           124 ( 24.4%)\n",
            "    >= 0.20 (large):      90 ( 17.7%)\n",
            "\n",
            "  Which window is more confident when they disagree:\n",
            "    Backward higher: 252 ( 49.6%)\n",
            "    Forward higher:  256 ( 50.4%)\n",
            "\n",
            "  Accuracy when predictions disagree:\n",
            "    Backward correct: 154 / 508 ( 30.3%)\n",
            "    Forward correct:  120 / 508 ( 23.6%)\n",
            "    Both wrong:       234 / 508 ( 46.1%)\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Macro F1: 0.3014\n",
            "  Running seed 123... Macro F1: 0.4389\n",
            "  Running seed 456... Macro F1: 0.3861\n",
            "  Running seed 789... Macro F1: 0.5334\n",
            "  Running seed 2024... Macro F1: 0.4486\n",
            "  Running seed 3141... Macro F1: 0.3580\n",
            "  Running seed 5926... Macro F1: 0.5311\n",
            "  Running seed 8888... Macro F1: 0.4159\n",
            "  Running seed 1337... Macro F1: 0.3844\n",
            "  Running seed 9999... Macro F1: 0.4178\n",
            "\n",
            "  Fold 1 Summary:\n",
            "    Mean Macro F1: 0.4216 ¬± 0.0683\n",
            "    Min: 0.3014, Max: 0.5334\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 2\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42 [WITH DEBUG]...\n",
            "\n",
            "================================================================================\n",
            "üîç CONFIDENCE ANALYSIS - Seed 42\n",
            "================================================================================\n",
            "\n",
            "üìä Overall Statistics (first 1000 samples):\n",
            "  Total samples analyzed: 1000\n",
            "  Predictions AGREE:      669 ( 66.9%)\n",
            "  Predictions DISAGREE:   331 ( 33.1%)\n",
            "\n",
            "üìà Confidence Scores:\n",
            "  Backward window - Mean: 0.4951, Std: 0.1852\n",
            "  Forward window  - Mean: 0.4960, Std: 0.1841\n",
            "\n",
            "‚ö° When Predictions DISAGREE (331 cases):\n",
            "  Confidence difference:\n",
            "    Mean:   0.1338\n",
            "    Median: 0.0984\n",
            "    Std:    0.1150\n",
            "    Min:    0.0011\n",
            "    Max:    0.5153\n",
            "\n",
            "  Confidence difference distribution:\n",
            "    < 0.05 (very small):  80 ( 24.2%)\n",
            "    0.05-0.10:            91 ( 27.5%)\n",
            "    0.10-0.20:            85 ( 25.7%)\n",
            "    >= 0.20 (large):      75 ( 22.7%)\n",
            "\n",
            "  Which window is more confident when they disagree:\n",
            "    Backward higher: 178 ( 53.8%)\n",
            "    Forward higher:  153 ( 46.2%)\n",
            "\n",
            "  Accuracy when predictions disagree:\n",
            "    Backward correct: 134 / 331 ( 40.5%)\n",
            "    Forward correct:  117 / 331 ( 35.3%)\n",
            "    Both wrong:        80 / 331 ( 24.2%)\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Macro F1: 0.4176\n",
            "  Running seed 123... Macro F1: 0.3381\n",
            "  Running seed 456... "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1749796301.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Running seed {seed}...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_pipeline_single_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_confidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mfold_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Macro F1: {result['macro_f1']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2568378693.py\u001b[0m in \u001b[0;36mrun_pipeline_single_seed\u001b[0;34m(train_df, test_df, seed, verbose, debug_confidence)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Use backward window for validation (standard approach)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mX_train_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_backward_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    399\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                     )\n\u001b[0;32m--> 401\u001b[0;31m                 val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    402\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_evaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to text file\n",
        "with open('4fold_10seed_results.txt', 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"4-FOLD CROSS-VALIDATION WITH 10 SEEDS PER FOLD\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    # Overall summary\n",
        "    all_macro_f1 = []\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        fold_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "        all_macro_f1.extend(fold_scores)\n",
        "\n",
        "    f.write(\"OVERALL RESULTS (40 runs total):\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Mean Macro F1: {np.mean(all_macro_f1):.4f} ¬± {np.std(all_macro_f1):.4f}\\n\")\n",
        "    f.write(f\"Min: {np.min(all_macro_f1):.4f}, Max: {np.max(all_macro_f1):.4f}\\n\\n\")\n",
        "\n",
        "    # Per-fold results\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        f.write(f\"\\n{'='*80}\\n\")\n",
        "        f.write(f\"FOLD {fold_num} RESULTS\\n\")\n",
        "        f.write(f\"{'='*80}\\n\\n\")\n",
        "\n",
        "        fold_results = all_fold_results[fold_num]\n",
        "        macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "\n",
        "        f.write(f\"Macro F1 Scores (10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        for i, result in enumerate(fold_results):\n",
        "            f.write(f\"  Seed {result['seed']:5d}: {result['macro_f1']:.4f}\\n\")\n",
        "\n",
        "        f.write(f\"\\nStatistics:\\n\")\n",
        "        f.write(f\"  Mean: {np.mean(macro_f1_scores):.4f} ¬± {np.std(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Min:  {np.min(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Max:  {np.max(macro_f1_scores):.4f}\\n\")\n",
        "\n",
        "        # Per-class F1 (averaged across 10 seeds)\n",
        "        f.write(f\"\\nPer-Class F1 Scores (averaged across 10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "\n",
        "        # Collect all class names\n",
        "        all_classes = set()\n",
        "        for result in fold_results:\n",
        "            all_classes.update(result['per_class_f1'].keys())\n",
        "\n",
        "        # Average per-class F1 across seeds\n",
        "        for class_name in sorted(all_classes):\n",
        "            class_f1_scores = [r['per_class_f1'].get(class_name, 0) for r in fold_results]\n",
        "            mean_f1 = np.mean(class_f1_scores)\n",
        "            std_f1 = np.std(class_f1_scores)\n",
        "            f.write(f\"  {class_name:20s}: {mean_f1:.4f} ¬± {std_f1:.4f}\\n\")\n",
        "\n",
        "print(\"‚úÖ Results saved to 4fold_10seed_results.txt\")"
      ],
      "metadata": {
        "id": "zNURmdwCN0gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY - 4 FOLDS √ó 10 SEEDS = 40 TOTAL RUNS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    macro_f1_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "    print(f\"Fold {fold_num}: {np.mean(macro_f1_scores):.4f} ¬± {np.std(macro_f1_scores):.4f}\")\n",
        "\n",
        "all_macro_f1 = []\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    all_macro_f1.extend([r['macro_f1'] for r in all_fold_results[fold_num]])\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Overall Mean: {np.mean(all_macro_f1):.4f} ¬± {np.std(all_macro_f1):.4f}\")\n",
        "print(f\"{'='*80}\")"
      ],
      "metadata": {
        "id": "wPP_0K0rN2XE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
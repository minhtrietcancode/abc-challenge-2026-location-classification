{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "60VMoKcqNeNE",
        "outputId": "f542c36d-694c-4d50-87d6-146bcd5a8cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from tensorflow.keras.layers import Bidirectional, GRU\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ All imports successful\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmy0nM8ONqO2",
        "outputId": "ec0465ca-cb50-456f-c243-bb6e3441f3b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_filter_fold(i):\n",
        "    train_dir = f'/content/drive/MyDrive/split_data/fold{i}/train.csv'\n",
        "    test_dir = f'/content/drive/MyDrive/split_data/fold{i}/test.csv'\n",
        "    train_df = pd.read_csv(train_dir)\n",
        "    test_df = pd.read_csv(test_dir)\n",
        "\n",
        "    train_labels = list(train_df['room'].unique())\n",
        "    test_labels = list(test_df['room'].unique())\n",
        "    common_labels = list(set(train_labels) & set(test_labels))\n",
        "\n",
        "    train_df = train_df[train_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "    test_df = test_df[test_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Load all 4 folds\n",
        "train_df_1, test_df_1 = load_and_filter_fold(1)\n",
        "train_df_2, test_df_2 = load_and_filter_fold(2)\n",
        "train_df_3, test_df_3 = load_and_filter_fold(3)\n",
        "train_df_4, test_df_4 = load_and_filter_fold(4)\n",
        "\n",
        "print(\"✓ All folds loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Scobs0NqRs",
        "outputId": "42b4dfd0-cc16-4573-a8e8-8f636691ad0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All folds loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "def create_room_groups(df):\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    df['room_group'] = (df['room'] != df['room'].shift()).cumsum()\n",
        "    return df\n",
        "\n",
        "def create_beacon_count_vectors(df):\n",
        "    \"\"\"Aggregates readings into 1s vectors. Handles data with or without 'room_group'.\"\"\"\n",
        "    vectors = []\n",
        "    has_groups = 'room_group' in df.columns # Check if we are in 'training' mode\n",
        "\n",
        "    for _, group in df.groupby('timestamp'):\n",
        "        beacon_counts = group['mac address'].value_counts()\n",
        "        total_readings = len(group)\n",
        "\n",
        "        vector = [0.0] * 23\n",
        "        for beacon_id, count in beacon_counts.items():\n",
        "            if 1 <= beacon_id <= 23:\n",
        "                vector[int(beacon_id) - 1] = count / total_readings\n",
        "\n",
        "        entry = {\n",
        "            'timestamp': group['timestamp'].iloc[0],\n",
        "            'room': group['room'].iloc[0],\n",
        "            'beacon_vector': vector\n",
        "        }\n",
        "\n",
        "        if has_groups:\n",
        "            entry['room_group'] = group['room_group'].iloc[0]\n",
        "\n",
        "        vectors.append(entry)\n",
        "\n",
        "    return pd.DataFrame(vectors)\n",
        "\n",
        "def create_sequences_from_groups(vector_df, min_length=3, max_length=50):\n",
        "    \"\"\"Used for Training: Creates clean sequences where the room is constant.\"\"\"\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for (room, room_group), group in vector_df.groupby(['room', 'room_group']):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=False)\n",
        "        seq_length = len(group)\n",
        "\n",
        "        if seq_length < min_length:\n",
        "            continue\n",
        "\n",
        "        if seq_length > max_length:\n",
        "            group = group.tail(max_length)\n",
        "\n",
        "        sequence = [row['beacon_vector'] for _, row in group.iterrows()]\n",
        "        sequences.append(sequence)\n",
        "        labels.append(room)\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "def create_sliding_windows_by_day(vector_df, window_size=10):\n",
        "    \"\"\"Used for Inference: Creates a sequence for every frame, respecting day boundaries.\"\"\"\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    # Ensure chronological order and group by day\n",
        "    vector_df['dt'] = pd.to_datetime(vector_df['timestamp'])\n",
        "    vector_df['date'] = vector_df['dt'].dt.date\n",
        "\n",
        "    for _, day_group in vector_df.groupby('date'):\n",
        "        day_group = day_group.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "        if len(day_group) >= window_size:\n",
        "            vectors = list(day_group['beacon_vector'])\n",
        "            rooms = list(day_group['room'])\n",
        "\n",
        "            for i in range(len(vectors) - window_size + 1):\n",
        "                window = vectors[i : i + window_size]\n",
        "                sequences.append(window)\n",
        "                # Goal: Predict the room at the final timestamp of the window\n",
        "                labels.append(rooms[i + window_size - 1])\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "def build_bidirectional_gru_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Bidirectional GRU Architecture\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Masking(mask_value=0.0, input_shape=input_shape),\n",
        "\n",
        "        Bidirectional(GRU(128, return_sequences=True)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Bidirectional(GRU(64, return_sequences=False)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "print(\"✅ Bidirectional GRU model function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FG2rO5MNqUE",
        "outputId": "016b1e2a-7837-4e41-f15c-8c54c1dbd48c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Bidirectional GRU model function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_adjacency_matrix():\n",
        "    \"\"\"\n",
        "    Build room adjacency from the floor plan.\n",
        "    Returns: adjacency dict and room list\n",
        "    \"\"\"\n",
        "    # All unique room names from your data\n",
        "    rooms = [\n",
        "        # left wings of 5th floor\n",
        "        '501', '502', '503', '505', '506',\n",
        "        '513', '515', '516', '517',\n",
        "\n",
        "        # middle of 5th floor\n",
        "        'cleaning', 'kitchen', 'cafeteria', 'nurse station',\n",
        "\n",
        "        # right wings of 5th floor\n",
        "        '507', '508', '510', '511', '512',\n",
        "        '518', '520', '521', '522', '523',\n",
        "\n",
        "        # and the hallway\n",
        "        'hallway'\n",
        "    ]\n",
        "\n",
        "    # Build adjacency manually from floor plan\n",
        "    adjacency = {}\n",
        "\n",
        "    # top left wings\n",
        "    adjacency['501'] = ['502', 'hallway', '513', '515', '516']\n",
        "    adjacency['502'] = ['501', '503', 'hallway', '515', '515', '516', '517']\n",
        "    adjacency['503'] = ['502', 'hallway', '505', '516', '517']\n",
        "    adjacency['505'] = ['503', '506', 'hallway', '517']\n",
        "    adjacency['506'] = ['505', 'hallway']\n",
        "\n",
        "    # down left wings\n",
        "    adjacency['513'] = ['501', '515', 'hallway']\n",
        "    adjacency['515'] = ['513', '501', '516', '502', 'hallway']\n",
        "    adjacency['516'] = ['515', '517', 'hallway', '502', '501', '503']\n",
        "    adjacency['517'] = ['516', '502', '503', '505', 'hallway']\n",
        "\n",
        "    # middle\n",
        "    adjacency['cleaning'] = ['hallway', '506']\n",
        "    adjacency['kitchen'] = ['hallway', 'cafeteria']\n",
        "    adjacency['cafeteria'] = ['hallway', 'kitchen', 'nurse station']\n",
        "    adjacency['nurse station'] = ['cafeteria', '518', '507', 'hallway']\n",
        "\n",
        "    # top right wings\n",
        "    adjacency['507'] = ['hallway', 'nurse station', '508', '518', '520']\n",
        "    adjacency['508'] = ['hallway', '507', '510', '518', '520', '521']\n",
        "    adjacency['510'] = ['hallway', '508', '511', '520', '521', '522']\n",
        "    adjacency['511'] = ['hallway', '510', '512', '521', '522', '523']\n",
        "    adjacency['512'] = ['hallway', '511', '522', '523']\n",
        "\n",
        "    # down right wings\n",
        "    adjacency['518'] = ['hallway', 'nurse station', '507', '520', '508']\n",
        "    adjacency['520'] = ['hallway', '507', '508', '510', '518', '521']\n",
        "    adjacency['521'] = ['hallway', '508', '510', '511', '520', '522']\n",
        "    adjacency['522'] = ['hallway', '510', '511', '512', '521', '523']\n",
        "    adjacency['523'] = ['hallway', '511', '512', '522']\n",
        "\n",
        "    # Hallway connects to EVERYTHING (central corridor)\n",
        "    adjacency['hallway'] = rooms.copy()\n",
        "    adjacency['hallway'].remove('hallway')  # Don't connect to itself\n",
        "\n",
        "    return adjacency, rooms\n",
        "\n",
        "adjacency_matrix, all_rooms = build_adjacency_matrix()\n",
        "print(\"✅ Adjacency matrix built\")\n",
        "print(f\"   Example: kitchen connects to {adjacency_matrix['kitchen']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOtiOlJYjdhA",
        "outputId": "4f901039-c817-432f-88a9-0e9151b9d7fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Adjacency matrix built\n",
            "   Example: kitchen connects to ['hallway', 'cafeteria']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_spatial_decoding(predictions_encoded, confidences, timestamps,\n",
        "                             adjacency_matrix, label_encoder,\n",
        "                             transition_penalty=5.0):\n",
        "    \"\"\"\n",
        "    Use Viterbi algorithm to find globally optimal room sequence\n",
        "    considering spatial constraints\n",
        "    \"\"\"\n",
        "    n_frames = len(predictions_encoded)\n",
        "    n_rooms = len(label_encoder.classes_)\n",
        "    room_names = label_encoder.classes_\n",
        "\n",
        "    # Create lookup: room name -> index\n",
        "    room_to_idx = {room: i for i, room in enumerate(room_names)}\n",
        "\n",
        "    # Viterbi tables\n",
        "    viterbi = np.zeros((n_frames, n_rooms))\n",
        "    backpointer = np.zeros((n_frames, n_rooms), dtype=int)\n",
        "\n",
        "    # Initialize first frame with model confidences\n",
        "    for room_idx in range(n_rooms):\n",
        "        viterbi[0, room_idx] = confidences[0] if predictions_encoded[0] == room_idx else 0.01\n",
        "\n",
        "    # Forward pass\n",
        "    for t in range(1, n_frames):\n",
        "        prev_room_probs = viterbi[t-1]\n",
        "        time_diff = (timestamps[t] - timestamps[t-1]).total_seconds()\n",
        "\n",
        "        for curr_room_idx in range(n_rooms):\n",
        "            curr_room_name = room_names[curr_room_idx]\n",
        "\n",
        "            # Model confidence for this room\n",
        "            model_conf = confidences[t] if predictions_encoded[t] == curr_room_idx else 0.01\n",
        "\n",
        "            # Find best previous room\n",
        "            best_score = -np.inf\n",
        "            best_prev = 0\n",
        "\n",
        "            for prev_room_idx in range(n_rooms):\n",
        "                prev_room_name = room_names[prev_room_idx]\n",
        "\n",
        "                # Transition score\n",
        "                if prev_room_name == curr_room_name:\n",
        "                    # Staying in same room: bonus\n",
        "                    transition_score = 2.0\n",
        "                elif curr_room_name in adjacency_matrix.get(prev_room_name, []):\n",
        "                    # Adjacent rooms: allowed\n",
        "                    transition_score = 0.0\n",
        "                else:\n",
        "                    # Non-adjacent: penalty (but not impossible!)\n",
        "                    transition_score = -transition_penalty\n",
        "\n",
        "                # Time penalty: too quick transitions are suspicious\n",
        "                if time_diff < 3.0 and prev_room_name != curr_room_name:\n",
        "                    transition_score -= 1.0\n",
        "\n",
        "                total_score = prev_room_probs[prev_room_idx] + transition_score + np.log(model_conf + 1e-10)\n",
        "\n",
        "                if total_score > best_score:\n",
        "                    best_score = total_score\n",
        "                    best_prev = prev_room_idx\n",
        "\n",
        "            viterbi[t, curr_room_idx] = best_score\n",
        "            backpointer[t, curr_room_idx] = best_prev\n",
        "\n",
        "    # Backward pass: find optimal path\n",
        "    path = np.zeros(n_frames, dtype=int)\n",
        "    path[-1] = np.argmax(viterbi[-1])\n",
        "\n",
        "    for t in range(n_frames - 2, -1, -1):\n",
        "        path[t] = backpointer[t + 1, path[t + 1]]\n",
        "\n",
        "    # Decode to room names\n",
        "    optimal_rooms = label_encoder.inverse_transform(path)\n",
        "\n",
        "    return optimal_rooms\n",
        "\n",
        "print(\"✅ Viterbi global spatial decoding ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgl4Tuzpjfnz",
        "outputId": "99a7bf88-41f1-4c26-f2c5-7017d36a18e7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Viterbi global spatial decoding ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline_single_seed(train_df, test_df, seed, verbose=False):\n",
        "    \"\"\"\n",
        "    Sliding window (10s) + Temporal voting (5s) + Viterbi spatial decoding\n",
        "    \"\"\"\n",
        "    tf.keras.backend.clear_session()\n",
        "    set_seeds(seed)\n",
        "\n",
        "    window_size = 10\n",
        "    vote_window = 5\n",
        "    max_seq_length = 50\n",
        "\n",
        "    # 1. Preprocessing\n",
        "    train_df = create_room_groups(train_df)\n",
        "    train_vectors = create_beacon_count_vectors(train_df)\n",
        "    test_vectors = create_beacon_count_vectors(test_df)\n",
        "\n",
        "    # 2. Sequence Creation\n",
        "    X_train, y_train = create_sequences_from_groups(train_vectors, max_length=max_seq_length)\n",
        "    X_test, y_test = create_sliding_windows_by_day(test_vectors, window_size=window_size)\n",
        "\n",
        "    # 3. Encoding & Padding\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(list(y_train) + list(y_test))\n",
        "\n",
        "    y_train_encoded = label_encoder.transform(y_train)\n",
        "    y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "    X_train_padded = pad_sequences(X_train, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "    X_test_padded = pad_sequences(X_test, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "\n",
        "    # 4. Train Model\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    model = build_bidirectional_gru_model(input_shape=(max_seq_length, 23), num_classes=len(label_encoder.classes_))\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=0)\n",
        "    ]\n",
        "\n",
        "    model.fit(\n",
        "        X_train_padded, y_train_encoded,\n",
        "        validation_data=(X_test_padded, y_test_encoded),\n",
        "        epochs=100, batch_size=32,\n",
        "        class_weight=class_weight_dict,\n",
        "        callbacks=callbacks, verbose=0\n",
        "    )\n",
        "\n",
        "    # 5. INFERENCE\n",
        "    y_pred_probs = model.predict(X_test_padded, verbose=0)\n",
        "    y_pred_raw_encoded = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # 6. TEMPORAL VOTING (5s majority vote)\n",
        "    def apply_temporal_voting(preds, v_window):\n",
        "        smoothed = []\n",
        "        for i in range(len(preds)):\n",
        "            start = max(0, i - v_window // 2)\n",
        "            end = min(len(preds), i + v_window // 2 + 1)\n",
        "            neighborhood = preds[start:end]\n",
        "            smoothed.append(np.bincount(neighborhood).argmax())\n",
        "        return np.array(smoothed)\n",
        "\n",
        "    y_pred_voted_encoded = apply_temporal_voting(y_pred_raw_encoded, vote_window)\n",
        "\n",
        "    # 7. VITERBI SPATIAL DECODING\n",
        "    # Get timestamps matching sliding window predictions\n",
        "    test_vectors['timestamp'] = pd.to_datetime(test_vectors['timestamp'])\n",
        "    test_vectors_sorted = test_vectors.sort_values('timestamp').reset_index(drop=True)\n",
        "    test_vectors_sorted['date'] = test_vectors_sorted['timestamp'].dt.date\n",
        "\n",
        "    timestamps_for_predictions = []\n",
        "    for _, day_group in test_vectors_sorted.groupby('date'):\n",
        "        day_group = day_group.sort_values('timestamp').reset_index(drop=True)\n",
        "        if len(day_group) >= window_size:\n",
        "            for i in range(len(day_group) - window_size + 1):\n",
        "                timestamps_for_predictions.append(day_group['timestamp'].iloc[i + window_size - 1])\n",
        "\n",
        "    # Get confidence scores\n",
        "    y_pred_confidences = np.max(y_pred_probs, axis=1)\n",
        "\n",
        "    # Apply Viterbi global optimization\n",
        "    y_pred_optimal = viterbi_spatial_decoding(\n",
        "        predictions_encoded=y_pred_voted_encoded,\n",
        "        confidences=y_pred_confidences,\n",
        "        timestamps=timestamps_for_predictions,\n",
        "        adjacency_matrix=adjacency_matrix,\n",
        "        label_encoder=label_encoder,\n",
        "        transition_penalty=5.0\n",
        "    )\n",
        "\n",
        "    # 8. Final Evaluation\n",
        "    macro_f1 = f1_score(y_test, y_pred_optimal, average='macro', zero_division=0)\n",
        "    per_class_f1 = f1_score(y_test, y_pred_optimal, average=None,\n",
        "                           labels=label_encoder.classes_, zero_division=0)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Seed {seed}: Macro F1 = {macro_f1:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'seed': seed,\n",
        "        'macro_f1': macro_f1,\n",
        "        'per_class_f1': {label: f1 for label, f1 in zip(label_encoder.classes_, per_class_f1)}\n",
        "    }\n",
        "\n",
        "print(\"✅ Pipeline with Viterbi spatial decoding ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rc_pqeTjhyw",
        "outputId": "f35ce90c-7cec-4d74-b635-42807e066647"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pipeline with Viterbi spatial decoding ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rt7ry8WNqbj",
        "outputId": "9b3df389-9295-4f11-a43c-84ad908e0ea2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run 10 seeds for each of 4 folds\n",
        "seeds = [42, 123, 456, 789, 2024, 3141, 5926, 8888, 1337, 9999]\n",
        "folds = {\n",
        "    1: (train_df_1, test_df_1),\n",
        "    2: (train_df_2, test_df_2),\n",
        "    3: (train_df_3, test_df_3),\n",
        "    4: (train_df_4, test_df_4)\n",
        "}\n",
        "\n",
        "all_fold_results = {}\n",
        "\n",
        "for fold_num, (train_df, test_df) in folds.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"PROCESSING FOLD {fold_num}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    fold_results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"  Running seed {seed}...\", end=\" \")\n",
        "        result = run_pipeline_single_seed(train_df, test_df, seed, verbose=False)\n",
        "        fold_results.append(result)\n",
        "        print(f\"Macro F1: {result['macro_f1']:.4f}\")\n",
        "\n",
        "    all_fold_results[fold_num] = fold_results\n",
        "\n",
        "    # Calculate fold statistics\n",
        "    macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "    print(f\"\\n  Fold {fold_num} Summary:\")\n",
        "    print(f\"    Mean Macro F1: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\")\n",
        "    print(f\"    Min: {np.min(macro_f1_scores):.4f}, Max: {np.max(macro_f1_scores):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ALL FOLDS COMPLETED!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOCMii8ENqeP",
        "outputId": "74608ca8-7509-4a0f-c34d-dbb71c4b5db9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 1\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.3681\n",
            "  Running seed 123... Macro F1: 0.4194\n",
            "  Running seed 456... Macro F1: 0.3903\n",
            "  Running seed 789... Macro F1: 0.4875\n",
            "  Running seed 2024... Macro F1: 0.4353\n",
            "  Running seed 3141... Macro F1: 0.3350\n",
            "  Running seed 5926... Macro F1: 0.4721\n",
            "  Running seed 8888... Macro F1: 0.4091\n",
            "  Running seed 1337... Macro F1: 0.3960\n",
            "  Running seed 9999... Macro F1: 0.4122\n",
            "\n",
            "  Fold 1 Summary:\n",
            "    Mean Macro F1: 0.4125 ± 0.0430\n",
            "    Min: 0.3350, Max: 0.4875\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 2\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.4001\n",
            "  Running seed 123... Macro F1: 0.3348\n",
            "  Running seed 456... Macro F1: 0.3923\n",
            "  Running seed 789... Macro F1: 0.3372\n",
            "  Running seed 2024... Macro F1: 0.4119\n",
            "  Running seed 3141... Macro F1: 0.3570\n",
            "  Running seed 5926... Macro F1: 0.3806\n",
            "  Running seed 8888... Macro F1: 0.3477\n",
            "  Running seed 1337... Macro F1: 0.3822\n",
            "  Running seed 9999... Macro F1: 0.3527\n",
            "\n",
            "  Fold 2 Summary:\n",
            "    Mean Macro F1: 0.3697 ± 0.0259\n",
            "    Min: 0.3348, Max: 0.4119\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 3\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.3203\n",
            "  Running seed 123... Macro F1: 0.4099\n",
            "  Running seed 456... Macro F1: 0.3585\n",
            "  Running seed 789... Macro F1: 0.4672\n",
            "  Running seed 2024... Macro F1: 0.3766\n",
            "  Running seed 3141... Macro F1: 0.3505\n",
            "  Running seed 5926... Macro F1: 0.4024\n",
            "  Running seed 8888... Macro F1: 0.4319\n",
            "  Running seed 1337... Macro F1: 0.3899\n",
            "  Running seed 9999... Macro F1: 0.4366\n",
            "\n",
            "  Fold 3 Summary:\n",
            "    Mean Macro F1: 0.3944 ± 0.0422\n",
            "    Min: 0.3203, Max: 0.4672\n",
            "\n",
            "================================================================================\n",
            "PROCESSING FOLD 4\n",
            "================================================================================\n",
            "\n",
            "  Running seed 42... Macro F1: 0.3137\n",
            "  Running seed 123... Macro F1: 0.3389\n",
            "  Running seed 456... Macro F1: 0.3711\n",
            "  Running seed 789... Macro F1: 0.3117\n",
            "  Running seed 2024... Macro F1: 0.3341\n",
            "  Running seed 3141... Macro F1: 0.4137\n",
            "  Running seed 5926... Macro F1: 0.4107\n",
            "  Running seed 8888... Macro F1: 0.4102\n",
            "  Running seed 1337... Macro F1: 0.4018\n",
            "  Running seed 9999... Macro F1: 0.4232\n",
            "\n",
            "  Fold 4 Summary:\n",
            "    Mean Macro F1: 0.3729 ± 0.0422\n",
            "    Min: 0.3117, Max: 0.4232\n",
            "\n",
            "================================================================================\n",
            "ALL FOLDS COMPLETED!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to text file\n",
        "with open('4fold_10seed_results.txt', 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"4-FOLD CROSS-VALIDATION WITH 10 SEEDS PER FOLD\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    # Overall summary\n",
        "    all_macro_f1 = []\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        fold_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "        all_macro_f1.extend(fold_scores)\n",
        "\n",
        "    f.write(\"OVERALL RESULTS (40 runs total):\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Mean Macro F1: {np.mean(all_macro_f1):.4f} ± {np.std(all_macro_f1):.4f}\\n\")\n",
        "    f.write(f\"Min: {np.min(all_macro_f1):.4f}, Max: {np.max(all_macro_f1):.4f}\\n\\n\")\n",
        "\n",
        "    # Per-fold results\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        f.write(f\"\\n{'='*80}\\n\")\n",
        "        f.write(f\"FOLD {fold_num} RESULTS\\n\")\n",
        "        f.write(f\"{'='*80}\\n\\n\")\n",
        "\n",
        "        fold_results = all_fold_results[fold_num]\n",
        "        macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "\n",
        "        f.write(f\"Macro F1 Scores (10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        for i, result in enumerate(fold_results):\n",
        "            f.write(f\"  Seed {result['seed']:5d}: {result['macro_f1']:.4f}\\n\")\n",
        "\n",
        "        f.write(f\"\\nStatistics:\\n\")\n",
        "        f.write(f\"  Mean: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Min:  {np.min(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Max:  {np.max(macro_f1_scores):.4f}\\n\")\n",
        "\n",
        "        # Per-class F1 (averaged across 10 seeds)\n",
        "        f.write(f\"\\nPer-Class F1 Scores (averaged across 10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "\n",
        "        # Collect all class names\n",
        "        all_classes = set()\n",
        "        for result in fold_results:\n",
        "            all_classes.update(result['per_class_f1'].keys())\n",
        "\n",
        "        # Average per-class F1 across seeds\n",
        "        for class_name in sorted(all_classes):\n",
        "            class_f1_scores = [r['per_class_f1'].get(class_name, 0) for r in fold_results]\n",
        "            mean_f1 = np.mean(class_f1_scores)\n",
        "            std_f1 = np.std(class_f1_scores)\n",
        "            f.write(f\"  {class_name:20s}: {mean_f1:.4f} ± {std_f1:.4f}\\n\")\n",
        "\n",
        "print(\"✅ Results saved to 4fold_10seed_results.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNURmdwCN0gY",
        "outputId": "770464ac-d068-4378-9865-ee0800f2cce3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Results saved to 4fold_10seed_results.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY - 4 FOLDS × 10 SEEDS = 40 TOTAL RUNS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    macro_f1_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "    print(f\"Fold {fold_num}: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\")\n",
        "\n",
        "all_macro_f1 = []\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    all_macro_f1.extend([r['macro_f1'] for r in all_fold_results[fold_num]])\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Overall Mean: {np.mean(all_macro_f1):.4f} ± {np.std(all_macro_f1):.4f}\")\n",
        "print(f\"{'='*80}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPP_0K0rN2XE",
        "outputId": "a1409109-ec2c-405a-96d9-5d6eece09f99"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY - 4 FOLDS × 10 SEEDS = 40 TOTAL RUNS\n",
            "================================================================================\n",
            "\n",
            "Fold 1: 0.4125 ± 0.0430\n",
            "Fold 2: 0.3697 ± 0.0259\n",
            "Fold 3: 0.3944 ± 0.0422\n",
            "Fold 4: 0.3729 ± 0.0422\n",
            "\n",
            "================================================================================\n",
            "Overall Mean: 0.3874 ± 0.0427\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}
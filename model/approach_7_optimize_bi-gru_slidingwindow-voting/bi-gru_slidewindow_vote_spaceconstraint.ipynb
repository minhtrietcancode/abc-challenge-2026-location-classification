{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "60VMoKcqNeNE",
        "outputId": "d2d17b6a-2dcd-41fa-c10a-d919f14948d7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmy0nM8ONqO2",
        "outputId": "4701809f-072c-4c6a-c7dc-981b0e91c6c4"
      },
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from tensorflow.keras.layers import Bidirectional, GRU\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ All imports successful\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Scobs0NqRs",
        "outputId": "fa33ceea-ce03-4923-b35d-2362a3acb7ca"
      },
      "outputs": [],
      "source": [
        "def load_and_filter_fold(i):\n",
        "    train_dir = f'/content/drive/MyDrive/split_data/fold{i}/train.csv'\n",
        "    test_dir = f'/content/drive/MyDrive/split_data/fold{i}/test.csv'\n",
        "    train_df = pd.read_csv(train_dir)\n",
        "    test_df = pd.read_csv(test_dir)\n",
        "\n",
        "    train_labels = list(train_df['room'].unique())\n",
        "    test_labels = list(test_df['room'].unique())\n",
        "    common_labels = list(set(train_labels) & set(test_labels))\n",
        "\n",
        "    train_df = train_df[train_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "    test_df = test_df[test_df['room'].isin(common_labels)].reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Load all 4 folds\n",
        "train_df_1, test_df_1 = load_and_filter_fold(1)\n",
        "train_df_2, test_df_2 = load_and_filter_fold(2)\n",
        "train_df_3, test_df_3 = load_and_filter_fold(3)\n",
        "train_df_4, test_df_4 = load_and_filter_fold(4)\n",
        "\n",
        "print(\"✓ All folds loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FG2rO5MNqUE",
        "outputId": "f3d6d663-1887-424f-ec68-2bddac02faf4"
      },
      "outputs": [],
      "source": [
        "def set_seeds(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "def create_room_groups(df):\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    df['room_group'] = (df['room'] != df['room'].shift()).cumsum()\n",
        "    return df\n",
        "\n",
        "def create_beacon_count_vectors(df):\n",
        "    \"\"\"Aggregates readings into 1s vectors. Handles data with or without 'room_group'.\"\"\"\n",
        "    vectors = []\n",
        "    has_groups = 'room_group' in df.columns # Check if we are in 'training' mode\n",
        "\n",
        "    for _, group in df.groupby('timestamp'):\n",
        "        beacon_counts = group['mac address'].value_counts()\n",
        "        total_readings = len(group)\n",
        "\n",
        "        vector = [0.0] * 23\n",
        "        for beacon_id, count in beacon_counts.items():\n",
        "            if 1 <= beacon_id <= 23:\n",
        "                vector[int(beacon_id) - 1] = count / total_readings\n",
        "\n",
        "        entry = {\n",
        "            'timestamp': group['timestamp'].iloc[0],\n",
        "            'room': group['room'].iloc[0],\n",
        "            'beacon_vector': vector\n",
        "        }\n",
        "\n",
        "        if has_groups:\n",
        "            entry['room_group'] = group['room_group'].iloc[0]\n",
        "\n",
        "        vectors.append(entry)\n",
        "\n",
        "    return pd.DataFrame(vectors)\n",
        "\n",
        "def create_sequences_from_groups(vector_df, min_length=3, max_length=50):\n",
        "    \"\"\"Used for Training: Creates clean sequences where the room is constant.\"\"\"\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for (room, room_group), group in vector_df.groupby(['room', 'room_group']):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=False)\n",
        "        seq_length = len(group)\n",
        "\n",
        "        if seq_length < min_length:\n",
        "            continue\n",
        "\n",
        "        if seq_length > max_length:\n",
        "            group = group.tail(max_length)\n",
        "\n",
        "        sequence = [row['beacon_vector'] for _, row in group.iterrows()]\n",
        "        sequences.append(sequence)\n",
        "        labels.append(room)\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "def create_sliding_windows_by_day(vector_df, window_size=10):\n",
        "    \"\"\"Used for Inference: Creates a sequence for every frame, respecting day boundaries.\"\"\"\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    # Ensure chronological order and group by day\n",
        "    vector_df['dt'] = pd.to_datetime(vector_df['timestamp'])\n",
        "    vector_df['date'] = vector_df['dt'].dt.date\n",
        "\n",
        "    for _, day_group in vector_df.groupby('date'):\n",
        "        day_group = day_group.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "        if len(day_group) >= window_size:\n",
        "            vectors = list(day_group['beacon_vector'])\n",
        "            rooms = list(day_group['room'])\n",
        "\n",
        "            for i in range(len(vectors) - window_size + 1):\n",
        "                window = vectors[i : i + window_size]\n",
        "                sequences.append(window)\n",
        "                # Goal: Predict the room at the final timestamp of the window\n",
        "                labels.append(rooms[i + window_size - 1])\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "def build_bidirectional_gru_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Bidirectional GRU Architecture\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Masking(mask_value=0.0, input_shape=input_shape),\n",
        "\n",
        "        Bidirectional(GRU(128, return_sequences=True)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Bidirectional(GRU(64, return_sequences=False)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "print(\"✅ Bidirectional GRU model function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_adjacency_matrix():\n",
        "    \"\"\"\n",
        "    Build room adjacency from the floor plan.\n",
        "    Returns: adjacency dict and room list\n",
        "    \"\"\"\n",
        "    # All unique room names from your data\n",
        "    rooms = [\n",
        "        '501', '502', '505', '506', '508', '511', '512', '513', '515', '516', \n",
        "        '517', '518', '520', '522', '523',\n",
        "        'cafeteria', 'cleaning', 'hallway', 'kitchen', 'nurse station', 'toilet'\n",
        "    ]\n",
        "    \n",
        "    # Build adjacency manually from floor plan\n",
        "    adjacency = {}\n",
        "    \n",
        "    # Top row left (Rooms 1,2,3,5,6 → 501,502,505,506,508 based on numbers)\n",
        "    adjacency['501'] = ['502', 'hallway']\n",
        "    adjacency['502'] = ['501', '505', 'hallway']\n",
        "    adjacency['505'] = ['502', '506', 'hallway']\n",
        "    adjacency['506'] = ['505', '508', 'hallway', 'cleaning']\n",
        "    adjacency['508'] = ['506', 'hallway', 'cleaning']\n",
        "    \n",
        "    # Top row right (Rooms 7,8,10,11,12 → 511,512,515,516,517 based on numbers)\n",
        "    adjacency['511'] = ['512', 'hallway']\n",
        "    adjacency['512'] = ['511', '515', 'hallway']\n",
        "    adjacency['515'] = ['512', '516', 'hallway']\n",
        "    adjacency['516'] = ['515', '517', 'hallway']\n",
        "    adjacency['517'] = ['516', 'hallway']\n",
        "    \n",
        "    # Bottom row left (Rooms 13,15,16,17 → 513,518,520,522 based on numbers)\n",
        "    adjacency['513'] = ['518', 'hallway']\n",
        "    adjacency['518'] = ['513', '520', 'hallway']\n",
        "    adjacency['520'] = ['518', '522', 'hallway', 'kitchen']\n",
        "    adjacency['522'] = ['520', 'hallway', 'kitchen']\n",
        "    \n",
        "    # Bottom row right (Rooms 18,20,21,22,23 → numbers match)\n",
        "    adjacency['nurse station'] = ['cafeteria', 'hallway']\n",
        "    adjacency['523'] = ['hallway', 'nurse station']  # Room 18 next to nurse station\n",
        "    \n",
        "    # Central facilities\n",
        "    adjacency['kitchen'] = ['toilet', 'cafeteria', 'hallway', '520', '522']\n",
        "    adjacency['toilet'] = ['kitchen', 'cafeteria', 'hallway']\n",
        "    adjacency['cafeteria'] = ['kitchen', 'toilet', 'nurse station', 'hallway']\n",
        "    adjacency['cleaning'] = ['506', '508', 'hallway']\n",
        "    \n",
        "    # Hallway connects to EVERYTHING (central corridor)\n",
        "    adjacency['hallway'] = rooms.copy()\n",
        "    adjacency['hallway'].remove('hallway')  # Don't connect to itself\n",
        "    \n",
        "    return adjacency, rooms\n",
        "\n",
        "adjacency_matrix, all_rooms = build_adjacency_matrix()\n",
        "print(\"✅ Adjacency matrix built\")\n",
        "print(f\"   Example: kitchen connects to {adjacency_matrix['kitchen']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_spatial_temporal_filter(predictions, confidences, timestamps, \n",
        "                                   adjacency_matrix, \n",
        "                                   confidence_threshold=0.6,\n",
        "                                   time_threshold=3.0):\n",
        "    \"\"\"\n",
        "    Filter predictions using:\n",
        "    1. Spatial constraints (room adjacency)\n",
        "    2. Temporal constraints (time since last transition)\n",
        "    \"\"\"\n",
        "    filtered = []\n",
        "    current_room = predictions[0]\n",
        "    last_transition_time = timestamps[0]\n",
        "    \n",
        "    for i, (pred_room, conf, timestamp) in enumerate(zip(predictions, confidences, timestamps)):\n",
        "        time_diff = (timestamp - last_transition_time).total_seconds()\n",
        "        \n",
        "        # Case 1: Same room → always accept\n",
        "        if pred_room == current_room:\n",
        "            filtered.append(pred_room)\n",
        "            continue\n",
        "        \n",
        "        # Case 2: Trying to change rooms\n",
        "        # Check if rooms are adjacent\n",
        "        is_adjacent = pred_room in adjacency_matrix.get(current_room, [])\n",
        "        \n",
        "        # Temporal check: too soon to change rooms?\n",
        "        too_soon = time_diff < time_threshold\n",
        "        \n",
        "        if is_adjacent and not too_soon:\n",
        "            # Adjacent + enough time passed → accept if confident\n",
        "            if conf > confidence_threshold:\n",
        "                filtered.append(pred_room)\n",
        "                current_room = pred_room\n",
        "                last_transition_time = timestamp\n",
        "            else:\n",
        "                # Low confidence, stay in current room\n",
        "                filtered.append(current_room)\n",
        "        else:\n",
        "            # Non-adjacent OR too soon → reject transition\n",
        "            filtered.append(current_room)\n",
        "    \n",
        "    return filtered\n",
        "\n",
        "print(\"✅ Spatial-temporal filter ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbYKyThhNqYV",
        "outputId": "113a07f5-4241-4c7e-ef18-cb2f7f49d40c"
      },
      "outputs": [],
      "source": [
        "def run_pipeline_single_seed(train_df, test_df, seed, verbose=False):\n",
        "    \"\"\"\n",
        "    Sliding window (10s) + Temporal voting (5s) + Spatial-temporal filtering\n",
        "    \"\"\"\n",
        "    tf.keras.backend.clear_session()\n",
        "    set_seeds(seed)\n",
        "    \n",
        "    window_size = 10\n",
        "    vote_window = 5\n",
        "    max_seq_length = 50\n",
        "    \n",
        "    # 1. Preprocessing\n",
        "    train_df = create_room_groups(train_df)\n",
        "    train_vectors = create_beacon_count_vectors(train_df)\n",
        "    test_vectors = create_beacon_count_vectors(test_df)\n",
        "    \n",
        "    # 2. Sequence Creation\n",
        "    X_train, y_train = create_sequences_from_groups(train_vectors, max_length=max_seq_length)\n",
        "    X_test, y_test = create_sliding_windows_by_day(test_vectors, window_size=window_size)\n",
        "    \n",
        "    # 3. Encoding & Padding\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(list(y_train) + list(y_test))\n",
        "    \n",
        "    y_train_encoded = label_encoder.transform(y_train)\n",
        "    y_test_encoded = label_encoder.transform(y_test)\n",
        "    \n",
        "    X_train_padded = pad_sequences(X_train, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "    X_test_padded = pad_sequences(X_test, maxlen=max_seq_length, dtype='float32', padding='post', value=0.0)\n",
        "    \n",
        "    # 4. Train Model\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "    \n",
        "    model = build_bidirectional_gru_model(input_shape=(max_seq_length, 23), num_classes=len(label_encoder.classes_))\n",
        "    \n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=0)\n",
        "    ]\n",
        "    \n",
        "    model.fit(\n",
        "        X_train_padded, y_train_encoded,\n",
        "        validation_data=(X_test_padded, y_test_encoded),\n",
        "        epochs=100, batch_size=32,\n",
        "        class_weight=class_weight_dict,\n",
        "        callbacks=callbacks, verbose=0\n",
        "    )\n",
        "    \n",
        "    # 5. INFERENCE\n",
        "    y_pred_probs = model.predict(X_test_padded, verbose=0)\n",
        "    y_pred_raw_encoded = np.argmax(y_pred_probs, axis=1)\n",
        "    \n",
        "    # 6. TEMPORAL VOTING (5s majority vote)\n",
        "    def apply_temporal_voting(preds, v_window):\n",
        "        smoothed = []\n",
        "        for i in range(len(preds)):\n",
        "            start = max(0, i - v_window // 2)\n",
        "            end = min(len(preds), i + v_window // 2 + 1)\n",
        "            neighborhood = preds[start:end]\n",
        "            smoothed.append(np.bincount(neighborhood).argmax())\n",
        "        return np.array(smoothed)\n",
        "    \n",
        "    y_pred_voted_encoded = apply_temporal_voting(y_pred_raw_encoded, vote_window)\n",
        "    \n",
        "    # 7. SPATIAL-TEMPORAL FILTERING\n",
        "    # Get timestamps from test data\n",
        "    test_vectors['timestamp'] = pd.to_datetime(test_vectors['timestamp'])\n",
        "    \n",
        "    # Create timestamp list matching sliding window predictions\n",
        "    test_vectors_sorted = test_vectors.sort_values('timestamp').reset_index(drop=True)\n",
        "    test_vectors_sorted['date'] = test_vectors_sorted['timestamp'].dt.date\n",
        "    \n",
        "    timestamps_for_predictions = []\n",
        "    for _, day_group in test_vectors_sorted.groupby('date'):\n",
        "        day_group = day_group.sort_values('timestamp').reset_index(drop=True)\n",
        "        if len(day_group) >= window_size:\n",
        "            for i in range(len(day_group) - window_size + 1):\n",
        "                # Use timestamp at the END of the window\n",
        "                timestamps_for_predictions.append(day_group['timestamp'].iloc[i + window_size - 1])\n",
        "    \n",
        "    # Decode predictions to room names\n",
        "    y_pred_decoded = label_encoder.inverse_transform(y_pred_voted_encoded)\n",
        "    \n",
        "    # Get confidence scores\n",
        "    y_pred_confidences = np.max(y_pred_probs, axis=1)\n",
        "    \n",
        "    # Apply spatial-temporal filtering\n",
        "    y_pred_filtered = apply_spatial_temporal_filter(\n",
        "        predictions=y_pred_decoded,\n",
        "        confidences=y_pred_confidences,\n",
        "        timestamps=timestamps_for_predictions,\n",
        "        adjacency_matrix=adjacency_matrix,\n",
        "        confidence_threshold=0.6,\n",
        "        time_threshold=3.0\n",
        "    )\n",
        "    \n",
        "    # 8. Final Evaluation\n",
        "    macro_f1 = f1_score(y_test, y_pred_filtered, average='macro', zero_division=0)\n",
        "    per_class_f1 = f1_score(y_test, y_pred_filtered, average=None, \n",
        "                           labels=label_encoder.classes_, zero_division=0)\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"Seed {seed}: Macro F1 = {macro_f1:.4f}\")\n",
        "    \n",
        "    return {\n",
        "        'seed': seed,\n",
        "        'macro_f1': macro_f1,\n",
        "        'per_class_f1': {label: f1 for label, f1 in zip(label_encoder.classes_, per_class_f1)}\n",
        "    }\n",
        "\n",
        "print(\"✅ Updated pipeline with spatial-temporal filtering\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rt7ry8WNqbj",
        "outputId": "6cb2c5b3-caaa-495b-9b5a-a7c7cd891086"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOCMii8ENqeP",
        "outputId": "98c4e3a9-05c7-4b3e-e88f-642cb90eb4bc"
      },
      "outputs": [],
      "source": [
        "# Run 10 seeds for each of 4 folds\n",
        "seeds = [42, 123, 456, 789, 2024, 3141, 5926, 8888, 1337, 9999]\n",
        "folds = {\n",
        "    1: (train_df_1, test_df_1),\n",
        "    2: (train_df_2, test_df_2),\n",
        "    3: (train_df_3, test_df_3),\n",
        "    4: (train_df_4, test_df_4)\n",
        "}\n",
        "\n",
        "all_fold_results = {}\n",
        "\n",
        "for fold_num, (train_df, test_df) in folds.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"PROCESSING FOLD {fold_num}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    fold_results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"  Running seed {seed}...\", end=\" \")\n",
        "        result = run_pipeline_single_seed(train_df, test_df, seed, verbose=False)\n",
        "        fold_results.append(result)\n",
        "        print(f\"Macro F1: {result['macro_f1']:.4f}\")\n",
        "\n",
        "    all_fold_results[fold_num] = fold_results\n",
        "\n",
        "    # Calculate fold statistics\n",
        "    macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "    print(f\"\\n  Fold {fold_num} Summary:\")\n",
        "    print(f\"    Mean Macro F1: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\")\n",
        "    print(f\"    Min: {np.min(macro_f1_scores):.4f}, Max: {np.max(macro_f1_scores):.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ALL FOLDS COMPLETED!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNURmdwCN0gY",
        "outputId": "c4fedf9b-6d9d-46b3-ac4c-d5df369db6d7"
      },
      "outputs": [],
      "source": [
        "# Save results to text file\n",
        "with open('4fold_10seed_results.txt', 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"4-FOLD CROSS-VALIDATION WITH 10 SEEDS PER FOLD\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    # Overall summary\n",
        "    all_macro_f1 = []\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        fold_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "        all_macro_f1.extend(fold_scores)\n",
        "\n",
        "    f.write(\"OVERALL RESULTS (40 runs total):\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Mean Macro F1: {np.mean(all_macro_f1):.4f} ± {np.std(all_macro_f1):.4f}\\n\")\n",
        "    f.write(f\"Min: {np.min(all_macro_f1):.4f}, Max: {np.max(all_macro_f1):.4f}\\n\\n\")\n",
        "\n",
        "    # Per-fold results\n",
        "    for fold_num in [1, 2, 3, 4]:\n",
        "        f.write(f\"\\n{'='*80}\\n\")\n",
        "        f.write(f\"FOLD {fold_num} RESULTS\\n\")\n",
        "        f.write(f\"{'='*80}\\n\\n\")\n",
        "\n",
        "        fold_results = all_fold_results[fold_num]\n",
        "        macro_f1_scores = [r['macro_f1'] for r in fold_results]\n",
        "\n",
        "        f.write(f\"Macro F1 Scores (10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        for i, result in enumerate(fold_results):\n",
        "            f.write(f\"  Seed {result['seed']:5d}: {result['macro_f1']:.4f}\\n\")\n",
        "\n",
        "        f.write(f\"\\nStatistics:\\n\")\n",
        "        f.write(f\"  Mean: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Min:  {np.min(macro_f1_scores):.4f}\\n\")\n",
        "        f.write(f\"  Max:  {np.max(macro_f1_scores):.4f}\\n\")\n",
        "\n",
        "        # Per-class F1 (averaged across 10 seeds)\n",
        "        f.write(f\"\\nPer-Class F1 Scores (averaged across 10 seeds):\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "\n",
        "        # Collect all class names\n",
        "        all_classes = set()\n",
        "        for result in fold_results:\n",
        "            all_classes.update(result['per_class_f1'].keys())\n",
        "\n",
        "        # Average per-class F1 across seeds\n",
        "        for class_name in sorted(all_classes):\n",
        "            class_f1_scores = [r['per_class_f1'].get(class_name, 0) for r in fold_results]\n",
        "            mean_f1 = np.mean(class_f1_scores)\n",
        "            std_f1 = np.std(class_f1_scores)\n",
        "            f.write(f\"  {class_name:20s}: {mean_f1:.4f} ± {std_f1:.4f}\\n\")\n",
        "\n",
        "print(\"✅ Results saved to 4fold_10seed_results.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPP_0K0rN2XE",
        "outputId": "beb21c66-97b3-4937-bd42-c2798b135ca5"
      },
      "outputs": [],
      "source": [
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY - 4 FOLDS × 10 SEEDS = 40 TOTAL RUNS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    macro_f1_scores = [r['macro_f1'] for r in all_fold_results[fold_num]]\n",
        "    print(f\"Fold {fold_num}: {np.mean(macro_f1_scores):.4f} ± {np.std(macro_f1_scores):.4f}\")\n",
        "\n",
        "all_macro_f1 = []\n",
        "for fold_num in [1, 2, 3, 4]:\n",
        "    all_macro_f1.extend([r['macro_f1'] for r in all_fold_results[fold_num]])\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Overall Mean: {np.mean(all_macro_f1):.4f} ± {np.std(all_macro_f1):.4f}\")\n",
        "print(f\"{'='*80}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

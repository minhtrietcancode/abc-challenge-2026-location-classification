# Indoor BLE Localization - Comprehensive Analysis & Recommendations

## Executive Summary

**Current Performance**: Frame-level Macro F1 = 0.23  
**Target**: Macro F1 â‰¥ 0.50  
**Primary Issue**: Severe class imbalance causing minority classes (506, 517, 518, hallway, 522, 511, 513, 502, 501) to have F1 scores between 0.0-0.20

**Key Findings from Research**:
- RSSI signals are highly noisy and require sophisticated filtering
- Temporal dependencies are critical for indoor localization
- Class imbalance is a common problem requiring specialized techniques
- Adjacent room confusion is expected and can be addressed with spatial constraints

---

## PART 1: OPTIMAL PIPELINE (Independent Recommendation)

Based on extensive research of BLE indoor localization literature, here's what an optimal pipeline should look like:

### 1. SIGNAL PREPROCESSING & FILTERING

**Problem**: Raw RSSI values fluctuate dramatically due to multipath propagation, interference, and environmental factors.

**Research-Backed Solutions**:

#### A. Multi-Stage Filtering (Recommended Order)
1. **Outlier Removal**: Remove RSSI values outside typical range (-100 to -30 dBm)
2. **Moving Average Filter**: Smooth short-term fluctuations
3. **Kalman Filter**: Handle dynamic changes while preserving signal trends
   - Specifically designed for RSSI: process noise Q and measurement noise R tuned to your environment
   - Research shows this is the most effective single filter for RSSI
4. **Advanced Option**: Fourier Transform + Fuzzy C-Means + Kalman (FFK method)
   - Extracts low-frequency components
   - Identifies Line-of-Sight (LOS) signals
   - Provides 15-30% accuracy improvement in studies

**Implementation Priority**: Start with Kalman filter, add moving average if needed.

#### B. Per-Beacon Channel Processing
- Process each beacon's RSSI independently before aggregation
- Each beacon has different noise characteristics
- Apply filtering to each beacon's time series separately

### 2. ADVANCED FEATURE ENGINEERING

**Beyond Basic Statistics** (mean, std, count):

#### A. Signal Quality Features
- **Visibility duration**: How long has each beacon been consistently visible
- **Signal stability**: Variance over longer windows (5-10 seconds)
- **Dominant beacons**: Top 3-5 strongest beacons (these are most reliable)
- **Signal ratios**: RSSI_beacon_i / RSSI_beacon_j for key beacon pairs

#### B. Temporal Features
- **RSSI derivatives**: Rate of change in signal strength
- **Trending indicators**: Is signal getting stronger/weaker (movement direction)
- **Historical features**: Statistics from previous N windows
- **Transition patterns**: Changes in beacon visibility patterns

#### C. Spatial Features (Using Floor Plan)
- **Zone-level aggregation**: Group beacons by zones/corridors
- **Beacon proximity groups**: Use floor plan to create logical beacon groups
- **Distance-weighted features**: Weight beacons by known distance from possible locations

#### D. Wavelet Transform Features
- Research shows Recursive Continuous Wavelet Transform (R-CWT) extracts discriminative features
- Captures both frequency and time information
- Reported 98%+ accuracy in some studies

### 3. OPTIMAL WINDOW STRATEGY

**Current**: 1-second windows

**Recommendation**: Multi-scale approach
- **Short windows (1s)**: Capture immediate state
- **Medium windows (3-5s)**: More stable for noisy environments
- **Long windows (10s)**: Capture movement patterns

**Adaptive Windowing**: 
- Smaller windows when signals are stable
- Larger windows when signals are noisy or sparse
- Sliding windows with overlap (50-75%) to smooth transitions

### 4. HANDLING CLASS IMBALANCE

**Critical for Macro F1!** Multiple complementary techniques:

#### A. Data-Level Techniques (Choose 1-2)

**Option 1: SMOTE (Synthetic Minority Oversampling Technique)**
```python
from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE

# Standard SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

# Borderline-SMOTE (focuses on decision boundary)
bsmote = BorderlineSMOTE(random_state=42, kind='borderline-1')
X_train_balanced, y_train_balanced = bsmote.fit_resample(X_train, y_train)

# SVM-SMOTE (most sophisticated)
svmsmote = SVMSMOTE(random_state=42)
X_train_balanced, y_train_balanced = svmsmote.fit_resample(X_train, y_train)
```

**When to Use**:
- Standard SMOTE: First baseline
- Borderline-SMOTE: When minority classes overlap with majority
- SVM-SMOTE: Best for complex decision boundaries (your case)

**Option 2: SMOTE + Undersampling Hybrid**
```python
from imblearn.combine import SMOTETomek, SMOTEENN

# SMOTE + Tomek Links (removes noisy border samples)
smt = SMOTETomek(random_state=42)
X_train_balanced, y_train_balanced = smt.fit_resample(X_train, y_train)

# SMOTE + ENN (removes samples misclassified by 3-NN)
smenn = SMOTEENN(random_state=42)
X_train_balanced, y_train_balanced = smenn.fit_resample(X_train, y_train)
```

**Option 3: ADASYN (Adaptive Synthetic Sampling)**
```python
from imblearn.over_sampling import ADASYN

# Creates more samples for harder-to-learn minority instances
adasyn = ADASYN(random_state=42)
X_train_balanced, y_train_balanced = adasyn.fit_resample(X_train, y_train)
```

#### B. Algorithm-Level Techniques (Use in Combination)

**You're already using sample weights âœ“** - but can optimize:

```python
# More aggressive class weighting
from sklearn.utils.class_weight import compute_sample_weight

# Custom weights giving even more importance to minority
sample_weights = compute_sample_weight(
    class_weight='balanced',
    y=y_train
)
# Multiply by additional factor for very rare classes
sample_weights[y_train.isin(['506', '517', '518', 'hallway'])] *= 2.0

# In XGBoost
model = xgb.XGBClassifier(
    scale_pos_weight=sample_weights,  # Use computed weights
    max_delta_step=1,  # Helps with extreme imbalance
    ...
)
```

**Cost-Sensitive Learning**:
```python
# Custom objective function emphasizing minority classes
def custom_focal_loss(y_true, y_pred):
    # Focal loss reduces loss for well-classified examples
    # Focuses learning on hard misclassified examples
    # Especially good for imbalanced data
    pass
```

#### C. Ensemble Methods

**Balanced Random Forest**:
```python
from imblearn.ensemble import BalancedRandomForestClassifier

brf = BalancedRandomForestClassifier(
    n_estimators=100,
    sampling_strategy='all',  # Balance all classes
    replacement=True,
    bootstrap=False,
    random_state=42
)
```

**Bagging with Balancing**:
```python
from imblearn.ensemble import BalancedBaggingClassifier

bbc = BalancedBaggingClassifier(
    estimator=xgb.XGBClassifier(),
    n_estimators=10,
    random_state=42
)
```

### 5. SPATIAL-TEMPORAL POST-PROCESSING

**Problem**: Raw predictions ignore physical constraints (e.g., can't teleport between rooms).

**Solution: Hidden Markov Model (HMM) Smoothing**

This is widely used in indoor localization and can improve accuracy by 20-40%!

```python
from hmmlearn import hmm
import numpy as np

# Step 1: Build transition probability matrix from training data
def build_transition_matrix(train_sequences, rooms):
    n_rooms = len(rooms)
    transition_counts = np.zeros((n_rooms, n_rooms))
    
    for sequence in train_sequences:
        for i in range(len(sequence) - 1):
            current_room = sequence[i]
            next_room = sequence[i + 1]
            transition_counts[current_room][next_room] += 1
    
    # Normalize to probabilities
    transition_probs = transition_counts / transition_counts.sum(axis=1, keepdims=True)
    
    # Add small probability for unseen transitions
    transition_probs += 0.01
    transition_probs /= transition_probs.sum(axis=1, keepdims=True)
    
    return transition_probs

# Step 2: Encode spatial constraints from floor plan
def encode_spatial_constraints(floor_plan, transition_probs):
    # Reduce probability of impossible transitions (distant rooms)
    # Increase probability of adjacent rooms
    for i, room_i in enumerate(rooms):
        for j, room_j in enumerate(rooms):
            if are_adjacent(room_i, room_j, floor_plan):
                transition_probs[i][j] *= 2.0  # Double probability
            elif distance(room_i, room_j, floor_plan) > threshold:
                transition_probs[i][j] *= 0.1  # Very unlikely
    
    # Re-normalize
    transition_probs /= transition_probs.sum(axis=1, keepdims=True)
    return transition_probs

# Step 3: Apply Viterbi algorithm for MAP trajectory
def smooth_predictions_with_hmm(ml_predictions, ml_probabilities, transition_matrix):
    """
    ml_predictions: Raw ML model predictions [T]
    ml_probabilities: Prediction probabilities [T, n_classes]
    transition_matrix: Room-to-room transitions [n_classes, n_classes]
    """
    model = hmm.MultinomialHMM(n_components=len(rooms))
    model.transmat_ = transition_matrix
    model.startprob_ = np.ones(len(rooms)) / len(rooms)
    
    # Use ML probabilities as emission probabilities
    model.emissionprob_ = ml_probabilities
    
    # Find most likely sequence
    smoothed_predictions = model.predict(ml_predictions.reshape(-1, 1))
    
    return smoothed_predictions

# Step 4: Simple moving majority vote as alternative
def majority_vote_smoothing(predictions, window_size=5):
    """Simpler alternative: moving window majority vote"""
    smoothed = []
    for i in range(len(predictions)):
        start = max(0, i - window_size // 2)
        end = min(len(predictions), i + window_size // 2 + 1)
        window = predictions[start:end]
        smoothed.append(max(set(window), key=window.count))
    return np.array(smoothed)
```

**Key Research Findings**:
- HMM with spatial constraints improves accuracy by 20-40%
- Viterbi algorithm finds globally optimal trajectory
- Encodes impossible/unlikely transitions (e.g., room 501 â†’ cafeteria requires passing through hallway)
- Particularly effective for confused adjacent rooms

### 6. MODEL ARCHITECTURE

**Current**: Single XGBoost model âœ“ (good choice!)

**Enhancements**:

#### A. Hierarchical Classification
```python
# Level 1: Predict zone (corridor/section of building)
zone_model = xgb.XGBClassifier(...)
zone_pred = zone_model.predict(X)

# Level 2: Within each zone, predict specific room
room_models = {
    'north_corridor': xgb.XGBClassifier(...),
    'south_corridor': xgb.XGBClassifier(...),
    'central_area': xgb.XGBClassifier(...),
}
room_pred = room_models[zone_pred].predict(X)
```

Benefits:
- Reduces confusion between distant rooms
- Easier to learn zone-specific patterns
- Can have different features for each zone

#### B. Ensemble of Multiple Models
```python
from sklearn.ensemble import VotingClassifier

ensemble = VotingClassifier(
    estimators=[
        ('xgb', xgb.XGBClassifier(...)),
        ('rf', BalancedRandomForestClassifier(...)),
        ('lgbm', lgb.LGBMClassifier(...)),
    ],
    voting='soft',  # Use probability averaging
    weights=[2, 1, 1]  # Weight XGB more
)
```

#### C. Deep Learning (If needed)
Only if tree-based methods plateau:
- 1D CNN on RSSI time series
- LSTM/GRU for temporal patterns
- ResNet-style architecture with skip connections

### 7. COMPLETE OPTIMAL PIPELINE

```
RAW BLE DATA
    â†“
1. SIGNAL FILTERING (per beacon)
   - Outlier removal
   - Moving average (window=5-10)
   - Kalman filter (Q, R optimized)
    â†“
2. MULTI-SCALE WINDOWING
   - 1s, 3s, 5s windows
   - Sliding with 50% overlap
    â†“
3. ADVANCED FEATURE ENGINEERING
   - Basic: mean, std, count, min, max per beacon
   - Quality: visibility_duration, stability_score, dominant_beacons
   - Temporal: delta_rssi, trend_indicator, historical_features
   - Spatial: zone_aggregations, beacon_group_features
   - (Optional) Wavelet: R-CWT features
    â†“
4. HANDLE CLASS IMBALANCE
   - Apply SMOTE/BorderlineSMOTE/SVMSMOTE
   - OR use BalancedBaggingClassifier
   - + Sample weights in model
    â†“
5. MODEL TRAINING
   - Primary: XGBoost with optimized hyperparameters
   - Alternative: Balanced Random Forest
   - Or: Ensemble of both
    â†“
6. SPATIAL-TEMPORAL POST-PROCESSING
   - HMM with floor-plan-informed transition matrix
   - Viterbi algorithm for MAP trajectory
   - OR: Simple majority vote smoothing
    â†“
FINAL PREDICTIONS
```

---

## PART 2: SPECIFIC IMPROVEMENTS TO YOUR CURRENT APPROACH

Based on your current pipeline (1s windowing â†’ XGBoost â†’ window-level prediction), here are targeted improvements ordered by expected impact:

### Priority 1: ADDRESS CLASS IMBALANCE (HIGH IMPACT) ğŸ”¥

**Why it's critical**: Your failing classes (506, 517, 518, hallway) have F1=0.0-0.022, dragging macro F1 down.

**Quick Win Solutions**:

#### Option A: SMOTE Oversampling (Easiest, ~24 hours to implement)
```python
from imblearn.over_sampling import BorderlineSMOTE

# After windowing, before model training
smote = BorderlineSMOTE(
    sampling_strategy='auto',  # Balance all classes
    k_neighbors=5,
    random_state=42
)
X_train_resampled, y_train_resampled = smote.fit_resample(
    X_train_windows, 
    y_train_windows
)

# Then train XGBoost on resampled data
model.fit(X_train_resampled, y_train_resampled)
```

**Expected improvement**: Macro F1: 0.23 â†’ 0.35-0.42

#### Option B: Balanced Ensemble (Medium effort, ~2-3 days)
```python
from imblearn.ensemble import BalancedBaggingClassifier
import xgboost as xgb

# Wraps XGBoost with automatic balancing
balanced_model = BalancedBaggingClassifier(
    estimator=xgb.XGBClassifier(
        max_depth=6,
        learning_rate=0.05,
        n_estimators=200,
        objective='multi:softprob',
    ),
    n_estimators=10,  # Number of balanced bags
    sampling_strategy='auto',
    replacement=False,
    random_state=42
)

balanced_model.fit(X_train_windows, y_train_windows)
```

**Expected improvement**: Macro F1: 0.23 â†’ 0.38-0.45

#### Option C: Enhanced Sample Weights (Quickest, ~4 hours)
```python
from sklearn.utils.class_weight import compute_sample_weight

# More aggressive weighting for failing classes
sample_weights = compute_sample_weight('balanced', y_train_windows)

# Extra boost for the worst performers
failing_classes = ['506', '517', '518', 'hallway', '522', '511']
failing_mask = y_train_windows.isin(failing_classes)
sample_weights[failing_mask] *= 3.0  # Triple the importance

# Use in XGBoost
model.fit(
    X_train_windows, 
    y_train_windows,
    sample_weight=sample_weights
)
```

**Expected improvement**: Macro F1: 0.23 â†’ 0.28-0.35

**Recommended**: Try Option A (SMOTE) first, then Option B if needed.

### Priority 2: SIGNAL PREPROCESSING (MEDIUM-HIGH IMPACT) ğŸ”¥

**Problem**: Raw RSSI is too noisy, especially for rare rooms.

**Solution: Kalman Filtering Before Windowing**

```python
from pykalman import KalmanFilter

def kalman_filter_rssi(beacon_data):
    """
    Apply Kalman filter to each beacon's RSSI time series
    
    beacon_data: DataFrame with columns [timestamp, beacon_id, rssi]
    Returns: DataFrame with additional column 'rssi_filtered'
    """
    filtered_data = []
    
    for beacon_id in beacon_data['beacon_id'].unique():
        beacon_rssi = beacon_data[beacon_data['beacon_id'] == beacon_id]['rssi'].values
        
        # Initialize Kalman filter
        kf = KalmanFilter(
            transition_matrices=[1],  # RSSI doesn't drift
            observation_matrices=[1],
            initial_state_mean=beacon_rssi[0],
            initial_state_covariance=1,
            observation_covariance=10,  # Measurement noise (tune this)
            transition_covariance=0.1   # Process noise (tune this)
        )
        
        # Apply filter
        state_means, _ = kf.filter(beacon_rssi)
        
        filtered_data.append({
            'beacon_id': beacon_id,
            'rssi_filtered': state_means.flatten()
        })
    
    return filtered_data

# Apply before windowing
cleaned_ble_data['rssi_filtered'] = kalman_filter_rssi(cleaned_ble_data)

# Use rssi_filtered instead of raw rssi in windowing
```

**Hyperparameter tuning**:
- `observation_covariance` (R): Measurement noise (5-20 typically)
- `transition_covariance` (Q): Process noise (0.01-1 typically)
- Tune on validation set

**Expected improvement**: Macro F1: 0.23 â†’ 0.28-0.33 (combined with SMOTE: 0.40-0.48)

### Priority 3: ENHANCED FEATURE ENGINEERING (MEDIUM IMPACT) ğŸ”¥

**Current features (per window)**: Mean, Std, Count per beacon (75 features)

**Add these features**:

```python
def engineer_advanced_features(window_data):
    """
    window_data: All BLE records within a 1-second window
    Returns: Dict of features
    """
    features = {}
    
    # Current features (keep these)
    for beacon_id in range(1, 26):
        beacon_signals = window_data[window_data['beacon'] == beacon_id]['rssi']
        features[f'beacon_{beacon_id}_mean'] = beacon_signals.mean()
        features[f'beacon_{beacon_id}_std'] = beacon_signals.std()
        features[f'beacon_{beacon_id}_count'] = len(beacon_signals)
    
    # NEW FEATURES
    
    # 1. Dominant beacons (most reliable)
    all_rssi = window_data.groupby('beacon')['rssi'].mean().sort_values(ascending=False)
    features['dominant_beacon_1'] = all_rssi.index[0] if len(all_rssi) > 0 else -1
    features['dominant_beacon_2'] = all_rssi.index[1] if len(all_rssi) > 1 else -1
    features['dominant_beacon_3'] = all_rssi.index[2] if len(all_rssi) > 2 else -1
    features['dominant_rssi_1'] = all_rssi.values[0] if len(all_rssi) > 0 else -100
    features['dominant_rssi_2'] = all_rssi.values[1] if len(all_rssi) > 1 else -100
    features['dominant_rssi_3'] = all_rssi.values[2] if len(all_rssi) > 2 else -100
    
    # 2. Signal quality metrics
    features['n_beacons_visible'] = len(all_rssi)
    features['avg_rssi_all_beacons'] = window_data['rssi'].mean()
    features['max_rssi_all_beacons'] = window_data['rssi'].max()
    features['rssi_range'] = window_data['rssi'].max() - window_data['rssi'].min()
    
    # 3. Beacon ratios (helps distinguish similar locations)
    if len(all_rssi) >= 2:
        features['rssi_ratio_1_2'] = all_rssi.values[0] / all_rssi.values[1]
    if len(all_rssi) >= 3:
        features['rssi_ratio_1_3'] = all_rssi.values[0] / all_rssi.values[2]
        features['rssi_ratio_2_3'] = all_rssi.values[1] / all_rssi.values[2]
    
    # 4. Zone-based features (group nearby beacons based on floor plan)
    # Example zones (customize based on your floor plan):
    north_zone = [1, 2, 3, 5, 6]
    south_zone = [7, 8, 10, 11, 12]
    central_zone = [4, 9, 14, 24, 25]
    
    for zone_name, beacon_ids in [('north', north_zone), 
                                   ('south', south_zone), 
                                   ('central', central_zone)]:
        zone_data = window_data[window_data['beacon'].isin(beacon_ids)]
        features[f'zone_{zone_name}_avg_rssi'] = zone_data['rssi'].mean() if len(zone_data) > 0 else -100
        features[f'zone_{zone_name}_n_beacons'] = len(zone_data['beacon'].unique())
    
    # 5. Temporal stability (requires previous windows)
    # Implement in windowing function to access history
    
    return features
```

**Expected improvement**: Macro F1: 0.23 â†’ 0.27-0.32 (combined with above: 0.45-0.52)

### Priority 4: POST-PROCESSING WITH HMM (MEDIUM IMPACT) ğŸ”¥

**Problem**: Predictions jump unrealistically between distant rooms.

**Solution**: Apply HMM smoothing with floor plan constraints.

```python
import numpy as np
from scipy.stats import mode

# Simple version: Majority vote smoothing
def majority_vote_smoothing(predictions, window_size=5):
    """
    Smooth predictions by majority vote in sliding window
    window_size: Should be odd (e.g., 3, 5, 7)
    """
    smoothed = predictions.copy()
    half_window = window_size // 2
    
    for i in range(len(predictions)):
        start = max(0, i - half_window)
        end = min(len(predictions), i + half_window + 1)
        window = predictions[start:end]
        
        # Most common prediction in window
        smoothed[i] = mode(window)[0]
    
    return smoothed

# Advanced version: HMM with spatial constraints
def build_transition_matrix_from_floor_plan(rooms, adjacency_dict):
    """
    Build transition matrix encoding spatial constraints
    
    adjacency_dict: Dictionary mapping each room to its adjacent rooms
    Example:
    {
        '501': ['502', 'hallway'],
        '502': ['501', '506', 'hallway'],
        'hallway': ['501', '502', '506', '511', '512', ...],
        ...
    }
    """
    n_rooms = len(rooms)
    room_to_idx = {room: i for i, room in enumerate(rooms)}
    
    # Initialize with small probability for all transitions
    transition_matrix = np.ones((n_rooms, n_rooms)) * 0.01
    
    # High probability for staying in same room
    np.fill_diagonal(transition_matrix, 0.7)
    
    # Medium probability for adjacent rooms
    for room, adjacent_rooms in adjacency_dict.items():
        i = room_to_idx[room]
        for adj_room in adjacent_rooms:
            j = room_to_idx[adj_room]
            transition_matrix[i][j] = 0.1
    
    # Normalize
    transition_matrix = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)
    
    return transition_matrix

def viterbi_smoothing(predictions, probabilities, transition_matrix):
    """
    Apply Viterbi algorithm to find most likely room sequence
    
    predictions: Raw predictions [T]
    probabilities: Model output probabilities [T, n_classes]
    transition_matrix: [n_classes, n_classes]
    """
    T = len(predictions)
    n_states = len(transition_matrix)
    
    # Initialize
    viterbi = np.zeros((T, n_states))
    backpointer = np.zeros((T, n_states), dtype=int)
    
    # First timestep
    viterbi[0] = probabilities[0]
    
    # Forward pass
    for t in range(1, T):
        for s in range(n_states):
            # Probability of transitioning to state s from each previous state
            trans_probs = viterbi[t-1] * transition_matrix[:, s]
            # Best previous state
            backpointer[t, s] = np.argmax(trans_probs)
            # Max probability
            viterbi[t, s] = np.max(trans_probs) * probabilities[t, s]
    
    # Backward pass: reconstruct best path
    best_path = np.zeros(T, dtype=int)
    best_path[-1] = np.argmax(viterbi[-1])
    
    for t in range(T-2, -1, -1):
        best_path[t] = backpointer[t+1, best_path[t+1]]
    
    return best_path

# Usage
# 1. Build adjacency from floor plan
adjacency = build_adjacency_from_floor_plan()  # Implement based on your map
transition_matrix = build_transition_matrix_from_floor_plan(rooms, adjacency)

# 2. Get model predictions and probabilities
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# 3. Apply smoothing
y_pred_smoothed = viterbi_smoothing(y_pred, y_pred_proba, transition_matrix)

# OR use simpler majority vote
y_pred_smoothed = majority_vote_smoothing(y_pred, window_size=5)
```

**Expected improvement**: +0.03-0.08 to Macro F1 (especially helps hallway and adjacent rooms)

### Priority 5: HYPERPARAMETER OPTIMIZATION (LOW-MEDIUM IMPACT)

**Current XGBoost parameters**: Likely using defaults?

**Optimize these**:

```python
from sklearn.model_selection import RandomizedSearchCV
import xgboost as xgb

param_distributions = {
    'max_depth': [4, 6, 8, 10],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'n_estimators': [100, 200, 300, 500],
    'min_child_weight': [1, 3, 5],
    'gamma': [0, 0.1, 0.2, 0.5],
    'subsample': [0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
    'reg_alpha': [0, 0.1, 1, 10],  # L1 regularization
    'reg_lambda': [0, 1, 10, 100],  # L2 regularization
}

model = xgb.XGBClassifier(
    objective='multi:softprob',
    eval_metric='auc',
    use_label_encoder=False,
)

# Use RandomizedSearchCV (faster than GridSearchCV)
random_search = RandomizedSearchCV(
    model,
    param_distributions,
    n_iter=50,  # Try 50 random combinations
    scoring='f1_macro',  # Optimize for macro F1!
    cv=3,  # 3-fold CV
    random_state=42,
    n_jobs=-1
)

random_search.fit(X_train, y_train, sample_weight=sample_weights)
best_model = random_search.best_estimator_
```

**Expected improvement**: +0.02-0.05 to Macro F1

### Priority 6: DIFFERENT WINDOW SIZES (LOW IMPACT)

**Current**: 1-second windows

**Experiment**:
- Try 2s, 3s, 5s windows
- Or multi-scale: extract features from 1s, 3s, 5s simultaneously

```python
def multi_scale_features(ble_data, timestamp, window_sizes=[1, 3, 5]):
    """
    Extract features at multiple time scales
    """
    all_features = {}
    
    for window_size in window_sizes:
        start_time = timestamp - pd.Timedelta(seconds=window_size)
        window_data = ble_data[
            (ble_data['timestamp'] >= start_time) & 
            (ble_data['timestamp'] <= timestamp)
        ]
        
        features = engineer_features(window_data)
        # Prefix with window size
        for key, value in features.items():
            all_features[f'{key}_w{window_size}s'] = value
    
    return all_features
```

**Expected improvement**: +0.01-0.03 to Macro F1

---

## IMPLEMENTATION ROADMAP

### Phase 1: Quick Wins (1-2 weeks) - Target F1: 0.35-0.42
1. âœ… Implement SMOTE or BorderlineSMOTE (2 days)
2. âœ… Enhance sample weights for failing classes (1 day)
3. âœ… Add dominant beacon features (2 days)
4. âœ… Try majority vote smoothing (1 day)
5. âœ… Hyperparameter tuning with macro F1 as metric (3 days)

**Expected result**: Macro F1 = 0.35-0.42

### Phase 2: Signal Quality (1-2 weeks) - Target F1: 0.42-0.50
1. âœ… Implement Kalman filtering per beacon (3 days)
2. âœ… Add advanced features (ratios, zones, quality metrics) (3 days)
3. âœ… Experiment with different window sizes (2 days)

**Expected result**: Macro F1 = 0.42-0.50

### Phase 3: Spatial Intelligence (1-2 weeks) - Target F1: 0.50-0.58
1. âœ… Build floor plan adjacency matrix (2 days)
2. âœ… Implement HMM with Viterbi algorithm (4 days)
3. âœ… Try hierarchical classification (zones â†’ rooms) (4 days)

**Expected result**: Macro F1 = 0.50-0.58

### Phase 4: Advanced Techniques (if needed) - Target F1: 0.58+
1. âœ… Wavelet transform features (4 days)
2. âœ… Balanced ensemble methods (3 days)
3. âœ… Deep learning (LSTM/CNN) (1-2 weeks)

---

## KEY INSIGHTS FROM CONFUSION MATRIX

Looking at your confusion matrix:

### Misclassification Patterns

1. **Room 502 Confusion**:
   - Predicted as: 518 (37.6%), 520 (29.6%), 517 (13.1%)
   - **Insight**: These rooms are likely adjacent or in same corridor
   - **Solution**: HMM with spatial constraints, zone-based features

2. **Room 506 Confusion**:
   - Scattered across many rooms (hallway, kitchen, nurse station, 520)
   - **Insight**: Beacon signal pattern similar to many locations (in central area?)
   - **Solution**: SMOTE + dominant beacon features + zone aggregation

3. **Hallway Confusion**:
   - Predicted as: nurse station (31.7%), cleaning (14.8%), 520 (20.2%)
   - **Insight**: Hallway connects many rooms, transitional space
   - **Solution**: Temporal features (movement patterns), transition detection

4. **Well-Performing Rooms**:
   - 501 (73.7% correct), 520 (57.1%), nurse station (68.9%), kitchen (48.1%)
   - **Insight**: These have distinctive beacon patterns
   - **Strategy**: Use their patterns as "anchors" in hierarchical model

### Adjacent Room Problem

Your intuition is correct! Looking at the floor map:
- Rooms 501-502-506 are in same row â†’ high confusion
- Rooms 511-512-513 are adjacent â†’ confusion
- Rooms in 520s corridor â†’ confusion

**Solutions**:
1. **Zone-level features**: Aggregate beacons by building sections
2. **Transition modeling**: Learn valid room transitions
3. **Temporal smoothing**: Prevent impossible jumps

---

## DEBUGGING TIPS

### Check Class Distribution
```python
# After SMOTE
print("Original class distribution:")
print(y_train.value_counts())
print("\nAfter SMOTE:")
print(y_train_resampled.value_counts())
```

### Analyze Per-Class Performance
```python
from sklearn.metrics import classification_report

# Detailed report
print(classification_report(y_true, y_pred, zero_division=0))

# Focus on failing classes
failing_classes = ['506', '517', '518', 'hallway']
failing_mask = y_true.isin(failing_classes)
print(f"\nFailing classes accuracy: {(y_true[failing_mask] == y_pred[failing_mask]).mean()}")
```

### Feature Importance
```python
import matplotlib.pyplot as plt

# XGBoost feature importance
importance = model.feature_importances_
feature_names = X_train.columns
importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': importance
}).sort_values('importance', ascending=False)

# Plot top 20
plt.figure(figsize=(10, 8))
plt.barh(importance_df['feature'][:20], importance_df['importance'][:20])
plt.xlabel('Importance')
plt.title('Top 20 Features')
plt.tight_layout()
plt.savefig('feature_importance.png')
```

---

## EXPECTED FINAL PERFORMANCE

With full implementation of recommendations:

| Phase | Techniques | Expected Macro F1 | Time |
|-------|-----------|------------------|------|
| Baseline | Current approach | 0.23 | - |
| Phase 1 | SMOTE + Weights + Features | 0.35-0.42 | 1-2 weeks |
| Phase 2 | + Kalman + Advanced Features | 0.42-0.50 | 2-3 weeks |
| Phase 3 | + HMM + Hierarchical | 0.50-0.58 | 3-4 weeks |
| Phase 4 | + Wavelets + Ensemble | 0.58-0.65 | 4-6 weeks |

**Target (0.50)**: Achievable in Phase 2-3 (3-4 weeks)

---

## CRITICAL SUCCESS FACTORS

1. **Class imbalance is your #1 problem** - Fix this first!
2. **Signal noise hurts minority classes most** - Kalman filtering essential
3. **Spatial constraints are powerful** - Use the floor plan!
4. **Temporal coherence matters** - People don't teleport
5. **Dominant beacons are most reliable** - Focus on strongest signals
6. **Adjacent rooms need extra attention** - Zone-based modeling helps

---

## REFERENCES

Research papers that informed these recommendations:
1. "SMOTE: Synthetic Minority Oversampling Technique" (Chawla et al., 2002)
2. "Kalman Filters for RSSI Indoor Localization" (multiple papers)
3. "Hidden Markov Models for Indoor Tracking" (multiple papers)
4. "R-CWT for BLE Indoor Localization" (recent papers, 2022-2023)
5. "Comparative Analysis of ML Algorithms for BLE Localization" (2024)
6. "Balanced Random Forest for Imbalanced Classification"

All techniques recommended are well-established in the literature with proven effectiveness for your exact problem type.

---

## CONCLUSION

Your current approach is solid but needs three critical additions:
1. **Class imbalance handling** (SMOTE / Balanced ensemble)
2. **Signal preprocessing** (Kalman filtering)
3. **Spatial-temporal post-processing** (HMM smoothing)

These three changes alone should get you from 0.23 â†’ 0.45-0.52 Macro F1.

The good news: Your best-performing rooms (kitchen, nurse station, 520) show the system CAN work. The problem is the minority classes being completely ignored. Fix the imbalance, and those classes will start learning.

**Start with Phase 1 (SMOTE + enhanced features)** - this is the fastest path to your 0.50 target! ğŸ¯